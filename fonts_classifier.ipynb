{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For selected font, script will generate each of above character (a-z, A-Z, 0-9) at nine different position to move text by one pixel in right-left and top-bottom direction. \n",
    "\n",
    "#### NOTE: If you want generate some new data use kernel == python2, because ttfquery can cause problems at python3\n",
    "Also you can use generated images from Synthetic_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import ttfquery.findsystem \n",
    "import string\n",
    "import ntpath\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input params:\n",
    "\n",
    "    fontSize\n",
    "    imgSize\n",
    "    position\n",
    "    font_list - list of fonts which will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordbag creating and exporting to .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_parser(inp_str):\n",
    "    lower_case_list = list(string.ascii_lowercase)\n",
    "    words = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    flag = False\n",
    "    while i < len(inp_str):\n",
    "        while inp_str[i] in string.ascii_letters:\n",
    "            i+=1  \n",
    "            flag = True\n",
    "        if flag and i>j+3: # take words with len > 3\n",
    "            words.append(inp_str.lower()[j:i])\n",
    "        i += 1\n",
    "        j = i\n",
    "        flag = False\n",
    "    return words\n",
    "\n",
    "def words_generator(path='words.txt'):\n",
    "    \n",
    "    try:\n",
    "        from sklearn.datasets import fetch_20newsgroups\n",
    "        \n",
    "        wordbag = fetch_20newsgroups(subset='all', categories=['sci.space'], shuffle=True, random_state=42)\n",
    "        words = []; i = 0\n",
    "        for text in wordbag.data[:100][:]:\n",
    "            tmp = words_parser(text)\n",
    "            words = np.hstack([words,tmp])\n",
    "        words = words.tolist()\n",
    "        print(len(words), 'words were generated')\n",
    "        f = open('words.txt','w')\n",
    "        for word in words:\n",
    "            f.write(word + '\\n')\n",
    "        f.close()\n",
    "    \n",
    "    except:\n",
    "        print('Install sklearn to generate text!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18509 words were generated\n"
     ]
    }
   ],
   "source": [
    "words_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_bag_reader(filename):\n",
    "    #reading wordbag\n",
    "    words_bag = []\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            words_bag.append(f.read())\n",
    "            words_bag = list(words_bag)\n",
    "        words_bag = words_bag[0].split('\\n')\n",
    "    except:\n",
    "        print(\"File with words doesnt exist!!!\")\n",
    "        \n",
    "    return words_bag\n",
    "\n",
    "def data_generator(fonts, directory='Synthetic_dataset', img_per_class=20, img_size=(128,128), fontSize=20):\n",
    "    \"\"\"\n",
    "    fonst -- list of fonts which will be classaficated\n",
    "    words randomly can be in lower case, upper case and only first char is upper\n",
    "    words are taken from wordbag file\n",
    "    \"\"\"\n",
    "        \n",
    "    words_bag = words_bag_reader('words.txt')\n",
    "    \n",
    "    #creating directory\n",
    "    dataset_path = os.path.join (os.getcwd(), directory)\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(dataset_path) \n",
    "    \n",
    "    #system fonts\n",
    "    all_fonts = ttfquery.findsystem.findFonts()\n",
    "    #creating paths to fonts\n",
    "    cases = [string.lower, string.upper, string.capitalize]\n",
    "    fonts.sort()\n",
    "    \n",
    "    for cur_font in fonts:\n",
    "        for i in range(img_per_class):\n",
    "            for sys_font in all_fonts:\n",
    "                sys_lower = sys_font.lower()\n",
    "                cur_lower = cur_font.lower()\n",
    "                if cur_lower+'.' in sys_lower:# dot is used to get regular style\n",
    "                    path = sys_font\n",
    "                    font = ImageFont.truetype(path, fontSize)\n",
    "                    text = np.random.choice(words_bag)\n",
    "                    text = np.random.choice(cases)(text)\n",
    "                    text_width, text_height = font.getsize(text)\n",
    "                    flag = (text_width >= img_size[0] or text_height >= img_size[1])\n",
    "                    while flag:\n",
    "                        text = np.random.choice(words_bag)\n",
    "                        text = np.random.choice(cases)(text)\n",
    "                        text_width, text_height = font.getsize(text)\n",
    "                        flag = (text_width >= img_size[0] or text_height >= img_size[1])\n",
    "                    image = Image.new(\"RGB\", (text_width, text_height), (255,255,255))\n",
    "                    draw = ImageDraw.Draw(image)\n",
    "                    draw.text((0,0), text, (0,0,0), font=font)\n",
    "                    file_name = str(cur_lower) + '_' + str(i)+'.jpg'\n",
    "                    file_name = os.path.join(dataset_path,file_name)\n",
    "                    image.save(file_name)\n",
    "                    break   \n",
    "                    \n",
    "def data_generator_folders(fonts, directory='Synthetic_dataset', img_per_class=20, img_size=(128,128), fontSize=20):\n",
    "    \"\"\"\n",
    "    fonst -- list of fonts which will be classaficated\n",
    "    words randomly can be in lower case, upper case and only first char is upper\n",
    "    words are taken from wordbag file\n",
    "    \"\"\"\n",
    "    \n",
    "    words_bag = words_bag_reader('words.txt')\n",
    "        \n",
    "    #creating directory\n",
    "    dataset_path = os.path.join (os.getcwd(), directory)\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(dataset_path) \n",
    "    \n",
    "    #system fonts\n",
    "    all_fonts = ttfquery.findsystem.findFonts()\n",
    "    #creating paths to fonts\n",
    "    cases = [string.lower, string.upper, string.capitalize]\n",
    "    fonts.sort()\n",
    "    for cur_font in fonts:\n",
    "        for i in range(img_per_class):\n",
    "            for sys_font in all_fonts:\n",
    "                sys_lower = sys_font.lower()\n",
    "                cur_lower = cur_font.lower()\n",
    "                if cur_lower+'.' in sys_lower:# dot is used to get regular style\n",
    "                    path = sys_font\n",
    "                    font = ImageFont.truetype(path, fontSize)\n",
    "                    text = np.random.choice(words_bag)\n",
    "                    text = np.random.choice(cases)(text)\n",
    "                    text_width, text_height = font.getsize(text)\n",
    "                    flag = (text_width >= img_size[0] or text_height >= img_size[1])\n",
    "                    while flag:\n",
    "                        text = np.random.choice(words_bag)\n",
    "                        text = np.random.choice(cases)(text)\n",
    "                        text_width, text_height = font.getsize(text)\n",
    "                        flag = (text_width >= img_size[0] or text_height >= img_size[1])\n",
    "                    image = Image.new(\"RGB\", (text_width, text_height), (255,255,255))\n",
    "                    draw = ImageDraw.Draw(image)\n",
    "                    draw.text((0,0), text, (0,0,0), font=font)\n",
    "                    file_name = str(i)+'.jpg'\n",
    "                    font_dir = os.path.join(dataset_path, cur_lower)\n",
    "                    if not os.path.exists(font_dir):\n",
    "                        os.makedirs(font_dir)\n",
    "                    file_name = os.path.join(font_dir,file_name)\n",
    "                    image.save(file_name)\n",
    "                    break   \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "def data_generator_folders_train_test(fonts, words_bag, directory='Synthetic_dataset', img_per_class=20, \\\n",
    "                                      img_size=(128,128), fontSize=18):\n",
    "    \"\"\"\n",
    "    fonst -- list of fonts which will be classaficated\n",
    "    words randomly can be in lower case, upper case and only first char is upper\n",
    "    words are taken from wordbag file\n",
    "    \"\"\"\n",
    "    #creating directory\n",
    "    dataset_path = os.path.join (os.getcwd(), directory)\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(dataset_path) \n",
    "    \n",
    "    #system fonts\n",
    "    all_fonts = ttfquery.findsystem.findFonts()\n",
    "    #creating paths to fonts\n",
    "    cases = [string.lower, string.upper, string.capitalize]\n",
    "    fonts.sort()\n",
    "    for cur_font in fonts:\n",
    "        for i in range(img_per_class):\n",
    "            for sys_font in all_fonts:\n",
    "                sys_lower = sys_font.lower()\n",
    "                cur_lower = cur_font.lower()\n",
    "                if cur_lower+'.' in sys_lower:# dot is used to get regular style\n",
    "                    path = sys_font\n",
    "                    font = ImageFont.truetype(path, fontSize)\n",
    "                    text = np.random.choice(words_bag)\n",
    "                    text = np.random.choice(cases)(text)\n",
    "                    text_width, text_height = font.getsize(text)\n",
    "                    flag = (text_width >= img_size[0] or text_height >= img_size[1])\n",
    "                    while flag:\n",
    "                        text = np.random.choice(words_bag)\n",
    "                        text = np.random.choice(cases)(text)\n",
    "                        text_width, text_height = font.getsize(text)\n",
    "                        flag = (text_width >= img_size[0] or text_height >= img_size[1])\n",
    "                    image = Image.new(\"RGB\", (text_width, text_height), (255,255,255))\n",
    "#                     image = Image.new(\"RGB\", img_size, (255,255,255))\n",
    "                    draw = ImageDraw.Draw(image)\n",
    "                    draw.text((0,0), text, (0,0,0), font=font)\n",
    "                    file_name = str(i)+'.jpg'\n",
    "                    font_dir = os.path.join(dataset_path, cur_lower)\n",
    "                    if not os.path.exists(font_dir):\n",
    "                        os.makedirs(font_dir)\n",
    "                    file_name = os.path.join(font_dir,file_name)\n",
    "                    image.save(file_name)\n",
    "                    break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for ubuntu\n",
    "fonts_list = ['Arial', 'Verdana', 'Comic_Sans_MS', 'Courier_New', 'Times_New_Roman', 'Impact', 'Georgia', 'Trebuc', \\\n",
    "             'Andalemo', 'Lato-Regular']\n",
    "#for windows\n",
    "fonts_list = ['Arial', 'Verdana', 'Comic', 'Cour', 'Times', 'Impact', 'Georgia', 'Trebuc', \\\n",
    "             'Alfredo', 'Borealis']\n",
    "data_generator_folders(fonts=fonts_list, directory='Synthetic_dataset_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for ubuntu\n",
    "fonts_list = ['Arial', 'Verdana', 'Comic_Sans_MS', 'Courier_New', 'Times_New_Roman', 'Impact', 'Georgia', 'Trebuc', \\\n",
    "             'Andalemo', 'Lato-Regular']\n",
    "#for windows\n",
    "fonts_list = ['Arial', 'Verdana', 'Comic', 'Cour', 'Times', 'Impact', 'Georgia', 'Trebuc', \\\n",
    "             'Corbel', 'Alger']\n",
    "img_per_class=100\n",
    "N = len(fonts_list)*img_per_class\n",
    "words_bag = words_bag_reader('words.txt')\n",
    "words_bag_set = np.random.choice(words_bag, size=3*N, replace=False)\n",
    "words_bag_train = words_bag_set[:N]\n",
    "words_bag_val = words_bag_set[N:2*N]\n",
    "words_bag_test = words_bag_set[2*N:]\n",
    "data_generator_folders_train_test(fonts_list, words_bag_train, 'Synthetic_dataset/train/', img_per_class)\n",
    "data_generator_folders_train_test(fonts_list, words_bag_val, 'Synthetic_dataset/val/', img_per_class)\n",
    "data_generator_folders_train_test(fonts_list, words_bag_test, 'Synthetic_dataset/test/', img_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here python3 is recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.layers import Conv2D, ActivityRegularization, MaxPooling2D\n",
    "from keras.backend import resize_images, reshape\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator usage\n",
    "We will use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen for train, validation and test\n",
    "\n",
    "For training we use train and validation data.\n",
    "After training, test score is calculated by cross validation at test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(model, directory_train, directory_val, directory_test, batch_size=16, epochs=10, verbose=1,\\\n",
    "            nb_train_samples = 2000, nb_validation_samples = 800, nb_test_samples = 1000, img_size=(128,128)):\n",
    "    \"\"\"\n",
    "    creating train/validaton generators for model fitting\n",
    "    \"\"\"\n",
    "    # this is the augmentation configuration we will use for training\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "    # this is the augmentation configuration we will use for testing:\n",
    "    # only rescaling\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255.,)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=directory_train,\n",
    "        batch_size=batch_size,   \n",
    "        color_mode='grayscale',\n",
    "        #save_to_dir='synt_aug/',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        directory=directory_val,\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=directory_test,\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    " \n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        verbose=verbose,\n",
    "        workers=1,#f you want multiprocessing change it\n",
    "        use_multiprocessing=False,)\n",
    "    \n",
    "    score, acc = model.evaluate_generator(generator=test_generator, steps=nb_test_samples, verbose = 1)\n",
    "    print('Score is', score, acc)\n",
    "    \n",
    "    return history, [score, acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose architecture\n",
    "#### First iteration\n",
    "\n",
    "Architectures:\n",
    "\n",
    "    1) CONV - POOL - DENSE - OUTPUT\n",
    "    2) CONV - CONV - POOL - DENSE - OUTPUT\n",
    "    3) CONV - CONV - CONV - POOL - DENSE - OUTPUT\n",
    "Here we dont use any regularizers, normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (32,32,1)\n",
    "models = []\n",
    "models.append(Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]))\n",
    "\n",
    "models.append(Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]))\n",
    "\n",
    "models.append(Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "200/200 [==============================] - 2s 11ms/step\n",
      "Score is 0.204753845501 0.923113810742\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "200/200 [==============================] - 2s 11ms/step\n",
      "Score is 0.18087388189 0.937180306905\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "200/200 [==============================] - 2s 11ms/step\n",
      "Score is 0.176490883929 0.955242966752\n",
      "[0.92311381074168797, 0.9371803069053708, 0.95524296675191811]\n",
      "The best model is model  3\n"
     ]
    }
   ],
   "source": [
    "scorelist = []\n",
    "for model in models:\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    history, score = datagen(model,'./Synthetic_dataset/train', './Synthetic_dataset/val', './Synthetic_dataset/test',\\\n",
    "                      verbose=0, img_size=(32,32), batch_size=32, epochs=30, nb_train_samples=1000,\\\n",
    "                      nb_validation_samples=200, nb_test_samples = 200)\n",
    "    scorelist.append(score[1])\n",
    "print(scorelist)\n",
    "argmax = np.argmax(scorelist)\n",
    "print('The best model is model ', argmax+1)\n",
    "model = models[argmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use BatchNormalization and Dropout.\n",
    "Parameters will be tuning:\n",
    "\n",
    "    dropout_1 -- uniform in [0, 1]\n",
    "    dropout_2 -- uniform in [0, 1]\n",
    "    second_conv -- adds conv - pool before dense\n",
    "    second_dense -- adds one more dense \n",
    "    dense_units -- choice in [32, 64, 128]\n",
    "    \n",
    "Batch size equals 32, it is good choice for this task.\n",
    "\n",
    "For net tunning we will take model 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use hyperas for hyperparameters tunning.\n",
    "There are some preparations for hyperas usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from PIL import Image, ImageDraw, ImageFont\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import ttfquery.findsystem\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import string\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import ntpath\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import glob\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import fetch_20newsgroups\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Activation, Dropout, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.normalization import BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D, ActivityRegularization, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.backend import resize_images, reshape\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD, Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'conv_second': hp.choice('conv_second', ['yes', 'no']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [32, 64, 128, 256]),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'conv_second_1': hp.choice('conv_second_1', ['yes', 'no']),\n",
      "        'Dense_1': hp.choice('Dense_1', [32, 64, 128, 256]),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: img_size = (32, 32)\n",
      "  3: train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
      "  4: test_datagen = ImageDataGenerator(rescale = 1./255.,)\n",
      "  5: \n",
      "  6: train_generator = train_datagen.flow_from_directory(\n",
      "  7:     directory='./Synthetic_dataset/train',\n",
      "  8:     batch_size=32,   \n",
      "  9:     color_mode='grayscale',\n",
      " 10:     target_size=img_size)\n",
      " 11: \n",
      " 12: validation_generator = test_datagen.flow_from_directory(\n",
      " 13:     directory='./Synthetic_dataset/val',\n",
      " 14:     batch_size=32,\n",
      " 15:     color_mode='grayscale',\n",
      " 16:     target_size=img_size)\n",
      " 17: \n",
      " 18: test_generator = test_datagen.flow_from_directory(\n",
      " 19:     directory='./Synthetic_dataset/test',\n",
      " 20:     batch_size=32,\n",
      " 21:     color_mode='grayscale',\n",
      " 22:     target_size=img_size)\n",
      " 23: \n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     nb_train_samples = 1000\n",
      "   5:     nb_validation_samples = 200\n",
      "   6:     nb_test_samples = 200\n",
      "   7:     epochs = 30\n",
      "   8:     batch_size = 32\n",
      "   9:     \n",
      "  10:     model = Sequential()\n",
      "  11:     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
      "  12:     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
      "  13:     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
      "  14:     model.add(BatchNormalization())\n",
      "  15:     model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
      "  16:     model.add(Dropout(space['Dropout']))\n",
      "  17:     \n",
      "  18:     conv_second = space['conv_second']\n",
      "  19:     if conv_second == 'yes':\n",
      "  20:         model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
      "  21:         model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
      "  22:         model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
      "  23:         model.add(BatchNormalization())\n",
      "  24:         model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
      "  25:         model.add(Dropout(space['Dropout_1']))\n",
      "  26:     \n",
      "  27:     model.add(Flatten())\n",
      "  28:     model.add(Dense(space['Dense'], activation='relu'))\n",
      "  29:     model.add(BatchNormalization())\n",
      "  30:     model.add(Dropout(space['Dropout_2']))\n",
      "  31:     \n",
      "  32:     dense_second = space['conv_second_1']\n",
      "  33:     if dense_second == 'yes':\n",
      "  34:         model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "  35:         model.add(BatchNormalization())\n",
      "  36:         model.add(Dropout(space['Dropout_3']))\n",
      "  37:     \n",
      "  38:     model.add(Dense(10, activation='softmax'))\n",
      "  39:         \n",
      "  40:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "  41: \n",
      "  42:     model.fit_generator(\n",
      "  43:         train_generator,\n",
      "  44:         steps_per_epoch=nb_train_samples // batch_size,\n",
      "  45:         epochs=epochs,\n",
      "  46:         validation_data=validation_generator,\n",
      "  47:         validation_steps=nb_validation_samples // batch_size,\n",
      "  48:         verbose=1,\n",
      "  49:         workers=1,#f you want multiprocessing change it\n",
      "  50:         use_multiprocessing=False,)\n",
      "  51:     \n",
      "  52:     score, acc = model.evaluate_generator(generator=test_generator, steps=nb_test_samples, verbose = 1)\n",
      "  53:     print('Test accuracy:', acc)\n",
      "  54:     \n",
      "  55:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  56: \n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 4.0306 - acc: 0.1018 - val_loss: 2.1729 - val_acc: 0.2135\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 3.6072 - acc: 0.1422 - val_loss: 1.9536 - val_acc: 0.3177\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.2106 - acc: 0.1543 - val_loss: 2.1580 - val_acc: 0.2240\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.8047 - acc: 0.1935 - val_loss: 3.7731 - val_acc: 0.1146\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.8344 - acc: 0.1815 - val_loss: 3.9541 - val_acc: 0.1250\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.5119 - acc: 0.2078 - val_loss: 4.9620 - val_acc: 0.0774\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.3385 - acc: 0.2319 - val_loss: 3.8934 - val_acc: 0.1771\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.1333 - acc: 0.2913 - val_loss: 2.7953 - val_acc: 0.2135\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.2291 - acc: 0.2581 - val_loss: 2.4446 - val_acc: 0.2604\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9936 - acc: 0.3287 - val_loss: 1.7902 - val_acc: 0.2865\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.0339 - acc: 0.2892 - val_loss: 1.6853 - val_acc: 0.3869\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9309 - acc: 0.3306 - val_loss: 1.3568 - val_acc: 0.4427\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8348 - acc: 0.3467 - val_loss: 1.7465 - val_acc: 0.3177\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8534 - acc: 0.3217 - val_loss: 1.5668 - val_acc: 0.3906\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7581 - acc: 0.3620 - val_loss: 1.4969 - val_acc: 0.4010\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8506 - acc: 0.3197 - val_loss: 1.2212 - val_acc: 0.5357\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7323 - acc: 0.3741 - val_loss: 1.4652 - val_acc: 0.4427\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6548 - acc: 0.3793 - val_loss: 1.3263 - val_acc: 0.5052\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6841 - acc: 0.3843 - val_loss: 1.6069 - val_acc: 0.3646\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6506 - acc: 0.3800 - val_loss: 1.6193 - val_acc: 0.3542\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5737 - acc: 0.4226 - val_loss: 1.3819 - val_acc: 0.4323\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5827 - acc: 0.4173 - val_loss: 1.0673 - val_acc: 0.6548\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5676 - acc: 0.4304 - val_loss: 1.3708 - val_acc: 0.4792\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5321 - acc: 0.4144 - val_loss: 1.7007 - val_acc: 0.3177\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4614 - acc: 0.4691 - val_loss: 1.3305 - val_acc: 0.5260\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4089 - acc: 0.4759 - val_loss: 1.4300 - val_acc: 0.4375\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4112 - acc: 0.4567 - val_loss: 1.5630 - val_acc: 0.3750\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3945 - acc: 0.4790 - val_loss: 1.0662 - val_acc: 0.6354\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3837 - acc: 0.4918 - val_loss: 0.9923 - val_acc: 0.6823\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3487 - acc: 0.4827 - val_loss: 0.9912 - val_acc: 0.6406\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.658088235294\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 5.7461 - acc: 0.0938 - val_loss: 2.5645 - val_acc: 0.0833\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 5.7934 - acc: 0.1048 - val_loss: 2.5160 - val_acc: 0.1250\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 5.4562 - acc: 0.1047 - val_loss: 2.4664 - val_acc: 0.1250\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 5.0474 - acc: 0.1017 - val_loss: 2.4370 - val_acc: 0.0990\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 4.7684 - acc: 0.0847 - val_loss: 2.4855 - val_acc: 0.1042\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 4.8003 - acc: 0.0958 - val_loss: 2.4624 - val_acc: 0.0938\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 4.5646 - acc: 0.0907 - val_loss: 2.4909 - val_acc: 0.0952\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 4.2468 - acc: 0.0978 - val_loss: 2.4388 - val_acc: 0.0990\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 3.9519 - acc: 0.1107 - val_loss: 2.3438 - val_acc: 0.1250\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 3.7332 - acc: 0.1270 - val_loss: 2.3811 - val_acc: 0.0833\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.6264 - acc: 0.1069 - val_loss: 2.3271 - val_acc: 0.0990\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.4402 - acc: 0.1027 - val_loss: 2.3232 - val_acc: 0.1548\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 3.3808 - acc: 0.1068 - val_loss: 2.3646 - val_acc: 0.0781\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 3.3094 - acc: 0.1179 - val_loss: 2.3806 - val_acc: 0.0729\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 3.2414 - acc: 0.1028 - val_loss: 2.2975 - val_acc: 0.1406\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.9574 - acc: 0.1278 - val_loss: 2.3673 - val_acc: 0.0885\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.9545 - acc: 0.1218 - val_loss: 2.3361 - val_acc: 0.0952\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.8423 - acc: 0.1147 - val_loss: 2.3450 - val_acc: 0.0885\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.7784 - acc: 0.1240 - val_loss: 2.3174 - val_acc: 0.1250\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.7733 - acc: 0.1028 - val_loss: 2.3406 - val_acc: 0.0885\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.7026 - acc: 0.1150 - val_loss: 2.3254 - val_acc: 0.0833\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.5842 - acc: 0.1310 - val_loss: 2.3219 - val_acc: 0.1198\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5405 - acc: 0.1099 - val_loss: 2.3463 - val_acc: 0.0774\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5192 - acc: 0.1210 - val_loss: 2.3398 - val_acc: 0.0729\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4653 - acc: 0.1201 - val_loss: 2.3173 - val_acc: 0.1406\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3734 - acc: 0.1352 - val_loss: 2.3312 - val_acc: 0.0885\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3579 - acc: 0.1381 - val_loss: 2.3225 - val_acc: 0.1250\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.2654 - acc: 0.1473 - val_loss: 2.3584 - val_acc: 0.0714\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.2727 - acc: 0.1673 - val_loss: 2.3212 - val_acc: 0.1042\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.2401 - acc: 0.1936 - val_loss: 2.3026 - val_acc: 0.1354\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.100223785166\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 9.1724 - acc: 0.0957 - val_loss: 2.4645 - val_acc: 0.0990\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 7.9386 - acc: 0.1068 - val_loss: 3.4195 - val_acc: 0.0536\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 6.7238 - acc: 0.1160 - val_loss: 2.8080 - val_acc: 0.1406\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 5.7896 - acc: 0.1290 - val_loss: 3.3609 - val_acc: 0.1042\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 5.7017 - acc: 0.1200 - val_loss: 2.6371 - val_acc: 0.1198\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 5.2612 - acc: 0.1049 - val_loss: 3.0410 - val_acc: 0.1250\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 4.6284 - acc: 0.0937 - val_loss: 2.5994 - val_acc: 0.1979\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 4.0157 - acc: 0.1210 - val_loss: 3.7637 - val_acc: 0.1667\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 3.8326 - acc: 0.1240 - val_loss: 9.4772 - val_acc: 0.1510\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 3.3537 - acc: 0.1472 - val_loss: 10.2505 - val_acc: 0.1719\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 3.1592 - acc: 0.1301 - val_loss: 2.9266 - val_acc: 0.0990\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 3.0196 - acc: 0.1261 - val_loss: 3.2779 - val_acc: 0.2188\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.8531 - acc: 0.1271 - val_loss: 6.9673 - val_acc: 0.1131\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.7115 - acc: 0.1795 - val_loss: 3.9084 - val_acc: 0.1719\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.7073 - acc: 0.1471 - val_loss: 7.3821 - val_acc: 0.1302\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.6485 - acc: 0.1592 - val_loss: 5.9159 - val_acc: 0.1667\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.4481 - acc: 0.1532 - val_loss: 7.2331 - val_acc: 0.2031\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4606 - acc: 0.1543 - val_loss: 10.1534 - val_acc: 0.1607\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5574 - acc: 0.1271 - val_loss: 10.2228 - val_acc: 0.1615\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5119 - acc: 0.1472 - val_loss: 5.6901 - val_acc: 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4117 - acc: 0.1614 - val_loss: 5.9829 - val_acc: 0.1250\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.3936 - acc: 0.1453 - val_loss: 9.2231 - val_acc: 0.1198\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.2932 - acc: 0.1673 - val_loss: 4.1794 - val_acc: 0.1615\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.3276 - acc: 0.1691 - val_loss: 2.3200 - val_acc: 0.1845\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4105 - acc: 0.1633 - val_loss: 2.1191 - val_acc: 0.2500\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.2730 - acc: 0.1997 - val_loss: 7.9993 - val_acc: 0.2240\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3201 - acc: 0.1804 - val_loss: 7.4053 - val_acc: 0.2188\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.2404 - acc: 0.1684 - val_loss: 4.5573 - val_acc: 0.2083\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1898 - acc: 0.1785 - val_loss: 2.0712 - val_acc: 0.2262\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.2058 - acc: 0.1624 - val_loss: 2.0641 - val_acc: 0.2240\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.186381074169\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 3.2430 - acc: 0.0987 - val_loss: 2.3967 - val_acc: 0.2083\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0806 - acc: 0.1088 - val_loss: 2.4122 - val_acc: 0.1250\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.0143 - acc: 0.1109 - val_loss: 2.3347 - val_acc: 0.1607\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.7992 - acc: 0.1288 - val_loss: 2.3554 - val_acc: 0.0938\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.7435 - acc: 0.1120 - val_loss: 2.2190 - val_acc: 0.1406\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.6224 - acc: 0.1322 - val_loss: 2.0374 - val_acc: 0.2292\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4832 - acc: 0.1735 - val_loss: 2.2258 - val_acc: 0.2344\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4345 - acc: 0.1743 - val_loss: 2.5632 - val_acc: 0.1667\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3448 - acc: 0.1904 - val_loss: 2.6170 - val_acc: 0.1726\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3141 - acc: 0.2076 - val_loss: 2.1563 - val_acc: 0.2031\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1455 - acc: 0.2680 - val_loss: 1.9417 - val_acc: 0.2292\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1368 - acc: 0.2719 - val_loss: 1.6599 - val_acc: 0.3646\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.0795 - acc: 0.2490 - val_loss: 1.7379 - val_acc: 0.2865\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1034 - acc: 0.2521 - val_loss: 1.6616 - val_acc: 0.3690\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.0139 - acc: 0.2773 - val_loss: 1.7622 - val_acc: 0.3073\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9958 - acc: 0.2732 - val_loss: 1.6501 - val_acc: 0.3333\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9214 - acc: 0.2995 - val_loss: 1.5154 - val_acc: 0.4010\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9052 - acc: 0.2924 - val_loss: 1.6494 - val_acc: 0.3854\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9007 - acc: 0.2915 - val_loss: 1.5769 - val_acc: 0.4048\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8765 - acc: 0.3134 - val_loss: 1.5762 - val_acc: 0.3646\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8626 - acc: 0.3235 - val_loss: 2.0755 - val_acc: 0.2135\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8376 - acc: 0.3258 - val_loss: 1.6980 - val_acc: 0.3490\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8186 - acc: 0.3508 - val_loss: 1.4434 - val_acc: 0.4479\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7715 - acc: 0.3287 - val_loss: 1.5485 - val_acc: 0.4531\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7922 - acc: 0.3338 - val_loss: 1.5837 - val_acc: 0.3869\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7301 - acc: 0.3747 - val_loss: 1.4535 - val_acc: 0.4635\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7203 - acc: 0.3667 - val_loss: 1.4831 - val_acc: 0.5104\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7398 - acc: 0.3579 - val_loss: 1.5512 - val_acc: 0.4531\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7021 - acc: 0.3841 - val_loss: 1.4126 - val_acc: 0.4427\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7318 - acc: 0.3709 - val_loss: 1.4562 - val_acc: 0.4345\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.402920410783\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 2.5484 - acc: 0.2205 - val_loss: 3.8198 - val_acc: 0.2865\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.9540 - acc: 0.3639 - val_loss: 2.7915 - val_acc: 0.3021\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6169 - acc: 0.4426 - val_loss: 1.9111 - val_acc: 0.3542\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4813 - acc: 0.4940 - val_loss: 1.1711 - val_acc: 0.5655\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4764 - acc: 0.4771 - val_loss: 4.5598 - val_acc: 0.2656\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3017 - acc: 0.5413 - val_loss: 5.8459 - val_acc: 0.2865\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1842 - acc: 0.5818 - val_loss: 2.0619 - val_acc: 0.4375\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.0743 - acc: 0.6150 - val_loss: 1.6354 - val_acc: 0.4740\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.9521 - acc: 0.6465 - val_loss: 2.5009 - val_acc: 0.3646\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.8463 - acc: 0.7007 - val_loss: 1.7395 - val_acc: 0.4940\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6958 - acc: 0.7450 - val_loss: 2.0910 - val_acc: 0.4375\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6545 - acc: 0.7625 - val_loss: 2.3181 - val_acc: 0.3594\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6339 - acc: 0.7915 - val_loss: 4.2189 - val_acc: 0.2865\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5419 - acc: 0.8084 - val_loss: 0.3526 - val_acc: 0.8750\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4469 - acc: 0.8700 - val_loss: 1.8272 - val_acc: 0.4286\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.4616 - acc: 0.8427 - val_loss: 1.4137 - val_acc: 0.5938\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4006 - acc: 0.8609 - val_loss: 1.4339 - val_acc: 0.5521\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3456 - acc: 0.8892 - val_loss: 0.6359 - val_acc: 0.8177\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2720 - acc: 0.9102 - val_loss: 0.4772 - val_acc: 0.8542\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.2824 - acc: 0.9073 - val_loss: 0.3725 - val_acc: 0.8690\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2582 - acc: 0.9204 - val_loss: 0.7921 - val_acc: 0.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2933 - acc: 0.9004 - val_loss: 0.5084 - val_acc: 0.8698\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2269 - acc: 0.9144 - val_loss: 1.0392 - val_acc: 0.7240\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1888 - acc: 0.9516 - val_loss: 1.3001 - val_acc: 0.6354\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2191 - acc: 0.9335 - val_loss: 0.4690 - val_acc: 0.8333\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2110 - acc: 0.9307 - val_loss: 0.9967 - val_acc: 0.6667\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1903 - acc: 0.9415 - val_loss: 0.1698 - val_acc: 0.9479\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2090 - acc: 0.9326 - val_loss: 0.3388 - val_acc: 0.9167\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1428 - acc: 0.9576 - val_loss: 0.7696 - val_acc: 0.7760\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1423 - acc: 0.9548 - val_loss: 0.3902 - val_acc: 0.8802\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.86668797954\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 75ms/step - loss: 2.6638 - acc: 0.2471 - val_loss: 5.8219 - val_acc: 0.1094\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.7037 - acc: 0.4425 - val_loss: 1.7054 - val_acc: 0.4688\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2427 - acc: 0.5766 - val_loss: 1.3706 - val_acc: 0.5781\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9308 - acc: 0.6706 - val_loss: 3.8621 - val_acc: 0.3281\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.7304 - acc: 0.7339 - val_loss: 1.9843 - val_acc: 0.4107\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6121 - acc: 0.7833 - val_loss: 0.4925 - val_acc: 0.8177\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4657 - acc: 0.8397 - val_loss: 1.6053 - val_acc: 0.5208\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3553 - acc: 0.8779 - val_loss: 0.3226 - val_acc: 0.9062\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3254 - acc: 0.8961 - val_loss: 0.1135 - val_acc: 0.9740\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2741 - acc: 0.9084 - val_loss: 0.2349 - val_acc: 0.9323\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2423 - acc: 0.9265 - val_loss: 0.6944 - val_acc: 0.7679\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2355 - acc: 0.9187 - val_loss: 0.5624 - val_acc: 0.8229\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1852 - acc: 0.9425 - val_loss: 0.2786 - val_acc: 0.9219\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1695 - acc: 0.9507 - val_loss: 0.2744 - val_acc: 0.8906\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1369 - acc: 0.9566 - val_loss: 0.1465 - val_acc: 0.9740\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1221 - acc: 0.9618 - val_loss: 0.1725 - val_acc: 0.9464\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0876 - acc: 0.9729 - val_loss: 0.0876 - val_acc: 0.9792\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1051 - acc: 0.9668 - val_loss: 0.0459 - val_acc: 0.9948\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0971 - acc: 0.9660 - val_loss: 0.2000 - val_acc: 0.9531\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1091 - acc: 0.9687 - val_loss: 0.4789 - val_acc: 0.8281\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0698 - acc: 0.9819 - val_loss: 0.2870 - val_acc: 0.9345\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1142 - acc: 0.9627 - val_loss: 0.3096 - val_acc: 0.9219\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1035 - acc: 0.9578 - val_loss: 0.3777 - val_acc: 0.8750\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0665 - acc: 0.9808 - val_loss: 0.1748 - val_acc: 0.9635\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0769 - acc: 0.9748 - val_loss: 0.0752 - val_acc: 0.9688\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0811 - acc: 0.9749 - val_loss: 0.0469 - val_acc: 0.9896\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0669 - acc: 0.9799 - val_loss: 0.2934 - val_acc: 0.9048\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0787 - acc: 0.9728 - val_loss: 0.2318 - val_acc: 0.9062\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0503 - acc: 0.9869 - val_loss: 0.0639 - val_acc: 0.9740\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0446 - acc: 0.9889 - val_loss: 0.1290 - val_acc: 0.9635\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.976662404092\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 1.9783 - acc: 0.3449 - val_loss: 2.5269 - val_acc: 0.3214\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.0252 - acc: 0.6614 - val_loss: 0.9347 - val_acc: 0.6719\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.7371 - acc: 0.7705 - val_loss: 4.1544 - val_acc: 0.3854\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5399 - acc: 0.8603 - val_loss: 0.5373 - val_acc: 0.8385\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3640 - acc: 0.9437 - val_loss: 0.4003 - val_acc: 0.8958\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2616 - acc: 0.9667 - val_loss: 0.3954 - val_acc: 0.9167\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2238 - acc: 0.9768 - val_loss: 0.3396 - val_acc: 0.9375\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2034 - acc: 0.9758 - val_loss: 0.4799 - val_acc: 0.8333\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1731 - acc: 0.9780 - val_loss: 0.2534 - val_acc: 0.9219\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1311 - acc: 0.9909 - val_loss: 0.2888 - val_acc: 0.8958\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1198 - acc: 0.9919 - val_loss: 0.2337 - val_acc: 0.9427\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0946 - acc: 0.9950 - val_loss: 0.2731 - val_acc: 0.9286\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0894 - acc: 0.9900 - val_loss: 0.2339 - val_acc: 0.9635\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0819 - acc: 0.9980 - val_loss: 0.2151 - val_acc: 0.9531\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0656 - acc: 0.9970 - val_loss: 0.3143 - val_acc: 0.8958\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0693 - acc: 0.9939 - val_loss: 0.2715 - val_acc: 0.9219\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0538 - acc: 0.9980 - val_loss: 0.2529 - val_acc: 0.9286\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0506 - acc: 0.9990 - val_loss: 0.1079 - val_acc: 0.9688\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0473 - acc: 0.9990 - val_loss: 0.1029 - val_acc: 0.9688\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0442 - acc: 0.9970 - val_loss: 0.2822 - val_acc: 0.9219\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 0.9635\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9583\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0368 - acc: 0.9980 - val_loss: 0.2794 - val_acc: 0.8958\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0277 - acc: 0.9980 - val_loss: 0.1473 - val_acc: 0.9688\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.1249 - val_acc: 0.9635\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9635\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0229 - acc: 0.9990 - val_loss: 0.0685 - val_acc: 0.9821\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0232 - acc: 0.9990 - val_loss: 0.1784 - val_acc: 0.9375\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9740\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.986413043478\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 2.0702 - acc: 0.3077 - val_loss: 4.4367 - val_acc: 0.1979\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.2419 - acc: 0.5666 - val_loss: 1.0069 - val_acc: 0.6964\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8000 - acc: 0.7350 - val_loss: 0.7497 - val_acc: 0.7812\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5674 - acc: 0.8185 - val_loss: 1.2997 - val_acc: 0.5885\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4063 - acc: 0.8740 - val_loss: 1.3184 - val_acc: 0.5677\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2828 - acc: 0.9153 - val_loss: 0.3837 - val_acc: 0.8802\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2921 - acc: 0.9033 - val_loss: 0.5001 - val_acc: 0.8452\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2032 - acc: 0.9436 - val_loss: 0.2127 - val_acc: 0.9271\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1491 - acc: 0.9588 - val_loss: 0.3248 - val_acc: 0.9062\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1840 - acc: 0.9377 - val_loss: 3.9199 - val_acc: 0.3854\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1561 - acc: 0.9485 - val_loss: 1.9186 - val_acc: 0.5208\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0886 - acc: 0.9759 - val_loss: 0.3346 - val_acc: 0.8802\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1044 - acc: 0.9639 - val_loss: 1.6479 - val_acc: 0.5833\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0685 - acc: 0.9859 - val_loss: 0.5958 - val_acc: 0.8542\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0890 - acc: 0.9769 - val_loss: 0.4512 - val_acc: 0.8698\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0722 - acc: 0.9798 - val_loss: 0.1130 - val_acc: 0.9531\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0616 - acc: 0.9839 - val_loss: 0.0822 - val_acc: 0.9792\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0618 - acc: 0.9819 - val_loss: 0.3583 - val_acc: 0.9167\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0598 - acc: 0.9860 - val_loss: 0.1703 - val_acc: 0.9531\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0497 - acc: 0.9829 - val_loss: 0.1240 - val_acc: 0.9479\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0447 - acc: 0.9840 - val_loss: 0.0936 - val_acc: 0.9740\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0473 - acc: 0.9850 - val_loss: 0.3704 - val_acc: 0.8802\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0483 - acc: 0.9889 - val_loss: 0.3070 - val_acc: 0.8690\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0467 - acc: 0.9869 - val_loss: 0.2555 - val_acc: 0.9219\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0211 - acc: 0.9960 - val_loss: 0.0506 - val_acc: 0.9792\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0214 - acc: 0.9950 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0214 - acc: 0.9970 - val_loss: 0.3283 - val_acc: 0.9271\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0433 - acc: 0.9869 - val_loss: 0.2245 - val_acc: 0.9219\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0219 - acc: 0.9950 - val_loss: 0.0893 - val_acc: 0.9762\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0129 - acc: 0.9980 - val_loss: 0.0736 - val_acc: 0.9792\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.984114249037\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 80ms/step - loss: 6.2498 - acc: 0.1090 - val_loss: 4.8971 - val_acc: 0.1927\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 5.4769 - acc: 0.1391 - val_loss: 2.1901 - val_acc: 0.3125\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 4.7894 - acc: 0.1765 - val_loss: 6.7524 - val_acc: 0.2143\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 4.5125 - acc: 0.1886 - val_loss: 6.5698 - val_acc: 0.1927\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 4.0324 - acc: 0.2178 - val_loss: 2.9210 - val_acc: 0.2604\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 3.3776 - acc: 0.2480 - val_loss: 4.6984 - val_acc: 0.2083\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 3.0345 - acc: 0.2724 - val_loss: 6.4969 - val_acc: 0.2083\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.6556 - acc: 0.3066 - val_loss: 2.8021 - val_acc: 0.3036\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.5190 - acc: 0.3359 - val_loss: 1.3838 - val_acc: 0.4844\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.2443 - acc: 0.3557 - val_loss: 1.0891 - val_acc: 0.5833\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.2672 - acc: 0.3541 - val_loss: 0.9544 - val_acc: 0.6198\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.1145 - acc: 0.3729 - val_loss: 0.9654 - val_acc: 0.6510\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9900 - acc: 0.3992 - val_loss: 2.3917 - val_acc: 0.3646\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7791 - acc: 0.4235 - val_loss: 1.3438 - val_acc: 0.4940\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7183 - acc: 0.4507 - val_loss: 1.8748 - val_acc: 0.4062\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6860 - acc: 0.4364 - val_loss: 0.7338 - val_acc: 0.7344\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5625 - acc: 0.4851 - val_loss: 0.7947 - val_acc: 0.7552\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5169 - acc: 0.4912 - val_loss: 0.9403 - val_acc: 0.6510\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4426 - acc: 0.4951 - val_loss: 3.8086 - val_acc: 0.2857\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4673 - acc: 0.5061 - val_loss: 1.8146 - val_acc: 0.3073\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4304 - acc: 0.4951 - val_loss: 0.9224 - val_acc: 0.6719\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3746 - acc: 0.5182 - val_loss: 1.2198 - val_acc: 0.5469\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2964 - acc: 0.5535 - val_loss: 0.8242 - val_acc: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2270 - acc: 0.5405 - val_loss: 0.7475 - val_acc: 0.7857\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2224 - acc: 0.5645 - val_loss: 0.6972 - val_acc: 0.8073\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1731 - acc: 0.5766 - val_loss: 0.5272 - val_acc: 0.8854\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1274 - acc: 0.6120 - val_loss: 0.6385 - val_acc: 0.8646\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1268 - acc: 0.5807 - val_loss: 0.5854 - val_acc: 0.8594\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0854 - acc: 0.6039 - val_loss: 1.6936 - val_acc: 0.4219\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0864 - acc: 0.6049 - val_loss: 0.6017 - val_acc: 0.8571\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.834079283887\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 94ms/step - loss: 2.4635 - acc: 0.2053 - val_loss: 2.2597 - val_acc: 0.2344\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7581 - acc: 0.3880 - val_loss: 2.4002 - val_acc: 0.2760\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4485 - acc: 0.4979 - val_loss: 1.9690 - val_acc: 0.3854\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2209 - acc: 0.5575 - val_loss: 1.2455 - val_acc: 0.5833\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0072 - acc: 0.6462 - val_loss: 0.9315 - val_acc: 0.6771\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9692 - acc: 0.6776 - val_loss: 1.5272 - val_acc: 0.5208\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8089 - acc: 0.7240 - val_loss: 1.4188 - val_acc: 0.5312\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6291 - acc: 0.8004 - val_loss: 2.1477 - val_acc: 0.4479\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5718 - acc: 0.8138 - val_loss: 2.2912 - val_acc: 0.2976\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4823 - acc: 0.8457 - val_loss: 1.6202 - val_acc: 0.5312\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4599 - acc: 0.8650 - val_loss: 0.6704 - val_acc: 0.7240\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3993 - acc: 0.8679 - val_loss: 0.3505 - val_acc: 0.8854\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3373 - acc: 0.8880 - val_loss: 1.4437 - val_acc: 0.5781\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3149 - acc: 0.9044 - val_loss: 1.0708 - val_acc: 0.5677\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4011 - acc: 0.8602 - val_loss: 0.4223 - val_acc: 0.8869\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2956 - acc: 0.9102 - val_loss: 1.2612 - val_acc: 0.6198\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2643 - acc: 0.9276 - val_loss: 0.2497 - val_acc: 0.9219\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2152 - acc: 0.9416 - val_loss: 0.1940 - val_acc: 0.9427\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2182 - acc: 0.9325 - val_loss: 0.3600 - val_acc: 0.9010\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2145 - acc: 0.9426 - val_loss: 0.9515 - val_acc: 0.6726\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1664 - acc: 0.9537 - val_loss: 0.2830 - val_acc: 0.9010\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1484 - acc: 0.9546 - val_loss: 0.1081 - val_acc: 0.9635\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1378 - acc: 0.9627 - val_loss: 0.3063 - val_acc: 0.9219\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1281 - acc: 0.9688 - val_loss: 0.3991 - val_acc: 0.8854\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1642 - acc: 0.9568 - val_loss: 1.3994 - val_acc: 0.6310\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1344 - acc: 0.9648 - val_loss: 0.3054 - val_acc: 0.8958\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1552 - acc: 0.9528 - val_loss: 0.3152 - val_acc: 0.9010\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1263 - acc: 0.9617 - val_loss: 0.3304 - val_acc: 0.9010\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1397 - acc: 0.9619 - val_loss: 0.2603 - val_acc: 0.9271\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1133 - acc: 0.9698 - val_loss: 3.0733 - val_acc: 0.4792\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.462915601023\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 76ms/step - loss: 2.3619 - acc: 0.3061 - val_loss: 3.3835 - val_acc: 0.1979\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3728 - acc: 0.5443 - val_loss: 2.7160 - val_acc: 0.2656\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9787 - acc: 0.6673 - val_loss: 1.0749 - val_acc: 0.6354\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7109 - acc: 0.7831 - val_loss: 0.5602 - val_acc: 0.8125\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5640 - acc: 0.8215 - val_loss: 0.3594 - val_acc: 0.9048\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4642 - acc: 0.8649 - val_loss: 0.2606 - val_acc: 0.9219\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4507 - acc: 0.8641 - val_loss: 0.2181 - val_acc: 0.9375\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3563 - acc: 0.8972 - val_loss: 0.2503 - val_acc: 0.9323\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2931 - acc: 0.9056 - val_loss: 0.2438 - val_acc: 0.9375\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2655 - acc: 0.9276 - val_loss: 0.3293 - val_acc: 0.8988\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2179 - acc: 0.9506 - val_loss: 0.1503 - val_acc: 0.9583\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1977 - acc: 0.9496 - val_loss: 0.0796 - val_acc: 0.9948\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1679 - acc: 0.9586 - val_loss: 0.3957 - val_acc: 0.8802\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1652 - acc: 0.9587 - val_loss: 0.3159 - val_acc: 0.9062\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1507 - acc: 0.9697 - val_loss: 0.1686 - val_acc: 0.9427\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1545 - acc: 0.9589 - val_loss: 0.0545 - val_acc: 0.9881\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1376 - acc: 0.9697 - val_loss: 0.3272 - val_acc: 0.8958\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1338 - acc: 0.9657 - val_loss: 0.2160 - val_acc: 0.9531\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1199 - acc: 0.9739 - val_loss: 0.1683 - val_acc: 0.9583\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1043 - acc: 0.9759 - val_loss: 0.1861 - val_acc: 0.9375\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0792 - acc: 0.9818 - val_loss: 0.2544 - val_acc: 0.9345\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0745 - acc: 0.9849 - val_loss: 0.0812 - val_acc: 0.9844\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0812 - acc: 0.9860 - val_loss: 0.0736 - val_acc: 0.9844\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0650 - acc: 0.9909 - val_loss: 0.0985 - val_acc: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0619 - acc: 0.9899 - val_loss: 0.2813 - val_acc: 0.9115\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0620 - acc: 0.9879 - val_loss: 0.1561 - val_acc: 0.9583\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0555 - acc: 0.9909 - val_loss: 0.1152 - val_acc: 0.9740\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0480 - acc: 0.9900 - val_loss: 0.2492 - val_acc: 0.9323\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0707 - acc: 0.9820 - val_loss: 0.0691 - val_acc: 0.9792\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0675 - acc: 0.9869 - val_loss: 0.0842 - val_acc: 0.9688\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.97946084724\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 94ms/step - loss: 6.9697 - acc: 0.1078 - val_loss: 6.4231 - val_acc: 0.1250\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 5.5418 - acc: 0.1218 - val_loss: 10.1292 - val_acc: 0.1302\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 4.7189 - acc: 0.1372 - val_loss: 4.4585 - val_acc: 0.2344\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 3.8999 - acc: 0.1742 - val_loss: 5.2192 - val_acc: 0.1562\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.7308 - acc: 0.149 - 1s 18ms/step - loss: 3.6970 - acc: 0.1544 - val_loss: 2.6330 - val_acc: 0.2031\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 3.2850 - acc: 0.1785 - val_loss: 2.5522 - val_acc: 0.1786\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.9911 - acc: 0.1855 - val_loss: 2.5790 - val_acc: 0.2708\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.6952 - acc: 0.2086 - val_loss: 2.2009 - val_acc: 0.3125\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.6746 - acc: 0.1875 - val_loss: 1.8896 - val_acc: 0.2656\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.5984 - acc: 0.1685 - val_loss: 6.4558 - val_acc: 0.1458\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.3775 - acc: 0.2056 - val_loss: 1.7550 - val_acc: 0.3155\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 2.4600 - acc: 0.1947 - val_loss: 2.2197 - val_acc: 0.1979\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.2914 - acc: 0.2257 - val_loss: 2.3395 - val_acc: 0.2552\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2992 - acc: 0.2230 - val_loss: 1.9526 - val_acc: 0.3021\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2261 - acc: 0.2218 - val_loss: 1.7947 - val_acc: 0.3906\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1963 - acc: 0.2146 - val_loss: 1.8485 - val_acc: 0.2448\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0771 - acc: 0.2510 - val_loss: 1.8104 - val_acc: 0.4048\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.0851 - acc: 0.2196 - val_loss: 1.7211 - val_acc: 0.4010\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1291 - acc: 0.2068 - val_loss: 3.9702 - val_acc: 0.2552\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2383 - acc: 0.2097 - val_loss: 5.7358 - val_acc: 0.1354\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.0613 - acc: 0.2487 - val_loss: 1.9476 - val_acc: 0.2760\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0045 - acc: 0.2640 - val_loss: 1.7678 - val_acc: 0.3452\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9627 - acc: 0.2417 - val_loss: 1.6613 - val_acc: 0.3750\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9732 - acc: 0.2650 - val_loss: 1.7965 - val_acc: 0.3594\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.9238 - acc: 0.2742 - val_loss: 1.8366 - val_acc: 0.4115\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9414 - acc: 0.2349 - val_loss: 1.5895 - val_acc: 0.4375\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.9259 - acc: 0.2792 - val_loss: 1.6255 - val_acc: 0.4405\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.8886 - acc: 0.2753 - val_loss: 1.5340 - val_acc: 0.4792\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9111 - acc: 0.2580 - val_loss: 1.5954 - val_acc: 0.4427\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.8595 - acc: 0.2902 - val_loss: 1.5830 - val_acc: 0.3906\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.394501278772\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 87ms/step - loss: 3.0366 - acc: 0.1634 - val_loss: 3.0774 - val_acc: 0.1615\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.3563 - acc: 0.2864 - val_loss: 2.4873 - val_acc: 0.3095\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9536 - acc: 0.3467 - val_loss: 1.3527 - val_acc: 0.4688\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6542 - acc: 0.4638 - val_loss: 1.1745 - val_acc: 0.5521\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.5040 - acc: 0.4819 - val_loss: 0.9722 - val_acc: 0.6094\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3321 - acc: 0.5413 - val_loss: 0.8808 - val_acc: 0.6719\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.2150 - acc: 0.5695 - val_loss: 0.8184 - val_acc: 0.7262\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.0748 - acc: 0.6121 - val_loss: 0.7038 - val_acc: 0.8281\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0337 - acc: 0.6433 - val_loss: 0.5380 - val_acc: 0.8438\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9339 - acc: 0.6601 - val_loss: 0.4810 - val_acc: 0.8646\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8546 - acc: 0.6856 - val_loss: 0.4699 - val_acc: 0.8698\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8553 - acc: 0.6996 - val_loss: 0.3679 - val_acc: 0.8810\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7378 - acc: 0.7461 - val_loss: 0.3888 - val_acc: 0.9062\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7323 - acc: 0.7540 - val_loss: 0.3810 - val_acc: 0.8906\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6355 - acc: 0.7792 - val_loss: 0.3292 - val_acc: 0.9167\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6561 - acc: 0.7812 - val_loss: 0.5950 - val_acc: 0.7760\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6114 - acc: 0.8015 - val_loss: 0.4815 - val_acc: 0.8542\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6122 - acc: 0.7945 - val_loss: 0.2859 - val_acc: 0.9286\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5202 - acc: 0.8208 - val_loss: 0.3269 - val_acc: 0.9115\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5952 - acc: 0.8136 - val_loss: 0.2377 - val_acc: 0.9583\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5106 - acc: 0.8345 - val_loss: 0.2519 - val_acc: 0.9219\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4869 - acc: 0.8348 - val_loss: 0.2699 - val_acc: 0.9427\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4627 - acc: 0.8428 - val_loss: 0.1752 - val_acc: 0.9643\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4600 - acc: 0.8529 - val_loss: 0.1638 - val_acc: 0.9688\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4009 - acc: 0.8710 - val_loss: 0.3600 - val_acc: 0.9010\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4040 - acc: 0.8640 - val_loss: 0.2713 - val_acc: 0.9271\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3630 - acc: 0.8880 - val_loss: 0.2279 - val_acc: 0.9479\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3384 - acc: 0.8983 - val_loss: 0.1731 - val_acc: 0.9643\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3709 - acc: 0.8741 - val_loss: 0.1830 - val_acc: 0.9479\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3406 - acc: 0.8890 - val_loss: 0.2155 - val_acc: 0.9375\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.930786445013\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 3.1421 - acc: 0.1130 - val_loss: 2.3369 - val_acc: 0.1458\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.8169 - acc: 0.1471 - val_loss: 2.9404 - val_acc: 0.1458\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.5791 - acc: 0.1895 - val_loss: 2.8153 - val_acc: 0.1786\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.4852 - acc: 0.1834 - val_loss: 2.6688 - val_acc: 0.1719\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.3334 - acc: 0.1915 - val_loss: 2.4639 - val_acc: 0.2708\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2562 - acc: 0.2409 - val_loss: 2.6058 - val_acc: 0.2188\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.1562 - acc: 0.2491 - val_loss: 2.1361 - val_acc: 0.2708\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.0715 - acc: 0.2721 - val_loss: 1.4982 - val_acc: 0.4583\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9420 - acc: 0.2964 - val_loss: 1.4413 - val_acc: 0.5208\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9743 - acc: 0.2884 - val_loss: 1.4806 - val_acc: 0.6042\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.8770 - acc: 0.3427 - val_loss: 1.3578 - val_acc: 0.5885\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.8182 - acc: 0.3446 - val_loss: 1.4230 - val_acc: 0.4740\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7939 - acc: 0.3439 - val_loss: 1.5933 - val_acc: 0.4405\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.7645 - acc: 0.3770 - val_loss: 3.3242 - val_acc: 0.0625\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.7385 - acc: 0.3891 - val_loss: 2.1078 - val_acc: 0.1458\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6907 - acc: 0.3763 - val_loss: 1.2859 - val_acc: 0.5885\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6794 - acc: 0.3942 - val_loss: 1.1843 - val_acc: 0.6562\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6050 - acc: 0.4163 - val_loss: 2.4404 - val_acc: 0.1719\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6108 - acc: 0.4154 - val_loss: 1.4838 - val_acc: 0.4583\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.5486 - acc: 0.4297 - val_loss: 1.0865 - val_acc: 0.7188\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.5085 - acc: 0.4608 - val_loss: 1.1027 - val_acc: 0.6510\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4586 - acc: 0.4477 - val_loss: 0.9601 - val_acc: 0.8177\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4176 - acc: 0.4920 - val_loss: 1.0228 - val_acc: 0.7448\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3869 - acc: 0.4990 - val_loss: 1.0016 - val_acc: 0.7679\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3662 - acc: 0.5083 - val_loss: 0.8756 - val_acc: 0.8281\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.3090 - acc: 0.5382 - val_loss: 1.0652 - val_acc: 0.6979\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.2572 - acc: 0.5504 - val_loss: 1.0944 - val_acc: 0.6771\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2569 - acc: 0.5444 - val_loss: 0.9564 - val_acc: 0.7135\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2664 - acc: 0.5455 - val_loss: 0.9180 - val_acc: 0.7024\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2405 - acc: 0.5504 - val_loss: 0.9267 - val_acc: 0.7292\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.739609974425\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 98ms/step - loss: 4.7122 - acc: 0.1654 - val_loss: 2.1524 - val_acc: 0.3594\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.4752 - acc: 0.2612 - val_loss: 1.8087 - val_acc: 0.4635\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.7254 - acc: 0.3315 - val_loss: 1.0433 - val_acc: 0.6094\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 2.3079 - acc: 0.3621 - val_loss: 1.1536 - val_acc: 0.5952\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.1548 - acc: 0.3934 - val_loss: 2.9322 - val_acc: 0.2031\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9576 - acc: 0.4145 - val_loss: 1.6222 - val_acc: 0.5052\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6213 - acc: 0.4789 - val_loss: 2.0509 - val_acc: 0.3490\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3935 - acc: 0.5150 - val_loss: 0.6458 - val_acc: 0.7708\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3363 - acc: 0.5353 - val_loss: 0.7808 - val_acc: 0.7976\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.2785 - acc: 0.5415 - val_loss: 0.8316 - val_acc: 0.6927\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.2316 - acc: 0.5818 - val_loss: 0.5571 - val_acc: 0.7865\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.1928 - acc: 0.6080 - val_loss: 0.8765 - val_acc: 0.6562\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.1433 - acc: 0.6092 - val_loss: 1.2948 - val_acc: 0.6667\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.9913 - acc: 0.6704 - val_loss: 0.5656 - val_acc: 0.8036\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9990 - acc: 0.6494 - val_loss: 0.3829 - val_acc: 0.9167\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8998 - acc: 0.6826 - val_loss: 0.2839 - val_acc: 0.9479\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8139 - acc: 0.6935 - val_loss: 0.2893 - val_acc: 0.9531\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7931 - acc: 0.7157 - val_loss: 0.4183 - val_acc: 0.8906\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.7637 - acc: 0.7420 - val_loss: 0.3140 - val_acc: 0.9323\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.7741 - acc: 0.7348 - val_loss: 1.5619 - val_acc: 0.5536\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.8417 - acc: 0.7129 - val_loss: 0.8676 - val_acc: 0.7448\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7982 - acc: 0.7117 - val_loss: 0.3004 - val_acc: 0.9375\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6708 - acc: 0.7773 - val_loss: 0.2561 - val_acc: 0.9531\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6221 - acc: 0.7853 - val_loss: 0.2401 - val_acc: 0.9427\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6163 - acc: 0.7883 - val_loss: 0.2643 - val_acc: 0.9405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6251 - acc: 0.7804 - val_loss: 0.2396 - val_acc: 0.9531\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5945 - acc: 0.7873 - val_loss: 0.2670 - val_acc: 0.9271\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5654 - acc: 0.8035 - val_loss: 0.1660 - val_acc: 0.9635\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.5387 - acc: 0.8023 - val_loss: 0.1459 - val_acc: 0.9844\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5612 - acc: 0.8006 - val_loss: 0.1427 - val_acc: 0.9881\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.980584082157\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 93ms/step - loss: 5.1388 - acc: 0.1300 - val_loss: 2.5976 - val_acc: 0.2031\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.4800 - acc: 0.2116 - val_loss: 3.5918 - val_acc: 0.1042\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.9318 - acc: 0.2472 - val_loss: 3.2587 - val_acc: 0.1979\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 2.4960 - acc: 0.2764 - val_loss: 1.9467 - val_acc: 0.3177\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.1016 - acc: 0.3276 - val_loss: 9.3748 - val_acc: 0.1310\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0979 - acc: 0.3278 - val_loss: 1.1572 - val_acc: 0.5312\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8151 - acc: 0.3831 - val_loss: 1.0358 - val_acc: 0.6510\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7604 - acc: 0.3970 - val_loss: 1.0035 - val_acc: 0.6875\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6058 - acc: 0.4244 - val_loss: 0.9872 - val_acc: 0.6510\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5161 - acc: 0.4506 - val_loss: 0.8252 - val_acc: 0.8214\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3946 - acc: 0.5017 - val_loss: 0.9194 - val_acc: 0.7344\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4023 - acc: 0.5038 - val_loss: 0.9907 - val_acc: 0.6510\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.3354 - acc: 0.5171 - val_loss: 0.7534 - val_acc: 0.8385\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3453 - acc: 0.5275 - val_loss: 0.5934 - val_acc: 0.8542\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2420 - acc: 0.5435 - val_loss: 0.5734 - val_acc: 0.8631\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1811 - acc: 0.5586 - val_loss: 0.6020 - val_acc: 0.8750\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1427 - acc: 0.5625 - val_loss: 0.8700 - val_acc: 0.7500\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1177 - acc: 0.5897 - val_loss: 0.5340 - val_acc: 0.8750\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1346 - acc: 0.5619 - val_loss: 0.5623 - val_acc: 0.8594\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1304 - acc: 0.5870 - val_loss: 0.4409 - val_acc: 0.9219\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0232 - acc: 0.6409 - val_loss: 0.5490 - val_acc: 0.8929\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9809 - acc: 0.6249 - val_loss: 0.3719 - val_acc: 0.9427\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9862 - acc: 0.6552 - val_loss: 0.3492 - val_acc: 0.9375\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9825 - acc: 0.6170 - val_loss: 0.3746 - val_acc: 0.9583\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9789 - acc: 0.6472 - val_loss: 0.3113 - val_acc: 0.9219\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9061 - acc: 0.6573 - val_loss: 0.3054 - val_acc: 0.9464\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8558 - acc: 0.6734 - val_loss: 0.2977 - val_acc: 0.9427\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8864 - acc: 0.6525 - val_loss: 0.3533 - val_acc: 0.9479\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8571 - acc: 0.6804 - val_loss: 0.2364 - val_acc: 0.9740\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8679 - acc: 0.6853 - val_loss: 0.3184 - val_acc: 0.9427\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.939098465473\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 94ms/step - loss: 1.7291 - acc: 0.3984 - val_loss: 1.7552 - val_acc: 0.4375\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.0138 - acc: 0.7027 - val_loss: 0.9641 - val_acc: 0.6250\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7206 - acc: 0.8249 - val_loss: 2.9222 - val_acc: 0.1458\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4394 - acc: 0.9325 - val_loss: 0.7455 - val_acc: 0.7865\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3187 - acc: 0.9498 - val_loss: 0.5384 - val_acc: 0.8281\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1980 - acc: 0.9859 - val_loss: 0.5768 - val_acc: 0.8036\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1505 - acc: 0.9849 - val_loss: 0.3400 - val_acc: 0.9115\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1064 - acc: 0.9980 - val_loss: 0.2189 - val_acc: 0.9479\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0730 - acc: 0.9980 - val_loss: 0.3235 - val_acc: 0.9271\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0680 - acc: 0.9990 - val_loss: 0.2341 - val_acc: 0.9479\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0466 - acc: 0.9990 - val_loss: 0.1424 - val_acc: 0.9762\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9740\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0364 - acc: 0.9990 - val_loss: 0.0916 - val_acc: 0.9896\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0334 - acc: 0.9990 - val_loss: 0.1248 - val_acc: 0.9792\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 0.9948\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0282 - acc: 0.9990 - val_loss: 0.1633 - val_acc: 0.9643\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9740\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9792\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9792\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9635\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9948\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0140 - acc: 0.9990 - val_loss: 0.1009 - val_acc: 0.9821\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9792\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 0.9844\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 0.9948\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1296 - val_acc: 0.9762\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0602 - val_acc: 0.9896\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 0.9792\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.991847826087\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 3.4807 - acc: 0.1401 - val_loss: 1.8945 - val_acc: 0.2976\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.7025 - acc: 0.2129 - val_loss: 3.3003 - val_acc: 0.2031\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.3678 - acc: 0.2510 - val_loss: 2.9121 - val_acc: 0.2969\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.1315 - acc: 0.3194 - val_loss: 2.1588 - val_acc: 0.2812\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.9855 - acc: 0.3387 - val_loss: 1.6717 - val_acc: 0.3594\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9187 - acc: 0.3669 - val_loss: 1.4263 - val_acc: 0.4531\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7848 - acc: 0.3962 - val_loss: 1.5247 - val_acc: 0.4464\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.7147 - acc: 0.3965 - val_loss: 3.0796 - val_acc: 0.2500\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6813 - acc: 0.4114 - val_loss: 1.1902 - val_acc: 0.5677\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6368 - acc: 0.3992 - val_loss: 1.2523 - val_acc: 0.5052\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5601 - acc: 0.4505 - val_loss: 1.2165 - val_acc: 0.5781\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4449 - acc: 0.4881 - val_loss: 1.1041 - val_acc: 0.6488\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4284 - acc: 0.4933 - val_loss: 1.3923 - val_acc: 0.5104\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3944 - acc: 0.4918 - val_loss: 0.9456 - val_acc: 0.6510\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3513 - acc: 0.5351 - val_loss: 1.0821 - val_acc: 0.6198\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2657 - acc: 0.5363 - val_loss: 1.4722 - val_acc: 0.5052\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2309 - acc: 0.5695 - val_loss: 1.0187 - val_acc: 0.6369\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.2538 - acc: 0.5625 - val_loss: 1.1604 - val_acc: 0.5781\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.1248 - acc: 0.5860 - val_loss: 1.0256 - val_acc: 0.6615\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1746 - acc: 0.5760 - val_loss: 0.8864 - val_acc: 0.6667\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0569 - acc: 0.6230 - val_loss: 0.8136 - val_acc: 0.7188\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0050 - acc: 0.6424 - val_loss: 7.0673 - val_acc: 0.1094\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.0183 - acc: 0.6505 - val_loss: 1.4354 - val_acc: 0.4940\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9383 - acc: 0.6794 - val_loss: 1.6320 - val_acc: 0.4635\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8582 - acc: 0.7037 - val_loss: 1.4878 - val_acc: 0.5000\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7883 - acc: 0.7008 - val_loss: 0.7581 - val_acc: 0.7083\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7854 - acc: 0.7280 - val_loss: 0.6961 - val_acc: 0.7969\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8006 - acc: 0.7057 - val_loss: 0.5207 - val_acc: 0.8512\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7073 - acc: 0.7561 - val_loss: 0.3929 - val_acc: 0.8594\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6472 - acc: 0.7851 - val_loss: 0.4694 - val_acc: 0.8281\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.872753530167\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 1.9764 - acc: 0.3748 - val_loss: 2.4172 - val_acc: 0.4062\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.0375 - acc: 0.6292 - val_loss: 1.4692 - val_acc: 0.4881\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5961 - acc: 0.7964 - val_loss: 1.0448 - val_acc: 0.6094\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.4121 - acc: 0.8771 - val_loss: 0.3496 - val_acc: 0.8750\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2633 - acc: 0.9223 - val_loss: 0.4480 - val_acc: 0.8177\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1632 - acc: 0.9536 - val_loss: 0.5901 - val_acc: 0.7865\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1659 - acc: 0.9458 - val_loss: 0.2355 - val_acc: 0.9219\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1017 - acc: 0.980 - 1s 20ms/step - loss: 0.0970 - acc: 0.9818 - val_loss: 0.5743 - val_acc: 0.8036\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0621 - acc: 0.9859 - val_loss: 0.5097 - val_acc: 0.8646\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0535 - acc: 0.9929 - val_loss: 0.2571 - val_acc: 0.9115\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0468 - acc: 0.9889 - val_loss: 0.1104 - val_acc: 0.9479\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0366 - acc: 0.9929 - val_loss: 0.2772 - val_acc: 0.9167\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0802 - acc: 0.9689 - val_loss: 0.6748 - val_acc: 0.7798\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0454 - acc: 0.9919 - val_loss: 0.0986 - val_acc: 0.9635\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0493 - acc: 0.9869 - val_loss: 0.0544 - val_acc: 0.9792\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0339 - acc: 0.9909 - val_loss: 0.0906 - val_acc: 0.9740\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0257 - acc: 0.9960 - val_loss: 0.1568 - val_acc: 0.9688\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0313 - acc: 0.9919 - val_loss: 0.0443 - val_acc: 0.9821\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0201 - acc: 0.9970 - val_loss: 0.0874 - val_acc: 0.9792\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0243 - acc: 0.9929 - val_loss: 0.0495 - val_acc: 0.9896\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0241 - acc: 0.9939 - val_loss: 0.0646 - val_acc: 0.9792\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0204 - acc: 0.9950 - val_loss: 0.1386 - val_acc: 0.9688\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0741 - val_acc: 0.9792\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0173 - acc: 0.9960 - val_loss: 0.0255 - val_acc: 0.9881\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.1359 - val_acc: 0.9844\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0356 - acc: 0.9910 - val_loss: 0.6606 - val_acc: 0.8281\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0522 - acc: 0.9849 - val_loss: 11.9537 - val_acc: 0.1667\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0585 - acc: 0.9830 - val_loss: 2.8394 - val_acc: 0.5781\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0843 - acc: 0.9697 - val_loss: 0.2683 - val_acc: 0.9405\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0348 - acc: 0.9909 - val_loss: 0.1351 - val_acc: 0.9688\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.979060102302\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 3.1243 - acc: 0.1776 - val_loss: 5.5038 - val_acc: 0.1302\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0943 - acc: 0.3468 - val_loss: 6.0493 - val_acc: 0.2083\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.7490 - acc: 0.4062 - val_loss: 5.9239 - val_acc: 0.1786\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.5136 - acc: 0.4890 - val_loss: 2.9436 - val_acc: 0.2760\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.2888 - acc: 0.5565 - val_loss: 1.8375 - val_acc: 0.4062\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.0637 - acc: 0.6300 - val_loss: 1.6795 - val_acc: 0.5052\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9935 - acc: 0.6462 - val_loss: 1.4564 - val_acc: 0.5729\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7801 - acc: 0.7126 - val_loss: 1.0425 - val_acc: 0.6406\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8141 - acc: 0.7097 - val_loss: 2.6702 - val_acc: 0.3036\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.7399 - acc: 0.7348 - val_loss: 1.6748 - val_acc: 0.4323\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6226 - acc: 0.7805 - val_loss: 1.2316 - val_acc: 0.5885\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5382 - acc: 0.8075 - val_loss: 1.2712 - val_acc: 0.5729\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4639 - acc: 0.8327 - val_loss: 0.4110 - val_acc: 0.8698\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4742 - acc: 0.8469 - val_loss: 0.7063 - val_acc: 0.7917\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.4270 - acc: 0.8388 - val_loss: 0.5309 - val_acc: 0.8073\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3523 - acc: 0.8910 - val_loss: 0.9791 - val_acc: 0.6927\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2832 - acc: 0.9032 - val_loss: 0.7170 - val_acc: 0.7396\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2677 - acc: 0.9113 - val_loss: 0.3008 - val_acc: 0.8958\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.2734 - acc: 0.9093 - val_loss: 0.3567 - val_acc: 0.8810\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2370 - acc: 0.9184 - val_loss: 0.7960 - val_acc: 0.7604\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2273 - acc: 0.9304 - val_loss: 0.2703 - val_acc: 0.9271\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2003 - acc: 0.9334 - val_loss: 0.6572 - val_acc: 0.7812\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1801 - acc: 0.9345 - val_loss: 0.6740 - val_acc: 0.7708\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1957 - acc: 0.9416 - val_loss: 0.4301 - val_acc: 0.8750\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1853 - acc: 0.9326 - val_loss: 0.2454 - val_acc: 0.9286\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1959 - acc: 0.9457 - val_loss: 0.7628 - val_acc: 0.7812\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2172 - acc: 0.9306 - val_loss: 1.0281 - val_acc: 0.7240\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1746 - acc: 0.9405 - val_loss: 0.7257 - val_acc: 0.7604\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1609 - acc: 0.9359 - val_loss: 0.4566 - val_acc: 0.8281\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1646 - acc: 0.9507 - val_loss: 1.4471 - val_acc: 0.6607\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.685901534527\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 1.5676 - acc: 0.4817 - val_loss: 2.0059 - val_acc: 0.4531\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.7123 - acc: 0.8235 - val_loss: 2.0205 - val_acc: 0.4010\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4089 - acc: 0.9415 - val_loss: 2.0360 - val_acc: 0.3021\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2273 - acc: 0.9839 - val_loss: 3.5829 - val_acc: 0.2083\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1374 - acc: 0.9960 - val_loss: 2.7834 - val_acc: 0.2969\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0964 - acc: 0.9980 - val_loss: 1.0772 - val_acc: 0.6250\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0684 - acc: 1.0000 - val_loss: 1.9332 - val_acc: 0.5573\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0513 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.8333\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0465 - acc: 1.0000 - val_loss: 0.3281 - val_acc: 0.9219\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.2848 - val_acc: 0.9286\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9271\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0691 - acc: 0.9911 - val_loss: 0.4581 - val_acc: 0.8438\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0342 - acc: 0.9990 - val_loss: 0.2053 - val_acc: 0.9427\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0261 - acc: 0.9990 - val_loss: 0.1576 - val_acc: 0.9740\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9464\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9792\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.9479\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9740\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9688\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9464\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0141 - acc: 0.9990 - val_loss: 0.2116 - val_acc: 0.9219\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9583\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0099 - acc: 0.9990 - val_loss: 0.2571 - val_acc: 0.9219\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9740\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.9531\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9464\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1332 - val_acc: 0.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1446 - val_acc: 0.9740\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 0.9844\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9688\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.976822250639\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 110ms/step - loss: 2.3314 - acc: 0.2631 - val_loss: 1.6277 - val_acc: 0.3750\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3597 - acc: 0.5452 - val_loss: 1.4996 - val_acc: 0.4948\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9649 - acc: 0.7085 - val_loss: 0.9040 - val_acc: 0.6719\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7346 - acc: 0.7653 - val_loss: 0.6192 - val_acc: 0.8177\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6048 - acc: 0.8346 - val_loss: 0.4910 - val_acc: 0.8452\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4952 - acc: 0.8631 - val_loss: 0.4040 - val_acc: 0.9010\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4228 - acc: 0.9113 - val_loss: 0.3224 - val_acc: 0.9427\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3726 - acc: 0.9095 - val_loss: 0.3075 - val_acc: 0.9167\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2838 - acc: 0.9405 - val_loss: 0.2823 - val_acc: 0.9219\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2472 - acc: 0.9566 - val_loss: 0.3192 - val_acc: 0.9323\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2650 - acc: 0.9407 - val_loss: 0.2474 - val_acc: 0.9405\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2191 - acc: 0.9586 - val_loss: 0.2699 - val_acc: 0.9323\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1871 - acc: 0.9739 - val_loss: 0.2835 - val_acc: 0.9167\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1443 - acc: 0.9788 - val_loss: 0.1234 - val_acc: 0.9792\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1349 - acc: 0.9748 - val_loss: 0.1532 - val_acc: 0.9740\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1154 - acc: 0.9829 - val_loss: 0.1301 - val_acc: 0.9702\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1294 - acc: 0.9759 - val_loss: 0.1345 - val_acc: 0.9688\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1094 - acc: 0.9799 - val_loss: 0.1665 - val_acc: 0.9375\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0880 - acc: 0.9869 - val_loss: 0.1327 - val_acc: 0.9792\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0938 - acc: 0.9829 - val_loss: 0.1099 - val_acc: 0.9792\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0887 - acc: 0.9839 - val_loss: 0.2756 - val_acc: 0.9345\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0718 - acc: 0.9869 - val_loss: 0.0890 - val_acc: 0.9792\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0660 - acc: 0.9929 - val_loss: 0.1038 - val_acc: 0.9740\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0640 - acc: 0.9860 - val_loss: 0.1324 - val_acc: 0.9792\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0734 - acc: 0.9850 - val_loss: 0.2791 - val_acc: 0.9271\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0599 - acc: 0.9899 - val_loss: 0.1292 - val_acc: 0.9583\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0496 - acc: 0.9960 - val_loss: 0.1153 - val_acc: 0.9762\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0673 - acc: 0.9840 - val_loss: 0.2139 - val_acc: 0.9219\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0604 - acc: 0.9880 - val_loss: 0.0583 - val_acc: 0.9896\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0600 - acc: 0.9939 - val_loss: 0.0941 - val_acc: 0.9792\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.986200256739\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 2.1797 - acc: 0.3034 - val_loss: 1.4562 - val_acc: 0.4821\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3130 - acc: 0.5718 - val_loss: 1.4934 - val_acc: 0.5104\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9853 - acc: 0.6914 - val_loss: 0.8946 - val_acc: 0.7031\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7652 - acc: 0.7640 - val_loss: 0.5762 - val_acc: 0.8125\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5713 - acc: 0.8488 - val_loss: 0.5734 - val_acc: 0.8385\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4508 - acc: 0.8992 - val_loss: 0.4484 - val_acc: 0.8988\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3693 - acc: 0.9183 - val_loss: 0.3571 - val_acc: 0.9271\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3221 - acc: 0.9356 - val_loss: 0.3837 - val_acc: 0.8854\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2585 - acc: 0.9506 - val_loss: 0.3040 - val_acc: 0.9115\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2019 - acc: 0.9687 - val_loss: 0.2935 - val_acc: 0.9375\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1889 - acc: 0.9638 - val_loss: 0.2514 - val_acc: 0.9531\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1484 - acc: 0.9818 - val_loss: 0.2052 - val_acc: 0.9524\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1344 - acc: 0.9758 - val_loss: 0.4214 - val_acc: 0.8698\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1123 - acc: 0.9899 - val_loss: 0.1773 - val_acc: 0.9635\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1053 - acc: 0.9829 - val_loss: 0.1935 - val_acc: 0.9479\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0999 - acc: 0.9859 - val_loss: 0.1420 - val_acc: 0.9583\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0893 - acc: 0.9859 - val_loss: 0.1187 - val_acc: 0.9643\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0657 - acc: 0.9940 - val_loss: 0.1866 - val_acc: 0.9479\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0578 - acc: 0.9970 - val_loss: 0.1205 - val_acc: 0.9635\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0536 - acc: 0.9980 - val_loss: 0.1345 - val_acc: 0.9688\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0554 - acc: 0.9939 - val_loss: 0.1392 - val_acc: 0.9635\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0481 - acc: 0.9960 - val_loss: 0.1081 - val_acc: 0.9762\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0583 - acc: 0.9950 - val_loss: 0.0907 - val_acc: 0.9792\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0599 - acc: 0.9860 - val_loss: 0.2545 - val_acc: 0.9271\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0475 - acc: 0.9990 - val_loss: 0.1194 - val_acc: 0.9740\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0494 - acc: 0.9939 - val_loss: 0.0887 - val_acc: 0.9740\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0429 - acc: 0.9950 - val_loss: 0.0591 - val_acc: 0.9844\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0387 - acc: 0.9930 - val_loss: 0.0504 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0346 - acc: 0.9970 - val_loss: 0.0926 - val_acc: 0.9896\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0375 - acc: 0.9930 - val_loss: 0.0880 - val_acc: 0.9688\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.971067774936\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 116ms/step - loss: 1.6317 - acc: 0.4646 - val_loss: 1.5035 - val_acc: 0.4740\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.8666 - acc: 0.7784 - val_loss: 1.2476 - val_acc: 0.5476\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4912 - acc: 0.9264 - val_loss: 0.7681 - val_acc: 0.7917\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3296 - acc: 0.9650 - val_loss: 0.9063 - val_acc: 0.7604\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2033 - acc: 0.9929 - val_loss: 1.1084 - val_acc: 0.5833\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1312 - acc: 0.9990 - val_loss: 0.6292 - val_acc: 0.8698\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0945 - acc: 1.0000 - val_loss: 0.6992 - val_acc: 0.8512\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0710 - acc: 1.0000 - val_loss: 0.4214 - val_acc: 0.9167\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0609 - acc: 1.0000 - val_loss: 0.3526 - val_acc: 0.9479\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0528 - acc: 1.0000 - val_loss: 0.2392 - val_acc: 0.9635\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0406 - acc: 1.0000 - val_loss: 0.2562 - val_acc: 0.9583\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.2654 - val_acc: 0.9375\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.2369 - val_acc: 0.9345\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9635\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9740\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.1249 - val_acc: 0.9792\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 0.9479\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1567 - val_acc: 0.9643\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.1826 - val_acc: 0.9531\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9688\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9948\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9688\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0738 - val_acc: 0.9940\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9688\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 0.9896\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9844\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9635\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9844\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9762\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9583\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.972985933504\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 117ms/step - loss: 1.9642 - acc: 0.3538 - val_loss: 1.8953 - val_acc: 0.3594\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.0728 - acc: 0.6693 - val_loss: 0.8936 - val_acc: 0.7292\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7482 - acc: 0.8095 - val_loss: 0.6991 - val_acc: 0.7679\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5026 - acc: 0.8952 - val_loss: 0.5194 - val_acc: 0.8594\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4002 - acc: 0.9294 - val_loss: 0.4770 - val_acc: 0.8542\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3178 - acc: 0.9526 - val_loss: 0.3913 - val_acc: 0.9271\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2378 - acc: 0.9748 - val_loss: 0.2104 - val_acc: 0.9792\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1778 - acc: 0.9899 - val_loss: 0.3326 - val_acc: 0.9583\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1615 - acc: 0.9799 - val_loss: 0.3948 - val_acc: 0.9115\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1326 - acc: 0.9909 - val_loss: 0.1656 - val_acc: 0.9688\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1266 - acc: 0.9899 - val_loss: 0.2996 - val_acc: 0.9271\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1197 - acc: 0.9800 - val_loss: 0.3120 - val_acc: 0.8958\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0826 - acc: 0.9970 - val_loss: 0.1382 - val_acc: 0.9792\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0765 - acc: 0.9950 - val_loss: 0.1019 - val_acc: 0.9940\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0651 - acc: 0.9951 - val_loss: 0.1365 - val_acc: 0.9740\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0515 - acc: 1.0000 - val_loss: 0.1558 - val_acc: 0.9635\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0424 - acc: 0.9990 - val_loss: 0.0885 - val_acc: 0.9792\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9844\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0437 - acc: 0.9980 - val_loss: 0.0849 - val_acc: 0.9881\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0452 - acc: 0.9970 - val_loss: 0.0644 - val_acc: 0.9896\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0358 - acc: 0.998 - 1s 20ms/step - loss: 0.0363 - acc: 0.9980 - val_loss: 0.1590 - val_acc: 0.9635\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0365 - acc: 0.9951 - val_loss: 0.2144 - val_acc: 0.9479\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0489 - acc: 0.9950 - val_loss: 0.2262 - val_acc: 0.9219\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0301 - acc: 0.9990 - val_loss: 0.0424 - val_acc: 0.9940\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9896\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0235 - acc: 0.9990 - val_loss: 0.1303 - val_acc: 0.9740\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9948\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0462 - acc: 0.9940 - val_loss: 0.2836 - val_acc: 0.9219\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0242 - acc: 0.9990 - val_loss: 0.0627 - val_acc: 0.9844\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0260 - acc: 0.9970 - val_loss: 0.1205 - val_acc: 0.9583\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.981065468549\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 1.5327 - acc: 0.4862 - val_loss: 1.6784 - val_acc: 0.4948\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.6998 - acc: 0.8347 - val_loss: 0.5909 - val_acc: 0.8385\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3939 - acc: 0.9357 - val_loss: 0.6165 - val_acc: 0.8229\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2057 - acc: 0.9828 - val_loss: 0.3394 - val_acc: 0.9286\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1295 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9219\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0863 - acc: 1.0000 - val_loss: 0.2846 - val_acc: 0.9427\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0767 - acc: 1.0000 - val_loss: 0.4137 - val_acc: 0.8750\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0558 - acc: 0.9990 - val_loss: 0.3157 - val_acc: 0.9062\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9844\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.1631 - val_acc: 0.9635\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9479\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.1587 - val_acc: 0.9531\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.4767 - val_acc: 0.8438\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9821\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.9583\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1338 - val_acc: 0.9688\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 0.9688\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9844\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9762\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.8645 - val_acc: 0.6927\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9583\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1390 - val_acc: 0.9740\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9844\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9940\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9896\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1295 - val_acc: 0.9635\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9792\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9844\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 0.9740\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.986572890026\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.5594 - acc: 0.5013 - val_loss: 1.5392 - val_acc: 0.4896\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6373 - acc: 0.8539 - val_loss: 0.7691 - val_acc: 0.7604\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.3326 - acc: 0.9596 - val_loss: 0.7211 - val_acc: 0.7708\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1831 - acc: 0.9879 - val_loss: 0.6831 - val_acc: 0.7656\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1430 - acc: 0.9950 - val_loss: 0.6288 - val_acc: 0.8155\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0817 - acc: 1.0000 - val_loss: 0.5438 - val_acc: 0.8438\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.4882 - val_acc: 0.8698\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0640 - acc: 0.9990 - val_loss: 0.2713 - val_acc: 0.9427\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.3603 - val_acc: 0.9115\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.7560\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0379 - acc: 1.0000 - val_loss: 0.1805 - val_acc: 0.9375\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0499 - acc: 0.9990 - val_loss: 0.2907 - val_acc: 0.9219\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.2788 - val_acc: 0.9323\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9844\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.9583\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9643\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.9635\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8646\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.9479\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.1990 - val_acc: 0.9531\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9643\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9531\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9740\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 0.9635\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9688\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1467 - val_acc: 0.9643\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1349 - val_acc: 0.9635\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9844\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1014 - val_acc: 0.9740\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.986253196931\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.6095 - acc: 0.4767 - val_loss: 2.5816 - val_acc: 0.4048\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.7359 - acc: 0.8438 - val_loss: 1.7845 - val_acc: 0.4896\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3881 - acc: 0.9556 - val_loss: 1.4167 - val_acc: 0.5312\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2552 - acc: 0.9749 - val_loss: 0.9455 - val_acc: 0.6771\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1586 - acc: 0.9939 - val_loss: 0.6676 - val_acc: 0.7969\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1119 - acc: 0.9980 - val_loss: 0.6122 - val_acc: 0.7976\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0776 - acc: 1.0000 - val_loss: 0.3958 - val_acc: 0.9062\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0640 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.9375\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0525 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.8177\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.2506 - val_acc: 0.9427\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.1433 - val_acc: 0.9762\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9740\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9583\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1483 - val_acc: 0.9688\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9740\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9688\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 0.9702\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9792\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.1298 - val_acc: 0.9740\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9427\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 0.9896\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9762\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 0.9740\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.2255 - val_acc: 0.9271\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.9635\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.3764 - val_acc: 0.8646\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1363 - val_acc: 0.9583\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.9635\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9688\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9792\n",
      "200/200 [==============================] - 3s 16ms/step\n",
      "Test accuracy: 0.969789002558\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 2.5546 - acc: 0.1862 - val_loss: 2.6110 - val_acc: 0.1719\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9067 - acc: 0.3509 - val_loss: 2.2348 - val_acc: 0.2619\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.5293 - acc: 0.4688 - val_loss: 1.5655 - val_acc: 0.4219\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.3162 - acc: 0.5442 - val_loss: 1.1220 - val_acc: 0.5990\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 1.1518 - acc: 0.6099 - val_loss: 1.4969 - val_acc: 0.4219\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 1.0760 - acc: 0.6311 - val_loss: 2.1652 - val_acc: 0.2656\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8968 - acc: 0.7248 - val_loss: 0.8532 - val_acc: 0.7262\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7654 - acc: 0.7733 - val_loss: 0.8708 - val_acc: 0.6771\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6926 - acc: 0.8005 - val_loss: 0.5813 - val_acc: 0.8021\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.6461 - acc: 0.7953 - val_loss: 0.6453 - val_acc: 0.7969\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5910 - acc: 0.8300 - val_loss: 0.4170 - val_acc: 0.9167\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.4743 - acc: 0.8799 - val_loss: 0.3165 - val_acc: 0.9345\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4421 - acc: 0.8760 - val_loss: 0.2865 - val_acc: 0.9427\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.3894 - acc: 0.8952 - val_loss: 0.3305 - val_acc: 0.9062\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.3362 - acc: 0.9174 - val_loss: 0.3577 - val_acc: 0.9167\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.3291 - acc: 0.9113 - val_loss: 0.3200 - val_acc: 0.9427\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.2971 - acc: 0.9285 - val_loss: 0.2233 - val_acc: 0.9531\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.3094 - acc: 0.9194 - val_loss: 0.2577 - val_acc: 0.9405\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.2678 - acc: 0.9445 - val_loss: 0.1515 - val_acc: 0.9688\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.2126 - acc: 0.9546 - val_loss: 0.1072 - val_acc: 0.9948\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.2147 - acc: 0.9536 - val_loss: 0.1002 - val_acc: 0.9792\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1949 - acc: 0.9556 - val_loss: 0.0957 - val_acc: 0.9844\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1898 - acc: 0.9527 - val_loss: 0.1087 - val_acc: 0.9762\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1960 - acc: 0.9506 - val_loss: 0.1390 - val_acc: 0.9740\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1693 - acc: 0.9638 - val_loss: 0.1099 - val_acc: 0.9740\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1423 - acc: 0.9718 - val_loss: 0.0673 - val_acc: 0.9948\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1499 - acc: 0.9608 - val_loss: 0.1343 - val_acc: 0.9792\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1420 - acc: 0.9678 - val_loss: 0.1124 - val_acc: 0.9702\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1484 - acc: 0.9659 - val_loss: 0.0882 - val_acc: 0.9896\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1259 - acc: 0.9788 - val_loss: 0.1865 - val_acc: 0.9323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.960044929397\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 2.4339 - acc: 0.2005 - val_loss: 2.8063 - val_acc: 0.1354\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8561 - acc: 0.3536 - val_loss: 1.7534 - val_acc: 0.3229\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.5451 - acc: 0.4425 - val_loss: 1.3740 - val_acc: 0.4286\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.2999 - acc: 0.5494 - val_loss: 0.8503 - val_acc: 0.7344\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.1158 - acc: 0.6442 - val_loss: 0.8800 - val_acc: 0.6875\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9288 - acc: 0.7018 - val_loss: 0.5462 - val_acc: 0.8490\n",
      "Epoch 7/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8212 - acc: 0.7469 - val_loss: 0.6177 - val_acc: 0.8229\n",
      "Epoch 8/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.7324 - acc: 0.7873 - val_loss: 0.5091 - val_acc: 0.8333\n",
      "Epoch 9/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6176 - acc: 0.8317 - val_loss: 0.4228 - val_acc: 0.8958\n",
      "Epoch 10/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5198 - acc: 0.8588 - val_loss: 0.4295 - val_acc: 0.8906\n",
      "Epoch 11/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4675 - acc: 0.8730 - val_loss: 0.2993 - val_acc: 0.9427\n",
      "Epoch 12/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4194 - acc: 0.9053 - val_loss: 0.2987 - val_acc: 0.9375\n",
      "Epoch 13/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3680 - acc: 0.8992 - val_loss: 0.3891 - val_acc: 0.8929\n",
      "Epoch 14/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.3459 - acc: 0.9165 - val_loss: 0.2684 - val_acc: 0.9635\n",
      "Epoch 15/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3413 - acc: 0.9083 - val_loss: 0.1816 - val_acc: 0.9479\n",
      "Epoch 16/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.2969 - acc: 0.9204 - val_loss: 0.2233 - val_acc: 0.9635\n",
      "Epoch 17/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2645 - acc: 0.9496 - val_loss: 0.1653 - val_acc: 0.9635\n",
      "Epoch 18/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2621 - acc: 0.9375 - val_loss: 0.2029 - val_acc: 0.9531\n",
      "Epoch 19/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2383 - acc: 0.9436 - val_loss: 0.4340 - val_acc: 0.8869\n",
      "Epoch 20/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2232 - acc: 0.9436 - val_loss: 0.3667 - val_acc: 0.8854\n",
      "Epoch 21/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1824 - acc: 0.9677 - val_loss: 0.1156 - val_acc: 0.9688\n",
      "Epoch 22/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1822 - acc: 0.9509 - val_loss: 0.1917 - val_acc: 0.9583\n",
      "Epoch 23/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1862 - acc: 0.9608 - val_loss: 0.1466 - val_acc: 0.9688\n",
      "Epoch 24/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1623 - acc: 0.9607 - val_loss: 0.5132 - val_acc: 0.8036\n",
      "Epoch 25/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1655 - acc: 0.9567 - val_loss: 0.1521 - val_acc: 0.9479\n",
      "Epoch 26/30\n",
      "31/31 [==============================] - 1s 21ms/step - loss: 0.1406 - acc: 0.9617 - val_loss: 0.1602 - val_acc: 0.9688\n",
      "Epoch 27/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1235 - acc: 0.9738 - val_loss: 0.2515 - val_acc: 0.9219\n",
      "Epoch 28/30\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1283 - acc: 0.9758 - val_loss: 0.1591 - val_acc: 0.9740\n",
      "Epoch 29/30\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.1092 - acc: 0.9798 - val_loss: 0.1027 - val_acc: 0.9702\n",
      "Epoch 30/30\n",
      "31/31 [==============================] - 1s 24ms/step - loss: 0.1383 - acc: 0.9718 - val_loss: 0.0755 - val_acc: 0.9844\n",
      "200/200 [==============================] - 3s 16ms/step\n",
      "Test accuracy: 0.992966751918\n",
      "Evalutation of best performing model:\n",
      "[0.070924851151369039, 0.99296675191815853]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 0, 'Dense_1': 1, 'Dropout': 0.9013722201421666, 'Dropout_1': 0.13188933623714183, 'Dropout_2': 0.00020065768929228636, 'Dropout_3': 0.7530043315724948, 'conv_second': 1, 'conv_second_1': 1}\n"
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    img_size = (32, 32)\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255.,)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory='./Synthetic_dataset/train',\n",
    "        batch_size=32,   \n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        directory='./Synthetic_dataset/val',\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory='./Synthetic_dataset/test',\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "def model(train_generator, validation_generator, test_generator):\n",
    "    \n",
    "    nb_train_samples = 1000\n",
    "    nb_validation_samples = 200\n",
    "    nb_test_samples = 200\n",
    "    epochs = 30\n",
    "    batch_size = 32\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    conv_second = {{choice(['yes', 'no'])}}\n",
    "    if conv_second == 'yes':\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense({{choice([32, 64, 128, 256])}}, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    dense_second = {{choice(['yes', 'no'])}}\n",
    "    if dense_second == 'yes':\n",
    "        model.add(Dense({{choice([32, 64, 128, 256])}}, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        verbose=1,\n",
    "        workers=1,#f you want multiprocessing change it\n",
    "        use_multiprocessing=False,)\n",
    "    \n",
    "    score, acc = model.evaluate_generator(generator=test_generator, steps=nb_test_samples, verbose = 1)\n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "train_generator, validation_generator, test_generator = data()\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=30,\n",
    "                                      verbose=1,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='fonts_classifier')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate_generator(generator=test_generator, steps=200))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.save('best_model_top')\n",
    "best_model.save_weights('best_model_top_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_adam = keras.models.load_model('best_model_top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate test score of best_model_adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "200/200 [==============================] - 4s 19ms/step\n",
      "200/200 [==============================] - 4s 19ms/step\n",
      "200/200 [==============================] - 4s 19ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 19ms/step\n",
      "0.9930306905370843\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255.,)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='./Synthetic_dataset/test/',\n",
    "    batch_size=32,   \n",
    "    color_mode='grayscale',\n",
    "    target_size=(32,32))\n",
    "acc_adam = []\n",
    "for i in range(5):\n",
    "    acc_adam.append(best_model_adam.evaluate_generator(generator=test_generator, steps=200, verbose = 1)[1])\n",
    "print(np.mean(acc_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAEWCAYAAADIE4vrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqSOWZBJkiR17H/fvIC5YOIVEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAEWCAYAAADIE4vrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkdfYPq+jz4M3uuBUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(best_model.history.history['acc'])\n",
    "plt.plot(best_model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(best_model.history.history['loss'])\n",
    "plt.plot(best_model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is hypothesis that with SGD optimizer we can get better score, but accuracy is so close to 1 and it will be very difficult\n",
    "\n",
    "Lets check it!\n",
    "\n",
    "There is duplicated code, it is necessary for hyperas run correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from PIL import Image, ImageDraw, ImageFont\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import ttfquery.findsystem\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import string\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import ntpath\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import glob\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import fetch_20newsgroups\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Activation, Dropout, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.normalization import BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D, ActivityRegularization, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.backend import resize_images, reshape\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD, Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'conv_second': hp.choice('conv_second', ['yes', 'no']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [32, 64, 128, 256]),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'conv_second_1': hp.choice('conv_second_1', ['yes', 'no']),\n",
      "        'Dense_1': hp.choice('Dense_1', [32, 64, 128, 256]),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
      "        'nesterov': hp.choice('nesterov', [True, False]),\n",
      "        'lr': hp.uniform('lr', 0, 0.3),\n",
      "        'Dropout_4': hp.uniform('Dropout_4', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: img_size = (32, 32)\n",
      "  3: train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
      "  4: test_datagen = ImageDataGenerator(rescale = 1./255.,)\n",
      "  5: \n",
      "  6: train_generator = train_datagen.flow_from_directory(\n",
      "  7:     directory='./Synthetic_dataset/train',\n",
      "  8:     batch_size=32,   \n",
      "  9:     color_mode='grayscale',\n",
      " 10:     target_size=img_size)\n",
      " 11: \n",
      " 12: validation_generator = test_datagen.flow_from_directory(\n",
      " 13:     directory='./Synthetic_dataset/val',\n",
      " 14:     batch_size=32,\n",
      " 15:     color_mode='grayscale',\n",
      " 16:     target_size=img_size)\n",
      " 17: \n",
      " 18: test_generator = test_datagen.flow_from_directory(\n",
      " 19:     directory='./Synthetic_dataset/test',\n",
      " 20:     batch_size=32,\n",
      " 21:     color_mode='grayscale',\n",
      " 22:     target_size=img_size)\n",
      " 23: \n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     nb_train_samples = 1000\n",
      "   5:     nb_validation_samples = 200\n",
      "   6:     nb_test_samples = 200\n",
      "   7:     epochs = 100\n",
      "   8:     batch_size = 32\n",
      "   9:     \n",
      "  10:     model = Sequential()\n",
      "  11:     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
      "  12:     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
      "  13:     model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
      "  14:     model.add(BatchNormalization())\n",
      "  15:     model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
      "  16:     model.add(Dropout(space['Dropout']))\n",
      "  17:     \n",
      "  18:     conv_second = space['conv_second']\n",
      "  19:     if conv_second == 'yes':\n",
      "  20:         model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
      "  21:         model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
      "  22:         model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
      "  23:         model.add(BatchNormalization())\n",
      "  24:         model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
      "  25:         model.add(Dropout(space['Dropout_1']))\n",
      "  26:     \n",
      "  27:     model.add(Flatten())\n",
      "  28:     model.add(Dense(space['Dense'], activation='relu'))\n",
      "  29:     model.add(BatchNormalization())\n",
      "  30:     model.add(Dropout(space['Dropout_2']))\n",
      "  31:     \n",
      "  32:     dense_second = space['conv_second_1']\n",
      "  33:     if dense_second == 'yes':\n",
      "  34:         model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "  35:         model.add(BatchNormalization())\n",
      "  36:         model.add(Dropout(space['Dropout_3']))\n",
      "  37:     \n",
      "  38:     model.add(Dense(10, activation='softmax'))\n",
      "  39:         \n",
      "  40:     nesterov = space['nesterov']\n",
      "  41:     print('nesterov is', nesterov)\n",
      "  42:     sgd = SGD(lr = space['lr'], momentum = space['Dropout_4'], nesterov=nesterov)\n",
      "  43:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
      "  44: \n",
      "  45:     model.fit_generator(\n",
      "  46:         train_generator,\n",
      "  47:         steps_per_epoch=nb_train_samples // batch_size,\n",
      "  48:         epochs=epochs,\n",
      "  49:         validation_data=validation_generator,\n",
      "  50:         validation_steps=nb_validation_samples // batch_size,\n",
      "  51:         verbose=1,\n",
      "  52:         workers=1,#f you want multiprocessing change it\n",
      "  53:         use_multiprocessing=False,)\n",
      "  54:     \n",
      "  55:     score, acc = model.evaluate_generator(generator=test_generator, steps=nb_test_samples, verbose = 1)\n",
      "  56:     print('Test accuracy:', acc)\n",
      "  57:     \n",
      "  58:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  59: \n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.7344 - acc: 0.4083 - val_loss: 11.8048 - val_acc: 0.1198\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.1556 - acc: 0.5705 - val_loss: 3.5021 - val_acc: 0.2708\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.9087 - acc: 0.6633 - val_loss: 6.5552 - val_acc: 0.1354\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6964 - acc: 0.7388 - val_loss: 10.9848 - val_acc: 0.1458\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6425 - acc: 0.7762 - val_loss: 0.6041 - val_acc: 0.7760\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4902 - acc: 0.8248 - val_loss: 4.8291 - val_acc: 0.2560\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4136 - acc: 0.8537 - val_loss: 6.4940 - val_acc: 0.1562\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5156 - acc: 0.8269 - val_loss: 6.1623 - val_acc: 0.3490\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4569 - acc: 0.8298 - val_loss: 1.1018 - val_acc: 0.6875\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3912 - acc: 0.8732 - val_loss: 0.5619 - val_acc: 0.8333\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3293 - acc: 0.8781 - val_loss: 0.5289 - val_acc: 0.8512\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4399 - acc: 0.8408 - val_loss: 12.0245 - val_acc: 0.1146\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3084 - acc: 0.8982 - val_loss: 0.5415 - val_acc: 0.8385\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3081 - acc: 0.8883 - val_loss: 0.8012 - val_acc: 0.7031\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1897 - acc: 0.9334 - val_loss: 1.7435 - val_acc: 0.5573\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2488 - acc: 0.9195 - val_loss: 0.4276 - val_acc: 0.8750\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1836 - acc: 0.9354 - val_loss: 0.7039 - val_acc: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1877 - acc: 0.9436 - val_loss: 1.8416 - val_acc: 0.5677\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1550 - acc: 0.9447 - val_loss: 1.3134 - val_acc: 0.6615\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1604 - acc: 0.9397 - val_loss: 13.2638 - val_acc: 0.1771\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.8434 - acc: 0.7157 - val_loss: 15.1107 - val_acc: 0.0625\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5528 - acc: 0.8028 - val_loss: 2.3827 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3699 - acc: 0.8681 - val_loss: 10.8506 - val_acc: 0.1875\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2195 - acc: 0.9123 - val_loss: 7.4912 - val_acc: 0.2031\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1745 - acc: 0.9407 - val_loss: 3.4304 - val_acc: 0.3958\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1551 - acc: 0.9476 - val_loss: 3.0255 - val_acc: 0.4531\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1415 - acc: 0.9496 - val_loss: 3.4920 - val_acc: 0.3869\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1193 - acc: 0.9648 - val_loss: 0.4799 - val_acc: 0.8490\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1370 - acc: 0.9567 - val_loss: 7.4317 - val_acc: 0.1979\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1234 - acc: 0.9518 - val_loss: 0.5572 - val_acc: 0.8333\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1509 - acc: 0.9466 - val_loss: 0.3045 - val_acc: 0.9219\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1493 - acc: 0.9569 - val_loss: 1.5723 - val_acc: 0.6012\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1166 - acc: 0.9556 - val_loss: 0.3901 - val_acc: 0.8698\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0937 - acc: 0.9677 - val_loss: 0.4155 - val_acc: 0.8490\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1088 - acc: 0.9617 - val_loss: 0.1364 - val_acc: 0.9479\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0854 - acc: 0.9708 - val_loss: 0.6714 - val_acc: 0.7969\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0906 - acc: 0.9688 - val_loss: 0.1243 - val_acc: 0.9531\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1165 - acc: 0.9587 - val_loss: 0.1092 - val_acc: 0.9702\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0698 - acc: 0.9808 - val_loss: 0.9750 - val_acc: 0.7604\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1234 - acc: 0.9598 - val_loss: 0.1505 - val_acc: 0.9531\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1250 - acc: 0.9658 - val_loss: 8.6842 - val_acc: 0.2240\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0528 - acc: 0.9828 - val_loss: 0.1124 - val_acc: 0.9427\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0793 - acc: 0.9749 - val_loss: 0.2922 - val_acc: 0.9107\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0620 - acc: 0.9779 - val_loss: 0.1786 - val_acc: 0.9375\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1976 - acc: 0.9358 - val_loss: 0.9818 - val_acc: 0.7656\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0948 - acc: 0.9648 - val_loss: 1.6192 - val_acc: 0.6562\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1223 - acc: 0.9489 - val_loss: 0.0513 - val_acc: 0.9792\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0927 - acc: 0.9709 - val_loss: 0.2234 - val_acc: 0.9405\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0665 - acc: 0.9778 - val_loss: 0.0902 - val_acc: 0.9792\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0723 - acc: 0.9760 - val_loss: 0.3074 - val_acc: 0.9271\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0515 - acc: 0.9819 - val_loss: 0.2031 - val_acc: 0.9479\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0973 - acc: 0.9688 - val_loss: 0.1107 - val_acc: 0.9531\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0497 - acc: 0.9809 - val_loss: 1.7922 - val_acc: 0.6250\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0697 - acc: 0.9759 - val_loss: 0.1767 - val_acc: 0.9345\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0625 - acc: 0.9818 - val_loss: 0.1561 - val_acc: 0.9635\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0472 - acc: 0.9859 - val_loss: 0.1972 - val_acc: 0.9531\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0491 - acc: 0.9840 - val_loss: 3.7612 - val_acc: 0.6198\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0994 - acc: 0.9610 - val_loss: 0.7761 - val_acc: 0.7708\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0430 - acc: 0.9869 - val_loss: 0.0919 - val_acc: 0.9821\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0888 - acc: 0.9741 - val_loss: 0.3014 - val_acc: 0.9271\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0506 - acc: 0.9818 - val_loss: 0.3472 - val_acc: 0.9427\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0256 - acc: 0.9909 - val_loss: 0.2299 - val_acc: 0.9531\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0387 - acc: 0.9859 - val_loss: 1.1127 - val_acc: 0.7031\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0602 - acc: 0.9789 - val_loss: 0.2646 - val_acc: 0.9583\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0564 - acc: 0.9798 - val_loss: 0.4076 - val_acc: 0.8594\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0418 - acc: 0.9828 - val_loss: 0.0857 - val_acc: 0.9792\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0406 - acc: 0.9839 - val_loss: 0.2731 - val_acc: 0.9010\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0453 - acc: 0.9829 - val_loss: 0.1701 - val_acc: 0.9583\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0377 - acc: 0.9889 - val_loss: 0.1804 - val_acc: 0.9583\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1105 - acc: 0.9690 - val_loss: 1.4120 - val_acc: 0.7202\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0579 - acc: 0.9869 - val_loss: 0.4093 - val_acc: 0.9427\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0500 - acc: 0.9859 - val_loss: 0.5473 - val_acc: 0.9323\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0431 - acc: 0.9839 - val_loss: 0.1715 - val_acc: 0.9323\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0474 - acc: 0.9859 - val_loss: 0.1082 - val_acc: 0.9688\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0486 - acc: 0.9839 - val_loss: 0.4125 - val_acc: 0.9107\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2070 - acc: 0.9498 - val_loss: 0.4541 - val_acc: 0.9115\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0327 - acc: 0.9939 - val_loss: 0.1833 - val_acc: 0.9583\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0865 - acc: 0.9740 - val_loss: 0.0658 - val_acc: 0.9688\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0432 - acc: 0.9849 - val_loss: 0.1174 - val_acc: 0.9635\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0497 - acc: 0.9810 - val_loss: 0.2910 - val_acc: 0.9286\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0578 - acc: 0.9789 - val_loss: 0.2093 - val_acc: 0.9427\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0576 - acc: 0.9859 - val_loss: 0.2008 - val_acc: 0.9531\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0401 - acc: 0.9919 - val_loss: 0.2209 - val_acc: 0.9375\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0230 - acc: 0.9960 - val_loss: 0.0829 - val_acc: 0.9792\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1024 - acc: 0.9708 - val_loss: 0.1399 - val_acc: 0.9427\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0298 - acc: 0.9919 - val_loss: 0.3093 - val_acc: 0.9464\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0173 - acc: 0.9950 - val_loss: 0.0942 - val_acc: 0.9792\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0192 - acc: 0.9929 - val_loss: 0.1628 - val_acc: 0.9635\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0343 - acc: 0.9890 - val_loss: 2.4253 - val_acc: 0.5885\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0651 - acc: 0.9799 - val_loss: 0.0884 - val_acc: 0.9844\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0275 - acc: 0.9899 - val_loss: 0.0362 - val_acc: 0.9940\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0247 - acc: 0.9909 - val_loss: 0.4917 - val_acc: 0.8594\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0279 - acc: 0.9899 - val_loss: 0.5267 - val_acc: 0.8958\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0346 - acc: 0.9859 - val_loss: 0.0347 - val_acc: 0.9948\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0316 - acc: 0.9879 - val_loss: 0.0817 - val_acc: 0.9896\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0475 - acc: 0.9879 - val_loss: 0.0874 - val_acc: 0.9821\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0161 - acc: 0.9960 - val_loss: 0.0193 - val_acc: 0.9896\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0663 - acc: 0.9780 - val_loss: 0.1541 - val_acc: 0.9635\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0740 - acc: 0.9780 - val_loss: 1.6736 - val_acc: 0.7135\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0418 - acc: 0.9840 - val_loss: 0.1737 - val_acc: 0.9635\n",
      "200/200 [==============================] - 2s 11ms/step\n",
      "Test accuracy: 0.982097186701\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 2.6745 - acc: 0.1815 - val_loss: 1.8023 - val_acc: 0.2917\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.9818 - acc: 0.2965 - val_loss: 1.7428 - val_acc: 0.3385\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8807 - acc: 0.2934 - val_loss: 7.7447 - val_acc: 0.0573\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8416 - acc: 0.3197 - val_loss: 1.7197 - val_acc: 0.3229\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8219 - acc: 0.2986 - val_loss: 1.5611 - val_acc: 0.3646\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7512 - acc: 0.3337 - val_loss: 1.4726 - val_acc: 0.4048\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7507 - acc: 0.3066 - val_loss: 2.0841 - val_acc: 0.2083\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7342 - acc: 0.3224 - val_loss: 2.0945 - val_acc: 0.2656\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6741 - acc: 0.3568 - val_loss: 1.5880 - val_acc: 0.4062\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7247 - acc: 0.3681 - val_loss: 1.4288 - val_acc: 0.4635\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6512 - acc: 0.3689 - val_loss: 1.5578 - val_acc: 0.3750\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7100 - acc: 0.3407 - val_loss: 1.6401 - val_acc: 0.3958\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6975 - acc: 0.3601 - val_loss: 2.9697 - val_acc: 0.1562\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6376 - acc: 0.3811 - val_loss: 2.3810 - val_acc: 0.2240\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6715 - acc: 0.3718 - val_loss: 2.4673 - val_acc: 0.2396\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6755 - acc: 0.3701 - val_loss: 2.3138 - val_acc: 0.2396\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6496 - acc: 0.3883 - val_loss: 1.7621 - val_acc: 0.3274\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5950 - acc: 0.3912 - val_loss: 1.5399 - val_acc: 0.4635\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5935 - acc: 0.3841 - val_loss: 2.4527 - val_acc: 0.2917\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6189 - acc: 0.3872 - val_loss: 2.9291 - val_acc: 0.2083\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6040 - acc: 0.3983 - val_loss: 2.8673 - val_acc: 0.1719\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5397 - acc: 0.4203 - val_loss: 2.9122 - val_acc: 0.1667\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5701 - acc: 0.4032 - val_loss: 2.5416 - val_acc: 0.1719\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6259 - acc: 0.3890 - val_loss: 1.3181 - val_acc: 0.4635\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4971 - acc: 0.4466 - val_loss: 1.2491 - val_acc: 0.5521\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6243 - acc: 0.3882 - val_loss: 1.4201 - val_acc: 0.5312\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4872 - acc: 0.4296 - val_loss: 2.9136 - val_acc: 0.2321\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5584 - acc: 0.4324 - val_loss: 3.2901 - val_acc: 0.2083\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5099 - acc: 0.4455 - val_loss: 3.1838 - val_acc: 0.2708\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5024 - acc: 0.4727 - val_loss: 1.6657 - val_acc: 0.4583\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4945 - acc: 0.4345 - val_loss: 2.6133 - val_acc: 0.2760\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.5344 - acc: 0.4345 - val_loss: 2.8670 - val_acc: 0.2292\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4948 - acc: 0.4183 - val_loss: 2.8724 - val_acc: 0.2440\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4936 - acc: 0.4469 - val_loss: 2.4940 - val_acc: 0.2812\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5129 - acc: 0.4465 - val_loss: 1.9940 - val_acc: 0.3333\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4650 - acc: 0.4638 - val_loss: 1.2658 - val_acc: 0.5208\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.4240 - acc: 0.476 - 0s 14ms/step - loss: 1.4236 - acc: 0.4779 - val_loss: 1.9314 - val_acc: 0.3958\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5301 - acc: 0.4177 - val_loss: 2.4149 - val_acc: 0.2738\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3973 - acc: 0.4929 - val_loss: 1.2245 - val_acc: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3679 - acc: 0.4960 - val_loss: 3.1652 - val_acc: 0.1927\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4188 - acc: 0.4619 - val_loss: 3.2996 - val_acc: 0.2604\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4062 - acc: 0.4770 - val_loss: 2.7165 - val_acc: 0.2708\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4455 - acc: 0.4637 - val_loss: 2.9554 - val_acc: 0.2857\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3806 - acc: 0.5131 - val_loss: 1.8545 - val_acc: 0.3854\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3207 - acc: 0.5192 - val_loss: 1.7084 - val_acc: 0.3333\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3188 - acc: 0.5061 - val_loss: 1.9406 - val_acc: 0.3385\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3939 - acc: 0.4910 - val_loss: 3.2543 - val_acc: 0.3021\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.3381 - acc: 0.5120 - val_loss: 2.8013 - val_acc: 0.1927\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2305 - acc: 0.5452 - val_loss: 3.1375 - val_acc: 0.2976\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3989 - acc: 0.4939 - val_loss: 2.9279 - val_acc: 0.3125\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3602 - acc: 0.5073 - val_loss: 1.1636 - val_acc: 0.5469\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2626 - acc: 0.5322 - val_loss: 3.2582 - val_acc: 0.3229\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2952 - acc: 0.5224 - val_loss: 1.6899 - val_acc: 0.4167\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3593 - acc: 0.5051 - val_loss: 2.3276 - val_acc: 0.2440\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3085 - acc: 0.5392 - val_loss: 1.7015 - val_acc: 0.4062\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3011 - acc: 0.5165 - val_loss: 9.3806 - val_acc: 0.0990\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3885 - acc: 0.5081 - val_loss: 3.8064 - val_acc: 0.1406\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2615 - acc: 0.5524 - val_loss: 2.2112 - val_acc: 0.3073\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.2600 - acc: 0.5272 - val_loss: 3.4598 - val_acc: 0.2738\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2675 - acc: 0.5243 - val_loss: 3.8337 - val_acc: 0.1458\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1811 - acc: 0.5585 - val_loss: 4.8592 - val_acc: 0.1510\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1480 - acc: 0.5845 - val_loss: 3.6881 - val_acc: 0.2031\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2302 - acc: 0.5665 - val_loss: 3.8574 - val_acc: 0.1927\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1948 - acc: 0.5547 - val_loss: 4.1495 - val_acc: 0.1198\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1389 - acc: 0.5625 - val_loss: 2.9626 - val_acc: 0.2917\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1929 - acc: 0.5707 - val_loss: 4.4414 - val_acc: 0.1094\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2360 - acc: 0.5527 - val_loss: 4.7190 - val_acc: 0.0938\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2011 - acc: 0.5576 - val_loss: 3.4716 - val_acc: 0.1927\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1163 - acc: 0.5858 - val_loss: 3.1924 - val_acc: 0.3646\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0214 - acc: 0.6102 - val_loss: 4.6742 - val_acc: 0.1190\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1733 - acc: 0.5808 - val_loss: 1.1529 - val_acc: 0.5573\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2586 - acc: 0.5747 - val_loss: 2.6633 - val_acc: 0.3021\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1259 - acc: 0.6040 - val_loss: 1.3439 - val_acc: 0.5365\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1657 - acc: 0.5880 - val_loss: 1.5426 - val_acc: 0.4635\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1339 - acc: 0.6099 - val_loss: 1.3424 - val_acc: 0.5774\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0213 - acc: 0.6211 - val_loss: 2.4226 - val_acc: 0.4010\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0281 - acc: 0.6150 - val_loss: 3.2268 - val_acc: 0.3229\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0030 - acc: 0.6320 - val_loss: 0.7025 - val_acc: 0.7344\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0530 - acc: 0.6091 - val_loss: 0.9249 - val_acc: 0.6094\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.0520 - acc: 0.6221 - val_loss: 2.4444 - val_acc: 0.3698\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9558 - acc: 0.6442 - val_loss: 1.0654 - val_acc: 0.5774\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0291 - acc: 0.6360 - val_loss: 0.6182 - val_acc: 0.7812\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9414 - acc: 0.6362 - val_loss: 1.8967 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0084 - acc: 0.6301 - val_loss: 1.0021 - val_acc: 0.6771\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0041 - acc: 0.6390 - val_loss: 2.8221 - val_acc: 0.3698\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0208 - acc: 0.6334 - val_loss: 1.1140 - val_acc: 0.6250\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.0188 - acc: 0.6422 - val_loss: 0.4859 - val_acc: 0.8438\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9000 - acc: 0.6713 - val_loss: 1.0326 - val_acc: 0.6510\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.9488 - acc: 0.6582 - val_loss: 5.1868 - val_acc: 0.2240\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9080 - acc: 0.6863 - val_loss: 2.8044 - val_acc: 0.3698\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9271 - acc: 0.6655 - val_loss: 3.1398 - val_acc: 0.2857\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.9119 - acc: 0.6656 - val_loss: 5.6152 - val_acc: 0.1094\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0013 - acc: 0.6545 - val_loss: 8.3153 - val_acc: 0.1042\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9881 - acc: 0.6595 - val_loss: 2.3865 - val_acc: 0.4115\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9204 - acc: 0.6845 - val_loss: 0.4541 - val_acc: 0.8021\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9030 - acc: 0.6784 - val_loss: 2.2463 - val_acc: 0.3698\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9480 - acc: 0.6867 - val_loss: 0.6268 - val_acc: 0.7679\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9084 - acc: 0.6776 - val_loss: 3.2408 - val_acc: 0.3385\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9275 - acc: 0.6585 - val_loss: 0.7456 - val_acc: 0.7552\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9586 - acc: 0.6362 - val_loss: 1.4712 - val_acc: 0.5625\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.545556265985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 2.3523 - acc: 0.1813 - val_loss: 2.0478 - val_acc: 0.1310\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.9988 - acc: 0.2430 - val_loss: 2.0955 - val_acc: 0.1406\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9104 - acc: 0.2701 - val_loss: 1.7611 - val_acc: 0.2708\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8650 - acc: 0.2763 - val_loss: 1.9757 - val_acc: 0.3333\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7995 - acc: 0.3084 - val_loss: 1.4010 - val_acc: 0.5469\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8293 - acc: 0.3002 - val_loss: 1.5331 - val_acc: 0.4821\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6834 - acc: 0.3699 - val_loss: 1.4073 - val_acc: 0.5469\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7945 - acc: 0.3126 - val_loss: 1.4323 - val_acc: 0.5052\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6995 - acc: 0.3277 - val_loss: 1.4893 - val_acc: 0.4635\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7783 - acc: 0.3197 - val_loss: 2.3250 - val_acc: 0.1979\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7155 - acc: 0.3307 - val_loss: 4.5626 - val_acc: 0.2031\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7255 - acc: 0.3398 - val_loss: 3.1694 - val_acc: 0.1369\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7059 - acc: 0.3377 - val_loss: 2.3164 - val_acc: 0.1562\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7009 - acc: 0.3357 - val_loss: 1.3766 - val_acc: 0.5208\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6815 - acc: 0.3287 - val_loss: 1.4269 - val_acc: 0.4115\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7133 - acc: 0.3368 - val_loss: 1.5242 - val_acc: 0.4375\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6647 - acc: 0.3549 - val_loss: 1.5975 - val_acc: 0.3810\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6434 - acc: 0.3832 - val_loss: 1.6642 - val_acc: 0.3490\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6560 - acc: 0.3668 - val_loss: 1.3470 - val_acc: 0.5260\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6731 - acc: 0.3500 - val_loss: 1.3090 - val_acc: 0.5208\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6533 - acc: 0.3628 - val_loss: 1.9059 - val_acc: 0.2708\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6431 - acc: 0.3680 - val_loss: 1.4248 - val_acc: 0.4881\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6444 - acc: 0.3647 - val_loss: 2.1906 - val_acc: 0.2083\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6474 - acc: 0.3648 - val_loss: 1.3333 - val_acc: 0.5521\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6164 - acc: 0.3660 - val_loss: 6.1543 - val_acc: 0.1198\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5951 - acc: 0.3880 - val_loss: 2.6704 - val_acc: 0.1979\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6083 - acc: 0.3870 - val_loss: 1.3204 - val_acc: 0.5104\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6771 - acc: 0.3639 - val_loss: 1.2893 - val_acc: 0.6488\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5940 - acc: 0.3911 - val_loss: 1.7632 - val_acc: 0.3750\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5938 - acc: 0.3902 - val_loss: 1.3046 - val_acc: 0.5729\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6372 - acc: 0.3601 - val_loss: 1.2089 - val_acc: 0.6250\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5917 - acc: 0.3881 - val_loss: 1.2811 - val_acc: 0.6042\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5604 - acc: 0.3860 - val_loss: 1.3024 - val_acc: 0.5119\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6666 - acc: 0.3650 - val_loss: 1.2704 - val_acc: 0.5990\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5880 - acc: 0.3731 - val_loss: 1.2966 - val_acc: 0.5885\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6052 - acc: 0.3859 - val_loss: 1.2907 - val_acc: 0.5677\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5878 - acc: 0.3823 - val_loss: 1.4433 - val_acc: 0.5260\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5479 - acc: 0.4143 - val_loss: 1.7935 - val_acc: 0.2976\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6816 - acc: 0.3670 - val_loss: 2.1102 - val_acc: 0.2604\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5360 - acc: 0.4094 - val_loss: 1.1927 - val_acc: 0.6615\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5987 - acc: 0.3850 - val_loss: 1.3847 - val_acc: 0.5417\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5803 - acc: 0.3922 - val_loss: 2.3912 - val_acc: 0.2708\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5513 - acc: 0.3658 - val_loss: 3.3463 - val_acc: 0.1510\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5370 - acc: 0.4074 - val_loss: 1.4170 - val_acc: 0.4583\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4830 - acc: 0.4122 - val_loss: 1.7824 - val_acc: 0.3177\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5816 - acc: 0.4092 - val_loss: 1.3732 - val_acc: 0.4635\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5835 - acc: 0.3853 - val_loss: 5.2046 - val_acc: 0.1198\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5201 - acc: 0.4095 - val_loss: 2.2846 - val_acc: 0.3229\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6046 - acc: 0.3820 - val_loss: 1.2450 - val_acc: 0.5714\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4531 - acc: 0.4506 - val_loss: 1.2427 - val_acc: 0.5729\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5572 - acc: 0.3983 - val_loss: 2.1656 - val_acc: 0.2604\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5267 - acc: 0.4324 - val_loss: 3.5255 - val_acc: 0.1510\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5659 - acc: 0.4132 - val_loss: 1.7568 - val_acc: 0.3750\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4806 - acc: 0.4114 - val_loss: 1.0760 - val_acc: 0.6369\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4701 - acc: 0.4246 - val_loss: 1.5863 - val_acc: 0.3802\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5814 - acc: 0.4032 - val_loss: 4.6029 - val_acc: 0.1146\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4909 - acc: 0.4216 - val_loss: 2.3628 - val_acc: 0.1510\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5063 - acc: 0.4244 - val_loss: 1.1036 - val_acc: 0.6198\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4621 - acc: 0.4305 - val_loss: 8.4901 - val_acc: 0.1354\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5509 - acc: 0.3891 - val_loss: 1.5317 - val_acc: 0.3512\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4712 - acc: 0.4415 - val_loss: 1.0253 - val_acc: 0.6667\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4967 - acc: 0.4364 - val_loss: 2.0125 - val_acc: 0.3073\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5233 - acc: 0.4154 - val_loss: 2.4466 - val_acc: 0.2708\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5423 - acc: 0.4053 - val_loss: 1.4169 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5107 - acc: 0.4196 - val_loss: 1.0848 - val_acc: 0.6786\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5947 - acc: 0.3991 - val_loss: 2.8102 - val_acc: 0.1927\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5015 - acc: 0.4233 - val_loss: 1.6123 - val_acc: 0.2969\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4385 - acc: 0.4375 - val_loss: 1.1935 - val_acc: 0.5260\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4960 - acc: 0.4072 - val_loss: 1.2087 - val_acc: 0.5885\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4773 - acc: 0.4307 - val_loss: 4.7719 - val_acc: 0.1369\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5130 - acc: 0.4212 - val_loss: 1.0858 - val_acc: 0.5573\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5189 - acc: 0.4021 - val_loss: 1.5174 - val_acc: 0.4167\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4620 - acc: 0.4415 - val_loss: 1.2847 - val_acc: 0.5885\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5522 - acc: 0.4104 - val_loss: 1.1583 - val_acc: 0.5312\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4298 - acc: 0.4364 - val_loss: 1.8754 - val_acc: 0.3333\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4366 - acc: 0.4456 - val_loss: 1.1551 - val_acc: 0.5060\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4363 - acc: 0.4425 - val_loss: 1.5914 - val_acc: 0.3958\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4851 - acc: 0.4265 - val_loss: 1.1359 - val_acc: 0.5521\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5042 - acc: 0.4195 - val_loss: 1.0616 - val_acc: 0.6510\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4327 - acc: 0.4496 - val_loss: 1.7972 - val_acc: 0.2917\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4362 - acc: 0.4476 - val_loss: 2.3479 - val_acc: 0.2560\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5347 - acc: 0.4144 - val_loss: 1.2196 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4636 - acc: 0.4328 - val_loss: 1.5556 - val_acc: 0.3802\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4390 - acc: 0.4357 - val_loss: 1.5924 - val_acc: 0.3802\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4394 - acc: 0.4518 - val_loss: 1.0447 - val_acc: 0.6250\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4684 - acc: 0.4142 - val_loss: 1.1277 - val_acc: 0.5655\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4795 - acc: 0.4396 - val_loss: 1.4413 - val_acc: 0.4010\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4972 - acc: 0.4366 - val_loss: 1.3811 - val_acc: 0.4062\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4638 - acc: 0.4528 - val_loss: 1.3672 - val_acc: 0.5156\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4317 - acc: 0.4688 - val_loss: 2.9824 - val_acc: 0.2396\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3933 - acc: 0.4397 - val_loss: 1.0220 - val_acc: 0.6354\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4193 - acc: 0.4656 - val_loss: 0.9302 - val_acc: 0.7024\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3731 - acc: 0.4597 - val_loss: 1.1315 - val_acc: 0.5885\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4536 - acc: 0.4598 - val_loss: 1.5665 - val_acc: 0.4062\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4028 - acc: 0.4536 - val_loss: 3.3039 - val_acc: 0.2188\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4772 - acc: 0.4465 - val_loss: 1.1722 - val_acc: 0.6042\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3884 - acc: 0.4739 - val_loss: 1.0023 - val_acc: 0.7083\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3968 - acc: 0.4680 - val_loss: 2.4537 - val_acc: 0.2604\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4250 - acc: 0.4418 - val_loss: 2.1775 - val_acc: 0.3229\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3629 - acc: 0.4736 - val_loss: 1.2784 - val_acc: 0.5469\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.566975703325\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 1.9292 - acc: 0.3943 - val_loss: 12.3802 - val_acc: 0.1845\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.3608 - acc: 0.5104 - val_loss: 4.9955 - val_acc: 0.2500\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1856 - acc: 0.5796 - val_loss: 1.4546 - val_acc: 0.4948\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0943 - acc: 0.6103 - val_loss: 1.5116 - val_acc: 0.5156\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0969 - acc: 0.5778 - val_loss: 3.6445 - val_acc: 0.4219\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0676 - acc: 0.6351 - val_loss: 5.4554 - val_acc: 0.4167\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.8903 - acc: 0.6786 - val_loss: 1.2774 - val_acc: 0.5893\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9440 - acc: 0.6576 - val_loss: 5.9281 - val_acc: 0.2917\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0038 - acc: 0.6706 - val_loss: 10.1931 - val_acc: 0.2865\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.7801 - acc: 0.7207 - val_loss: 1.0623 - val_acc: 0.6771\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.7804 - acc: 0.7179 - val_loss: 3.9682 - val_acc: 0.3750\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0480 - acc: 0.6765 - val_loss: 14.0883 - val_acc: 0.1250\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7520 - acc: 0.7318 - val_loss: 8.9454 - val_acc: 0.3490\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.7054 - acc: 0.7480 - val_loss: 13.4943 - val_acc: 0.0990\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5914 - acc: 0.7855 - val_loss: 13.6231 - val_acc: 0.1458\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5575 - acc: 0.8046 - val_loss: 13.6641 - val_acc: 0.1198\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5887 - acc: 0.8055 - val_loss: 13.9635 - val_acc: 0.1131\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6195 - acc: 0.7943 - val_loss: 14.7730 - val_acc: 0.0573\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4176 - acc: 0.8430 - val_loss: 14.0973 - val_acc: 0.1250\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6712 - acc: 0.8065 - val_loss: 11.0057 - val_acc: 0.2292\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5314 - acc: 0.8418 - val_loss: 12.8159 - val_acc: 0.1927\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3717 - acc: 0.8749 - val_loss: 13.9689 - val_acc: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2800 - acc: 0.9074 - val_loss: 13.2147 - val_acc: 0.1131\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3343 - acc: 0.8789 - val_loss: 12.4449 - val_acc: 0.1302\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2617 - acc: 0.9204 - val_loss: 13.1253 - val_acc: 0.1406\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3107 - acc: 0.9185 - val_loss: 12.6236 - val_acc: 0.1823\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4497 - acc: 0.8760 - val_loss: 8.8674 - val_acc: 0.2865\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3746 - acc: 0.8881 - val_loss: 4.2857 - val_acc: 0.4821\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4218 - acc: 0.8813 - val_loss: 8.1687 - val_acc: 0.2604\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3283 - acc: 0.9001 - val_loss: 0.9455 - val_acc: 0.7656\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3149 - acc: 0.9114 - val_loss: 2.6253 - val_acc: 0.5781\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4295 - acc: 0.8762 - val_loss: 0.6635 - val_acc: 0.8906\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4051 - acc: 0.8860 - val_loss: 0.7484 - val_acc: 0.8155\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1566 - acc: 0.9396 - val_loss: 9.5476 - val_acc: 0.2552\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1842 - acc: 0.9415 - val_loss: 2.8856 - val_acc: 0.6042\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2126 - acc: 0.9324 - val_loss: 0.9622 - val_acc: 0.8021\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2554 - acc: 0.9235 - val_loss: 0.8896 - val_acc: 0.7656\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2115 - acc: 0.9405 - val_loss: 0.4837 - val_acc: 0.8750\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1728 - acc: 0.9527 - val_loss: 0.5105 - val_acc: 0.8810\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1440 - acc: 0.9546 - val_loss: 3.6093 - val_acc: 0.5312\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2059 - acc: 0.9436 - val_loss: 2.8218 - val_acc: 0.6146\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1619 - acc: 0.9577 - val_loss: 0.8570 - val_acc: 0.8698\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2220 - acc: 0.9397 - val_loss: 1.6288 - val_acc: 0.7604\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1812 - acc: 0.9436 - val_loss: 13.1941 - val_acc: 0.1310\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2231 - acc: 0.9457 - val_loss: 5.8000 - val_acc: 0.4479\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2262 - acc: 0.9385 - val_loss: 2.2753 - val_acc: 0.7083\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2965 - acc: 0.9395 - val_loss: 1.1848 - val_acc: 0.8073\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2458 - acc: 0.9346 - val_loss: 9.0651 - val_acc: 0.2500\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4364 - acc: 0.9034 - val_loss: 11.6144 - val_acc: 0.1548\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3704 - acc: 0.9176 - val_loss: 1.1712 - val_acc: 0.8385\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3394 - acc: 0.9264 - val_loss: 2.1933 - val_acc: 0.6823\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3651 - acc: 0.9396 - val_loss: 6.8850 - val_acc: 0.4427\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1970 - acc: 0.9617 - val_loss: 6.0827 - val_acc: 0.4531\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2066 - acc: 0.9577 - val_loss: 1.1192 - val_acc: 0.8594\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1435 - acc: 0.9628 - val_loss: 5.2417 - val_acc: 0.5476\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1540 - acc: 0.9627 - val_loss: 10.5417 - val_acc: 0.2917\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1096 - acc: 0.9677 - val_loss: 1.0683 - val_acc: 0.8594\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1158 - acc: 0.9668 - val_loss: 5.0923 - val_acc: 0.5260\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1547 - acc: 0.9627 - val_loss: 2.0399 - val_acc: 0.7344\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1649 - acc: 0.9629 - val_loss: 0.5797 - val_acc: 0.9226\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2529 - acc: 0.9608 - val_loss: 4.7453 - val_acc: 0.5469\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1445 - acc: 0.9657 - val_loss: 0.8329 - val_acc: 0.8906\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0604 - acc: 0.9869 - val_loss: 0.6550 - val_acc: 0.8854\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2205 - acc: 0.9586 - val_loss: 4.0844 - val_acc: 0.6406\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5150 - acc: 0.9244 - val_loss: 1.4642 - val_acc: 0.8274\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3430 - acc: 0.9325 - val_loss: 12.7127 - val_acc: 0.1615\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3081 - acc: 0.9587 - val_loss: 1.5264 - val_acc: 0.8385\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2280 - acc: 0.9688 - val_loss: 0.7025 - val_acc: 0.9219\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2802 - acc: 0.9567 - val_loss: 3.0778 - val_acc: 0.7135\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2089 - acc: 0.9617 - val_loss: 2.6403 - val_acc: 0.7656\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1567 - acc: 0.9657 - val_loss: 0.9390 - val_acc: 0.8929\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1487 - acc: 0.9628 - val_loss: 2.9929 - val_acc: 0.6823\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2876 - acc: 0.9649 - val_loss: 5.5126 - val_acc: 0.5990\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1274 - acc: 0.9828 - val_loss: 1.2427 - val_acc: 0.8646\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2870 - acc: 0.9558 - val_loss: 9.9340 - val_acc: 0.2812\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2727 - acc: 0.9547 - val_loss: 1.1646 - val_acc: 0.8333\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2472 - acc: 0.9586 - val_loss: 9.0482 - val_acc: 0.3750\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4687 - acc: 0.9387 - val_loss: 12.8163 - val_acc: 0.1667\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5075 - acc: 0.9314 - val_loss: 7.8925 - val_acc: 0.4531\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3139 - acc: 0.9486 - val_loss: 0.8790 - val_acc: 0.9115\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2293 - acc: 0.9657 - val_loss: 3.9997 - val_acc: 0.6845\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1994 - acc: 0.9657 - val_loss: 3.1440 - val_acc: 0.7344\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1834 - acc: 0.9718 - val_loss: 3.6211 - val_acc: 0.6979\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2357 - acc: 0.9729 - val_loss: 3.1106 - val_acc: 0.7344\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2708 - acc: 0.9668 - val_loss: 1.1505 - val_acc: 0.8958\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4634 - acc: 0.9456 - val_loss: 1.4514 - val_acc: 0.8750\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1304 - acc: 0.9056 - val_loss: 6.5950 - val_acc: 0.5238\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.9131 - acc: 0.9095 - val_loss: 4.8506 - val_acc: 0.6615\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6498 - acc: 0.9276 - val_loss: 4.2788 - val_acc: 0.6719\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4246 - acc: 0.9475 - val_loss: 2.5747 - val_acc: 0.8125\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4650 - acc: 0.9577 - val_loss: 3.1214 - val_acc: 0.7604\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4828 - acc: 0.9517 - val_loss: 2.2543 - val_acc: 0.8274\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4430 - acc: 0.9607 - val_loss: 13.1847 - val_acc: 0.1667\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7247 - acc: 0.9346 - val_loss: 8.9786 - val_acc: 0.3958\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4836 - acc: 0.9517 - val_loss: 6.6559 - val_acc: 0.5469\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9200 - acc: 0.9185 - val_loss: 2.8374 - val_acc: 0.7969\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4753 - acc: 0.9556 - val_loss: 4.8940 - val_acc: 0.6786\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9409 - acc: 0.9195 - val_loss: 13.9685 - val_acc: 0.1250\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.8910 - acc: 0.9306 - val_loss: 2.3925 - val_acc: 0.8333\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6291 - acc: 0.9446 - val_loss: 7.6792 - val_acc: 0.4948\n",
      "200/200 [==============================] - 2s 11ms/step\n",
      "Test accuracy: 0.509627727856\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 2.1073 - acc: 0.2760 - val_loss: 1.4657 - val_acc: 0.4167\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.7262 - acc: 0.3659 - val_loss: 1.2769 - val_acc: 0.4583\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6124 - acc: 0.3680 - val_loss: 1.2501 - val_acc: 0.5260\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6194 - acc: 0.3854 - val_loss: 1.4721 - val_acc: 0.4115\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.5654 - acc: 0.3993 - val_loss: 1.2280 - val_acc: 0.5573\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4999 - acc: 0.4456 - val_loss: 1.8706 - val_acc: 0.3333\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3992 - acc: 0.4679 - val_loss: 3.9843 - val_acc: 0.1905\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4723 - acc: 0.4445 - val_loss: 3.2629 - val_acc: 0.2344\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4159 - acc: 0.4556 - val_loss: 1.7012 - val_acc: 0.4010\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3487 - acc: 0.4749 - val_loss: 1.6912 - val_acc: 0.2865\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3862 - acc: 0.4870 - val_loss: 6.9099 - val_acc: 0.0990\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.3097 - acc: 0.5071 - val_loss: 6.7158 - val_acc: 0.1131\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2632 - acc: 0.4991 - val_loss: 7.8376 - val_acc: 0.1146\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2663 - acc: 0.5234 - val_loss: 4.9838 - val_acc: 0.1771\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2919 - acc: 0.5193 - val_loss: 4.8120 - val_acc: 0.1667\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3013 - acc: 0.5080 - val_loss: 5.7751 - val_acc: 0.1302\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2583 - acc: 0.5506 - val_loss: 4.1074 - val_acc: 0.2552\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1908 - acc: 0.5532 - val_loss: 0.8423 - val_acc: 0.7024\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1363 - acc: 0.5605 - val_loss: 0.7752 - val_acc: 0.6823\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.1772 - acc: 0.5686 - val_loss: 7.2253 - val_acc: 0.0781\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1718 - acc: 0.5485 - val_loss: 1.9462 - val_acc: 0.4427\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1517 - acc: 0.5724 - val_loss: 1.3693 - val_acc: 0.5312\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0592 - acc: 0.587 - 0s 15ms/step - loss: 1.0696 - acc: 0.5897 - val_loss: 0.6599 - val_acc: 0.7202\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1039 - acc: 0.5908 - val_loss: 0.6993 - val_acc: 0.7552\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0793 - acc: 0.5917 - val_loss: 2.8723 - val_acc: 0.3906\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0187 - acc: 0.6120 - val_loss: 0.6534 - val_acc: 0.7708\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.9788 - acc: 0.6441 - val_loss: 0.5729 - val_acc: 0.8229\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.9934 - acc: 0.6241 - val_loss: 0.6807 - val_acc: 0.7560\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0491 - acc: 0.6091 - val_loss: 2.0355 - val_acc: 0.4323\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9955 - acc: 0.6480 - val_loss: 1.9134 - val_acc: 0.4167\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9580 - acc: 0.6461 - val_loss: 0.5419 - val_acc: 0.8177\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9155 - acc: 0.6524 - val_loss: 0.5646 - val_acc: 0.8438\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9041 - acc: 0.6473 - val_loss: 1.0198 - val_acc: 0.5677\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.8914 - acc: 0.6653 - val_loss: 2.2958 - val_acc: 0.3452\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9816 - acc: 0.6322 - val_loss: 3.0247 - val_acc: 0.3125\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.8651 - acc: 0.6712 - val_loss: 2.9057 - val_acc: 0.3385\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.8255 - acc: 0.6824 - val_loss: 3.0646 - val_acc: 0.3333\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9366 - acc: 0.6503 - val_loss: 0.5703 - val_acc: 0.7917\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9181 - acc: 0.6654 - val_loss: 0.6990 - val_acc: 0.7083\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9422 - acc: 0.6556 - val_loss: 4.7409 - val_acc: 0.2656\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9427 - acc: 0.6594 - val_loss: 0.5520 - val_acc: 0.8021\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.8609 - acc: 0.6966 - val_loss: 0.4020 - val_acc: 0.8750\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.8143 - acc: 0.7014 - val_loss: 0.5146 - val_acc: 0.8073\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9237 - acc: 0.6737 - val_loss: 0.8793 - val_acc: 0.6845\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.8452 - acc: 0.6906 - val_loss: 2.2920 - val_acc: 0.4167\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.8537 - acc: 0.6936 - val_loss: 0.5358 - val_acc: 0.7865\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.8771 - acc: 0.6788 - val_loss: 0.9297 - val_acc: 0.6927\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.7858 - acc: 0.7065 - val_loss: 0.3381 - val_acc: 0.9219\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7345 - acc: 0.7188 - val_loss: 1.1491 - val_acc: 0.5781\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7764 - acc: 0.7207 - val_loss: 2.4592 - val_acc: 0.4762\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7365 - acc: 0.7348 - val_loss: 0.3707 - val_acc: 0.8854\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.8305 - acc: 0.7157 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0175 - acc: 0.6453 - val_loss: 0.6633 - val_acc: 0.7344\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7364 - acc: 0.7117 - val_loss: 1.5566 - val_acc: 0.4688\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7374 - acc: 0.7208 - val_loss: 2.4518 - val_acc: 0.5298\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.7623 - acc: 0.7399 - val_loss: 0.5997 - val_acc: 0.7396\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7263 - acc: 0.7329 - val_loss: 0.9470 - val_acc: 0.6667\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6750 - acc: 0.7440 - val_loss: 0.5214 - val_acc: 0.7865\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7310 - acc: 0.7340 - val_loss: 1.9716 - val_acc: 0.5052\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7197 - acc: 0.7402 - val_loss: 0.7334 - val_acc: 0.7381\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7797 - acc: 0.7158 - val_loss: 0.8430 - val_acc: 0.6667\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7365 - acc: 0.7138 - val_loss: 0.3238 - val_acc: 0.9062\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6772 - acc: 0.7439 - val_loss: 0.2582 - val_acc: 0.9531\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6463 - acc: 0.7702 - val_loss: 0.3541 - val_acc: 0.8542\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.7382 - acc: 0.7392 - val_loss: 0.2695 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6969 - acc: 0.7280 - val_loss: 0.2521 - val_acc: 0.9167\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6552 - acc: 0.7520 - val_loss: 3.0070 - val_acc: 0.3906\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6727 - acc: 0.7360 - val_loss: 0.3779 - val_acc: 0.8854\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6564 - acc: 0.7490 - val_loss: 0.2694 - val_acc: 0.9010\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6428 - acc: 0.7561 - val_loss: 10.6349 - val_acc: 0.2396\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6251 - acc: 0.7663 - val_loss: 14.6037 - val_acc: 0.0833\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.7145 - acc: 0.7410 - val_loss: 7.4811 - val_acc: 0.2760\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6784 - acc: 0.7521 - val_loss: 2.1743 - val_acc: 0.4740\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6540 - acc: 0.7573 - val_loss: 0.3153 - val_acc: 0.8958\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6730 - acc: 0.7550 - val_loss: 8.4484 - val_acc: 0.1562\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6121 - acc: 0.7732 - val_loss: 2.4777 - val_acc: 0.4286\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5481 - acc: 0.7913 - val_loss: 1.7545 - val_acc: 0.5260\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6851 - acc: 0.7542 - val_loss: 0.4363 - val_acc: 0.8542\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6448 - acc: 0.7652 - val_loss: 0.2475 - val_acc: 0.9323\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5406 - acc: 0.7944 - val_loss: 0.2379 - val_acc: 0.9167\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6604 - acc: 0.7694 - val_loss: 0.5666 - val_acc: 0.7865\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5431 - acc: 0.7943 - val_loss: 0.4503 - val_acc: 0.8512\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6022 - acc: 0.7783 - val_loss: 1.8432 - val_acc: 0.4635\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4906 - acc: 0.8155 - val_loss: 1.8158 - val_acc: 0.5156\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6005 - acc: 0.7864 - val_loss: 2.0872 - val_acc: 0.4948\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6478 - acc: 0.7701 - val_loss: 0.2881 - val_acc: 0.8906\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5760 - acc: 0.7966 - val_loss: 11.0959 - val_acc: 0.1369\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5258 - acc: 0.8034 - val_loss: 0.6095 - val_acc: 0.7656\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5516 - acc: 0.8075 - val_loss: 1.0349 - val_acc: 0.6823\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5521 - acc: 0.8065 - val_loss: 0.1808 - val_acc: 0.9323\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5734 - acc: 0.8035 - val_loss: 0.1256 - val_acc: 0.9792\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5031 - acc: 0.8165 - val_loss: 0.2001 - val_acc: 0.9345\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.9309 - acc: 0.7201 - val_loss: 1.4559 - val_acc: 0.6250\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5483 - acc: 0.8115 - val_loss: 0.2673 - val_acc: 0.8646\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5240 - acc: 0.8015 - val_loss: 0.1418 - val_acc: 0.9583\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5318 - acc: 0.7915 - val_loss: 0.2694 - val_acc: 0.9167\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5490 - acc: 0.7743 - val_loss: 0.2614 - val_acc: 0.9167\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5154 - acc: 0.8286 - val_loss: 0.1460 - val_acc: 0.9583\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5305 - acc: 0.8003 - val_loss: 0.8600 - val_acc: 0.7188\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5104 - acc: 0.8166 - val_loss: 0.3840 - val_acc: 0.8698\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.872122762148\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 6.3877 - acc: 0.1139 - val_loss: 8.3383 - val_acc: 0.1875\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 4.2799 - acc: 0.1905 - val_loss: 4.3950 - val_acc: 0.1667\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 3.4893 - acc: 0.2046 - val_loss: 5.5126 - val_acc: 0.1354\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 3.2218 - acc: 0.1946 - val_loss: 3.2577 - val_acc: 0.2396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 3.0692 - acc: 0.2078 - val_loss: 2.8803 - val_acc: 0.1927\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.9403 - acc: 0.2105 - val_loss: 1.9093 - val_acc: 0.3438\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.9078 - acc: 0.2157 - val_loss: 1.7945 - val_acc: 0.3274\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.8153 - acc: 0.2280 - val_loss: 2.5157 - val_acc: 0.2708\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.6220 - acc: 0.2340 - val_loss: 1.8402 - val_acc: 0.3594\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5934 - acc: 0.2258 - val_loss: 1.7880 - val_acc: 0.3229\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.4990 - acc: 0.2462 - val_loss: 2.1051 - val_acc: 0.2917\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5562 - acc: 0.2591 - val_loss: 1.7803 - val_acc: 0.3438\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.5906 - acc: 0.2380 - val_loss: 1.8022 - val_acc: 0.3095\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.3561 - acc: 0.2378 - val_loss: 1.8828 - val_acc: 0.3281\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.3439 - acc: 0.2460 - val_loss: 1.7987 - val_acc: 0.3438\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3107 - acc: 0.2529 - val_loss: 1.9968 - val_acc: 0.2656\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1942 - acc: 0.2471 - val_loss: 1.7369 - val_acc: 0.2865\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1392 - acc: 0.2510 - val_loss: 1.7066 - val_acc: 0.3512\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.3005 - acc: 0.2630 - val_loss: 1.7264 - val_acc: 0.3333\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1490 - acc: 0.2762 - val_loss: 1.8217 - val_acc: 0.3177\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.2378 - acc: 0.2620 - val_loss: 1.9046 - val_acc: 0.2760\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.2619 - acc: 0.2390 - val_loss: 1.8911 - val_acc: 0.2656\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.1514 - acc: 0.2359 - val_loss: 2.0473 - val_acc: 0.2202\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1663 - acc: 0.2702 - val_loss: 1.7250 - val_acc: 0.3333\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1853 - acc: 0.2511 - val_loss: 1.7342 - val_acc: 0.2969\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0689 - acc: 0.2781 - val_loss: 1.6147 - val_acc: 0.3385\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0583 - acc: 0.2692 - val_loss: 1.8612 - val_acc: 0.2656\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1099 - acc: 0.2660 - val_loss: 1.7120 - val_acc: 0.2708\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0367 - acc: 0.2611 - val_loss: 1.8045 - val_acc: 0.2857\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0301 - acc: 0.2849 - val_loss: 1.8567 - val_acc: 0.2812\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0853 - acc: 0.2855 - val_loss: 2.0473 - val_acc: 0.3021\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0812 - acc: 0.2391 - val_loss: 2.0390 - val_acc: 0.2135\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9494 - acc: 0.2582 - val_loss: 1.8321 - val_acc: 0.3021\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9792 - acc: 0.2713 - val_loss: 1.9331 - val_acc: 0.2679\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0207 - acc: 0.2762 - val_loss: 1.8548 - val_acc: 0.2708\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9613 - acc: 0.2925 - val_loss: 1.8466 - val_acc: 0.3438\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9733 - acc: 0.2880 - val_loss: 1.7816 - val_acc: 0.3229\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9977 - acc: 0.2813 - val_loss: 1.7797 - val_acc: 0.2865\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9325 - acc: 0.2892 - val_loss: 1.8958 - val_acc: 0.2143\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0093 - acc: 0.2743 - val_loss: 1.7472 - val_acc: 0.2865\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9130 - acc: 0.2532 - val_loss: 1.7295 - val_acc: 0.3333\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9637 - acc: 0.2601 - val_loss: 1.7837 - val_acc: 0.3281\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8942 - acc: 0.3025 - val_loss: 1.7072 - val_acc: 0.3646\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9057 - acc: 0.2451 - val_loss: 1.6839 - val_acc: 0.2865\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8726 - acc: 0.2834 - val_loss: 1.5861 - val_acc: 0.3929\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8834 - acc: 0.2662 - val_loss: 1.7161 - val_acc: 0.3646\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8879 - acc: 0.2833 - val_loss: 1.8104 - val_acc: 0.3333\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9465 - acc: 0.2743 - val_loss: 1.9346 - val_acc: 0.2604\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9448 - acc: 0.2734 - val_loss: 2.1190 - val_acc: 0.2396\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8832 - acc: 0.2974 - val_loss: 1.8664 - val_acc: 0.2798\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8755 - acc: 0.2936 - val_loss: 2.1511 - val_acc: 0.2188\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8728 - acc: 0.2904 - val_loss: 1.7120 - val_acc: 0.3281\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8139 - acc: 0.2894 - val_loss: 1.7499 - val_acc: 0.2865\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8720 - acc: 0.2853 - val_loss: 1.7407 - val_acc: 0.2969\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8215 - acc: 0.2913 - val_loss: 1.7851 - val_acc: 0.3274\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8478 - acc: 0.3005 - val_loss: 2.1318 - val_acc: 0.2083\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9057 - acc: 0.2824 - val_loss: 2.1003 - val_acc: 0.3073\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8159 - acc: 0.2953 - val_loss: 1.8658 - val_acc: 0.3073\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8192 - acc: 0.3135 - val_loss: 1.9698 - val_acc: 0.3021\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8828 - acc: 0.2794 - val_loss: 1.9737 - val_acc: 0.2760\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8578 - acc: 0.2752 - val_loss: 2.0327 - val_acc: 0.1905\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7902 - acc: 0.3197 - val_loss: 1.8025 - val_acc: 0.3177\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8237 - acc: 0.3055 - val_loss: 1.9570 - val_acc: 0.2812\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8174 - acc: 0.3114 - val_loss: 1.6368 - val_acc: 0.3646\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7832 - acc: 0.3115 - val_loss: 1.9285 - val_acc: 0.3073\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8547 - acc: 0.3025 - val_loss: 1.7954 - val_acc: 0.3393\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8434 - acc: 0.2943 - val_loss: 1.8250 - val_acc: 0.3177\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8188 - acc: 0.3144 - val_loss: 1.7615 - val_acc: 0.3438\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7976 - acc: 0.3247 - val_loss: 1.8771 - val_acc: 0.3073\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9016 - acc: 0.2815 - val_loss: 1.7764 - val_acc: 0.2969\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8223 - acc: 0.2875 - val_loss: 1.8426 - val_acc: 0.2560\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8288 - acc: 0.3015 - val_loss: 2.1276 - val_acc: 0.2552\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8055 - acc: 0.3096 - val_loss: 2.7992 - val_acc: 0.1302\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8774 - acc: 0.2834 - val_loss: 3.1699 - val_acc: 0.1146\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8088 - acc: 0.2984 - val_loss: 2.6702 - val_acc: 0.1615\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7554 - acc: 0.3215 - val_loss: 2.6957 - val_acc: 0.1667\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8728 - acc: 0.3105 - val_loss: 1.8435 - val_acc: 0.3512\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8398 - acc: 0.3175 - val_loss: 1.7612 - val_acc: 0.3646\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7718 - acc: 0.3186 - val_loss: 1.9988 - val_acc: 0.2656\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7884 - acc: 0.3055 - val_loss: 2.0576 - val_acc: 0.3125\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8057 - acc: 0.3144 - val_loss: 2.4995 - val_acc: 0.2083\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7611 - acc: 0.3145 - val_loss: 2.2200 - val_acc: 0.2798\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7458 - acc: 0.3207 - val_loss: 2.5596 - val_acc: 0.1615\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7894 - acc: 0.3185 - val_loss: 2.1987 - val_acc: 0.2500\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7917 - acc: 0.3106 - val_loss: 1.8837 - val_acc: 0.3333\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8194 - acc: 0.3034 - val_loss: 2.0685 - val_acc: 0.2865\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7987 - acc: 0.3185 - val_loss: 1.7962 - val_acc: 0.3810\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7218 - acc: 0.3547 - val_loss: 2.2214 - val_acc: 0.2396\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7897 - acc: 0.3057 - val_loss: 1.9131 - val_acc: 0.3646\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7874 - acc: 0.3145 - val_loss: 1.8718 - val_acc: 0.3333\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7895 - acc: 0.3116 - val_loss: 1.7200 - val_acc: 0.3594\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7799 - acc: 0.3316 - val_loss: 1.7308 - val_acc: 0.3281\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7523 - acc: 0.3278 - val_loss: 1.6275 - val_acc: 0.3214\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7797 - acc: 0.3115 - val_loss: 1.5931 - val_acc: 0.4167\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7887 - acc: 0.3125 - val_loss: 1.6808 - val_acc: 0.3750\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.7648 - acc: 0.3185 - val_loss: 1.6400 - val_acc: 0.3542\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7453 - acc: 0.3115 - val_loss: 1.5493 - val_acc: 0.4271\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7497 - acc: 0.3278 - val_loss: 1.6744 - val_acc: 0.3869\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7802 - acc: 0.3358 - val_loss: 1.6390 - val_acc: 0.3542\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7746 - acc: 0.3235 - val_loss: 1.5811 - val_acc: 0.4271\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.404411764706\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 3.2499 - acc: 0.1511 - val_loss: 2.3826 - val_acc: 0.1302\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.2980 - acc: 0.1825 - val_loss: 2.2441 - val_acc: 0.1726\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1853 - acc: 0.1937 - val_loss: 2.2215 - val_acc: 0.1823\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.2080 - acc: 0.1794 - val_loss: 1.9445 - val_acc: 0.3125\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.1259 - acc: 0.1997 - val_loss: 1.8318 - val_acc: 0.3229\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.0953 - acc: 0.2167 - val_loss: 1.9156 - val_acc: 0.2917\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0840 - acc: 0.2217 - val_loss: 2.1502 - val_acc: 0.1771\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1007 - acc: 0.2157 - val_loss: 1.8302 - val_acc: 0.3214\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0973 - acc: 0.2077 - val_loss: 1.8060 - val_acc: 0.3594\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0950 - acc: 0.2026 - val_loss: 1.8777 - val_acc: 0.3490\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1077 - acc: 0.1865 - val_loss: 1.9525 - val_acc: 0.2865\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0087 - acc: 0.2359 - val_loss: 1.8172 - val_acc: 0.2812\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0810 - acc: 0.2410 - val_loss: 1.8847 - val_acc: 0.2619\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0677 - acc: 0.2330 - val_loss: 1.7704 - val_acc: 0.3438\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0527 - acc: 0.2319 - val_loss: 1.9448 - val_acc: 0.2292\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0560 - acc: 0.2250 - val_loss: 1.8057 - val_acc: 0.2708\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9974 - acc: 0.2398 - val_loss: 1.8712 - val_acc: 0.2552\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1004 - acc: 0.2369 - val_loss: 1.7918 - val_acc: 0.2798\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0281 - acc: 0.2360 - val_loss: 1.7896 - val_acc: 0.3333\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0091 - acc: 0.2380 - val_loss: 1.7330 - val_acc: 0.3802\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0316 - acc: 0.2288 - val_loss: 1.7342 - val_acc: 0.3073\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0118 - acc: 0.2459 - val_loss: 1.7507 - val_acc: 0.3125\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9938 - acc: 0.2580 - val_loss: 1.7178 - val_acc: 0.3438\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9894 - acc: 0.2380 - val_loss: 1.9076 - val_acc: 0.2440\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9702 - acc: 0.2509 - val_loss: 2.2067 - val_acc: 0.1458\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9503 - acc: 0.2512 - val_loss: 2.0858 - val_acc: 0.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9965 - acc: 0.2158 - val_loss: 1.7276 - val_acc: 0.3490\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9899 - acc: 0.2418 - val_loss: 1.8074 - val_acc: 0.2656\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9888 - acc: 0.2369 - val_loss: 1.6467 - val_acc: 0.3214\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9677 - acc: 0.2512 - val_loss: 1.9158 - val_acc: 0.2865\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0195 - acc: 0.2521 - val_loss: 2.0205 - val_acc: 0.2240\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0374 - acc: 0.2239 - val_loss: 1.8852 - val_acc: 0.2760\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0105 - acc: 0.2308 - val_loss: 1.7283 - val_acc: 0.3281\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0536 - acc: 0.2420 - val_loss: 1.8675 - val_acc: 0.2440\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0477 - acc: 0.2480 - val_loss: 1.7153 - val_acc: 0.3438\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9945 - acc: 0.2350 - val_loss: 1.7989 - val_acc: 0.3125\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0065 - acc: 0.2288 - val_loss: 1.8910 - val_acc: 0.2708\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0222 - acc: 0.2340 - val_loss: 2.2813 - val_acc: 0.1667\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1000 - acc: 0.2289 - val_loss: 2.7719 - val_acc: 0.1667\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0473 - acc: 0.2328 - val_loss: 2.3282 - val_acc: 0.2083\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9617 - acc: 0.2721 - val_loss: 1.6669 - val_acc: 0.3802\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9910 - acc: 0.2490 - val_loss: 1.7734 - val_acc: 0.3333\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9645 - acc: 0.2551 - val_loss: 2.0055 - val_acc: 0.2240\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9686 - acc: 0.2389 - val_loss: 1.9649 - val_acc: 0.2292\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0551 - acc: 0.2270 - val_loss: 1.8320 - val_acc: 0.2738\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0411 - acc: 0.2360 - val_loss: 1.9172 - val_acc: 0.2656\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9300 - acc: 0.2752 - val_loss: 2.4999 - val_acc: 0.1146\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9682 - acc: 0.2581 - val_loss: 1.8691 - val_acc: 0.3073\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0230 - acc: 0.2460 - val_loss: 2.2042 - val_acc: 0.1823\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9561 - acc: 0.2942 - val_loss: 1.7332 - val_acc: 0.3095\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9686 - acc: 0.2600 - val_loss: 1.6682 - val_acc: 0.4010\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0248 - acc: 0.2418 - val_loss: 1.6759 - val_acc: 0.3073\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9879 - acc: 0.2530 - val_loss: 1.6239 - val_acc: 0.3594\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9434 - acc: 0.2580 - val_loss: 1.6453 - val_acc: 0.3854\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9888 - acc: 0.2401 - val_loss: 1.6487 - val_acc: 0.3542\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9938 - acc: 0.2591 - val_loss: 2.7865 - val_acc: 0.1845\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9826 - acc: 0.2300 - val_loss: 2.2531 - val_acc: 0.1875\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9793 - acc: 0.2832 - val_loss: 2.2900 - val_acc: 0.1667\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9325 - acc: 0.2703 - val_loss: 1.8189 - val_acc: 0.2656\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0012 - acc: 0.2518 - val_loss: 1.9920 - val_acc: 0.1875\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0530 - acc: 0.2551 - val_loss: 1.8693 - val_acc: 0.3333\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0322 - acc: 0.2418 - val_loss: 1.8159 - val_acc: 0.2552\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9443 - acc: 0.2852 - val_loss: 1.8714 - val_acc: 0.1927\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9843 - acc: 0.2469 - val_loss: 1.7316 - val_acc: 0.3594\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9960 - acc: 0.2540 - val_loss: 1.7784 - val_acc: 0.3594\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9616 - acc: 0.2611 - val_loss: 1.6951 - val_acc: 0.2798\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9484 - acc: 0.2824 - val_loss: 1.6600 - val_acc: 0.3750\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9660 - acc: 0.2521 - val_loss: 1.6111 - val_acc: 0.3021\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9975 - acc: 0.2419 - val_loss: 1.7938 - val_acc: 0.3125\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9802 - acc: 0.2581 - val_loss: 1.8002 - val_acc: 0.2865\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9109 - acc: 0.2803 - val_loss: 1.6688 - val_acc: 0.3333\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0029 - acc: 0.2410 - val_loss: 1.7560 - val_acc: 0.3333\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0149 - acc: 0.2528 - val_loss: 1.6341 - val_acc: 0.2865\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9300 - acc: 0.2681 - val_loss: 1.7595 - val_acc: 0.2812\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0108 - acc: 0.2401 - val_loss: 1.7471 - val_acc: 0.3229\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0197 - acc: 0.2640 - val_loss: 1.6970 - val_acc: 0.3958\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9639 - acc: 0.2530 - val_loss: 1.8454 - val_acc: 0.2976\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9686 - acc: 0.2601 - val_loss: 2.1438 - val_acc: 0.1979\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0097 - acc: 0.2390 - val_loss: 1.6957 - val_acc: 0.3385\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0295 - acc: 0.2379 - val_loss: 1.6300 - val_acc: 0.3542\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9742 - acc: 0.2501 - val_loss: 2.0553 - val_acc: 0.2240\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9549 - acc: 0.2461 - val_loss: 2.2314 - val_acc: 0.3036\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9819 - acc: 0.2589 - val_loss: 2.4465 - val_acc: 0.1198\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9445 - acc: 0.2600 - val_loss: 1.7930 - val_acc: 0.2240\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9943 - acc: 0.2641 - val_loss: 1.6966 - val_acc: 0.2865\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9444 - acc: 0.2672 - val_loss: 1.7505 - val_acc: 0.3490\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.0220 - acc: 0.2451 - val_loss: 1.6294 - val_acc: 0.3958\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8913 - acc: 0.2591 - val_loss: 1.7957 - val_acc: 0.3690\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8998 - acc: 0.2661 - val_loss: 1.7281 - val_acc: 0.3073\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9876 - acc: 0.2682 - val_loss: 1.8832 - val_acc: 0.2188\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9128 - acc: 0.2608 - val_loss: 1.9180 - val_acc: 0.3125\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9727 - acc: 0.2542 - val_loss: 1.9278 - val_acc: 0.2240\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9952 - acc: 0.2722 - val_loss: 1.7536 - val_acc: 0.2500\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8652 - acc: 0.2982 - val_loss: 2.1939 - val_acc: 0.1667\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0259 - acc: 0.2501 - val_loss: 2.3751 - val_acc: 0.1927\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9178 - acc: 0.2682 - val_loss: 2.3073 - val_acc: 0.2917\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9232 - acc: 0.2661 - val_loss: 2.3473 - val_acc: 0.2344\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9591 - acc: 0.2801 - val_loss: 1.8480 - val_acc: 0.3155\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9236 - acc: 0.2720 - val_loss: 1.9080 - val_acc: 0.2969\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8945 - acc: 0.2942 - val_loss: 1.9010 - val_acc: 0.2604\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.30594629156\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 2.7692 - acc: 0.1109 - val_loss: 2.2485 - val_acc: 0.0938\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.3540 - acc: 0.1745 - val_loss: 2.1191 - val_acc: 0.2083\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.3177 - acc: 0.1583 - val_loss: 2.1433 - val_acc: 0.2381\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.2742 - acc: 0.1613 - val_loss: 2.0400 - val_acc: 0.1406\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.2095 - acc: 0.1765 - val_loss: 2.0779 - val_acc: 0.2344\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1904 - acc: 0.1632 - val_loss: 2.0263 - val_acc: 0.2188\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.1691 - acc: 0.1926 - val_loss: 2.0358 - val_acc: 0.1510\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1267 - acc: 0.1897 - val_loss: 2.0015 - val_acc: 0.2083\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.1279 - acc: 0.1916 - val_loss: 2.0992 - val_acc: 0.1562\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0879 - acc: 0.1976 - val_loss: 2.1828 - val_acc: 0.1198\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0826 - acc: 0.2056 - val_loss: 2.3063 - val_acc: 0.0781\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0719 - acc: 0.2369 - val_loss: 2.1680 - val_acc: 0.1510\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0515 - acc: 0.2298 - val_loss: 2.1230 - val_acc: 0.1964\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0561 - acc: 0.2307 - val_loss: 2.7163 - val_acc: 0.1875\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0000 - acc: 0.2418 - val_loss: 3.0053 - val_acc: 0.0781\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0607 - acc: 0.2289 - val_loss: 1.8816 - val_acc: 0.2656\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0286 - acc: 0.2148 - val_loss: 2.1694 - val_acc: 0.1875\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9919 - acc: 0.2490 - val_loss: 2.2266 - val_acc: 0.1875\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9459 - acc: 0.2409 - val_loss: 2.2626 - val_acc: 0.1845\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0378 - acc: 0.2240 - val_loss: 1.8643 - val_acc: 0.2396\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0200 - acc: 0.2198 - val_loss: 1.9390 - val_acc: 0.2969\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0105 - acc: 0.2179 - val_loss: 1.8365 - val_acc: 0.2969\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.0285 - acc: 0.2290 - val_loss: 1.9108 - val_acc: 0.2708\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9559 - acc: 0.2530 - val_loss: 2.9397 - val_acc: 0.2024\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9957 - acc: 0.2549 - val_loss: 2.6168 - val_acc: 0.0990\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9446 - acc: 0.2491 - val_loss: 3.3939 - val_acc: 0.1406\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.9547 - acc: 0.2620 - val_loss: 2.3875 - val_acc: 0.2031\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9967 - acc: 0.2360 - val_loss: 3.9795 - val_acc: 0.1042\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9579 - acc: 0.2651 - val_loss: 4.1155 - val_acc: 0.1310\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0095 - acc: 0.2318 - val_loss: 2.8594 - val_acc: 0.1302\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9314 - acc: 0.2450 - val_loss: 2.0374 - val_acc: 0.2135\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9558 - acc: 0.2401 - val_loss: 2.4034 - val_acc: 0.1875\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 2.0171 - acc: 0.2592 - val_loss: 2.3220 - val_acc: 0.1354\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9725 - acc: 0.2480 - val_loss: 2.1782 - val_acc: 0.1927\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9735 - acc: 0.2612 - val_loss: 2.3461 - val_acc: 0.1369\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9271 - acc: 0.2529 - val_loss: 2.4492 - val_acc: 0.2031\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9405 - acc: 0.2491 - val_loss: 2.7117 - val_acc: 0.1927\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9487 - acc: 0.2662 - val_loss: 2.7580 - val_acc: 0.1094\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9511 - acc: 0.2561 - val_loss: 2.2182 - val_acc: 0.1354\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9231 - acc: 0.2500 - val_loss: 3.5628 - val_acc: 0.0714\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8881 - acc: 0.2793 - val_loss: 2.6569 - val_acc: 0.2083\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8930 - acc: 0.2631 - val_loss: 5.5199 - val_acc: 0.1250\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9048 - acc: 0.2681 - val_loss: 2.7035 - val_acc: 0.1146\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9138 - acc: 0.2713 - val_loss: 2.2135 - val_acc: 0.1823\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9716 - acc: 0.2662 - val_loss: 2.6199 - val_acc: 0.2143\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9131 - acc: 0.2552 - val_loss: 4.4450 - val_acc: 0.1094\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9141 - acc: 0.2583 - val_loss: 2.8212 - val_acc: 0.1979\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.0042 - acc: 0.2420 - val_loss: 2.3389 - val_acc: 0.1302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9249 - acc: 0.2651 - val_loss: 4.7249 - val_acc: 0.0833\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8770 - acc: 0.2692 - val_loss: 1.8539 - val_acc: 0.2760\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9396 - acc: 0.2571 - val_loss: 2.2282 - val_acc: 0.1310\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8722 - acc: 0.2821 - val_loss: 3.4117 - val_acc: 0.0885\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9740 - acc: 0.2350 - val_loss: 2.2763 - val_acc: 0.1354\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9092 - acc: 0.2732 - val_loss: 2.0264 - val_acc: 0.2292\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9141 - acc: 0.2582 - val_loss: 1.9176 - val_acc: 0.2344\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8994 - acc: 0.2733 - val_loss: 1.7470 - val_acc: 0.2798\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8875 - acc: 0.2714 - val_loss: 1.9878 - val_acc: 0.2188\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9117 - acc: 0.2873 - val_loss: 1.8297 - val_acc: 0.3073\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8875 - acc: 0.2703 - val_loss: 1.9417 - val_acc: 0.1406\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9181 - acc: 0.2600 - val_loss: 2.7021 - val_acc: 0.1875\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8914 - acc: 0.2803 - val_loss: 1.8265 - val_acc: 0.2857\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8995 - acc: 0.2570 - val_loss: 1.9611 - val_acc: 0.2448\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8741 - acc: 0.2893 - val_loss: 1.9964 - val_acc: 0.2396\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8391 - acc: 0.2710 - val_loss: 1.8388 - val_acc: 0.2240\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8979 - acc: 0.2713 - val_loss: 1.9885 - val_acc: 0.2500\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8976 - acc: 0.2651 - val_loss: 1.7336 - val_acc: 0.3385\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7832 - acc: 0.3074 - val_loss: 1.7815 - val_acc: 0.3095\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8527 - acc: 0.2704 - val_loss: 1.8063 - val_acc: 0.2240\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8936 - acc: 0.2743 - val_loss: 1.9044 - val_acc: 0.2448\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8889 - acc: 0.2692 - val_loss: 1.9484 - val_acc: 0.1771\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7876 - acc: 0.3005 - val_loss: 2.1273 - val_acc: 0.1250\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8600 - acc: 0.2953 - val_loss: 2.4172 - val_acc: 0.1071\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8833 - acc: 0.2880 - val_loss: 1.8814 - val_acc: 0.2604\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8308 - acc: 0.2742 - val_loss: 2.4588 - val_acc: 0.1875\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8580 - acc: 0.2956 - val_loss: 1.9238 - val_acc: 0.2083\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8912 - acc: 0.2802 - val_loss: 2.4999 - val_acc: 0.1042\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8998 - acc: 0.2794 - val_loss: 2.0806 - val_acc: 0.1845\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8930 - acc: 0.2764 - val_loss: 1.8197 - val_acc: 0.2448\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8289 - acc: 0.2863 - val_loss: 1.9211 - val_acc: 0.2448\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8514 - acc: 0.2691 - val_loss: 2.4826 - val_acc: 0.2031\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9008 - acc: 0.2561 - val_loss: 2.0327 - val_acc: 0.2083\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8227 - acc: 0.2964 - val_loss: 2.2660 - val_acc: 0.0990\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8492 - acc: 0.2802 - val_loss: 2.1090 - val_acc: 0.2083\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8936 - acc: 0.2531 - val_loss: 2.1447 - val_acc: 0.1354\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9657 - acc: 0.2472 - val_loss: 5.1160 - val_acc: 0.0833\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9393 - acc: 0.2620 - val_loss: 3.0006 - val_acc: 0.0781\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8960 - acc: 0.2704 - val_loss: 1.9219 - val_acc: 0.2760\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8526 - acc: 0.2813 - val_loss: 1.9181 - val_acc: 0.2024\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.9029 - acc: 0.2623 - val_loss: 2.2682 - val_acc: 0.1615\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8938 - acc: 0.2529 - val_loss: 3.1967 - val_acc: 0.0990\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9139 - acc: 0.2761 - val_loss: 2.8508 - val_acc: 0.1302\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8291 - acc: 0.2750 - val_loss: 2.2117 - val_acc: 0.1354\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8143 - acc: 0.3046 - val_loss: 2.2533 - val_acc: 0.1429\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8210 - acc: 0.2804 - val_loss: 2.0172 - val_acc: 0.2083\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8128 - acc: 0.2933 - val_loss: 2.1528 - val_acc: 0.1667\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8766 - acc: 0.2734 - val_loss: 2.2848 - val_acc: 0.1198\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9036 - acc: 0.2659 - val_loss: 1.9419 - val_acc: 0.2135\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8298 - acc: 0.2993 - val_loss: 1.7886 - val_acc: 0.2656\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8669 - acc: 0.2629 - val_loss: 1.9952 - val_acc: 0.1190\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8608 - acc: 0.2572 - val_loss: 2.6762 - val_acc: 0.1354\n",
      "200/200 [==============================] - 2s 12ms/step\n",
      "Test accuracy: 0.12676508344\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 2.1320 - acc: 0.3590 - val_loss: 2.7683 - val_acc: 0.3229\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 1.4666 - acc: 0.4717 - val_loss: 2.0381 - val_acc: 0.3385\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1756 - acc: 0.5513 - val_loss: 4.7078 - val_acc: 0.1667\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0001 - acc: 0.6261 - val_loss: 14.3560 - val_acc: 0.0938\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9153 - acc: 0.6523 - val_loss: 2.3780 - val_acc: 0.3281\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8240 - acc: 0.7168 - val_loss: 3.6030 - val_acc: 0.2552\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.7580 - acc: 0.7240 - val_loss: 10.8191 - val_acc: 0.1250\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.5988 - acc: 0.7942 - val_loss: 1.8514 - val_acc: 0.5060\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.6475 - acc: 0.7642 - val_loss: 9.2007 - val_acc: 0.1979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5689 - acc: 0.8103 - val_loss: 1.7785 - val_acc: 0.5260\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4712 - acc: 0.8436 - val_loss: 1.8393 - val_acc: 0.4635\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6036 - acc: 0.8066 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.5139 - acc: 0.8093 - val_loss: 13.9199 - val_acc: 0.0729\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.4401 - acc: 0.8521 - val_loss: 13.9628 - val_acc: 0.0833\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4634 - acc: 0.8419 - val_loss: 0.6875 - val_acc: 0.7865\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3809 - acc: 0.8689 - val_loss: 10.0213 - val_acc: 0.1198\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3359 - acc: 0.8861 - val_loss: 9.6430 - val_acc: 0.1250\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3214 - acc: 0.8743 - val_loss: 1.5408 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2777 - acc: 0.9052 - val_loss: 1.4128 - val_acc: 0.5833\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2563 - acc: 0.9143 - val_loss: 0.1589 - val_acc: 0.9583\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2472 - acc: 0.9194 - val_loss: 0.9184 - val_acc: 0.7396\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2456 - acc: 0.9124 - val_loss: 0.1577 - val_acc: 0.9583\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2421 - acc: 0.9265 - val_loss: 1.5506 - val_acc: 0.5990\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.2693 - acc: 0.9083 - val_loss: 0.1883 - val_acc: 0.9405\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1957 - acc: 0.9415 - val_loss: 0.2270 - val_acc: 0.9271\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4214 - acc: 0.8599 - val_loss: 3.0726 - val_acc: 0.4375\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3559 - acc: 0.8946 - val_loss: 8.4207 - val_acc: 0.1510\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2224 - acc: 0.9203 - val_loss: 0.2703 - val_acc: 0.9167\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3185 - acc: 0.8974 - val_loss: 1.0028 - val_acc: 0.6927\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.2145 - acc: 0.9213 - val_loss: 0.3774 - val_acc: 0.8810\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2046 - acc: 0.9256 - val_loss: 0.6380 - val_acc: 0.7812\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1542 - acc: 0.9506 - val_loss: 0.1266 - val_acc: 0.9688\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1955 - acc: 0.9334 - val_loss: 0.3108 - val_acc: 0.9271\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1901 - acc: 0.9305 - val_loss: 0.1832 - val_acc: 0.9427\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1902 - acc: 0.9375 - val_loss: 0.1811 - val_acc: 0.9345\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1425 - acc: 0.9547 - val_loss: 0.2085 - val_acc: 0.9167\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1697 - acc: 0.9345 - val_loss: 0.0998 - val_acc: 0.9635\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1452 - acc: 0.9475 - val_loss: 0.2908 - val_acc: 0.9271\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1854 - acc: 0.9366 - val_loss: 0.2190 - val_acc: 0.9271\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1386 - acc: 0.9476 - val_loss: 0.2891 - val_acc: 0.8929\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1657 - acc: 0.9536 - val_loss: 0.1920 - val_acc: 0.9531\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1360 - acc: 0.9476 - val_loss: 0.0861 - val_acc: 0.9635\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1514 - acc: 0.9405 - val_loss: 0.1869 - val_acc: 0.9531\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1143 - acc: 0.9658 - val_loss: 0.7906 - val_acc: 0.7604\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1035 - acc: 0.9667 - val_loss: 0.1840 - val_acc: 0.9219\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1308 - acc: 0.9516 - val_loss: 0.3003 - val_acc: 0.9286\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1360 - acc: 0.9507 - val_loss: 0.0556 - val_acc: 0.9844\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1402 - acc: 0.9566 - val_loss: 0.1028 - val_acc: 0.9688\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1291 - acc: 0.9526 - val_loss: 0.0616 - val_acc: 0.9844\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1049 - acc: 0.9637 - val_loss: 0.1278 - val_acc: 0.9740\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1438 - acc: 0.9457 - val_loss: 0.1919 - val_acc: 0.9583\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1187 - acc: 0.9596 - val_loss: 0.0488 - val_acc: 0.9844\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2089 - acc: 0.9377 - val_loss: 0.2471 - val_acc: 0.9427\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1084 - acc: 0.9677 - val_loss: 1.7745 - val_acc: 0.5417\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1549 - acc: 0.9508 - val_loss: 0.0508 - val_acc: 0.9896\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1209 - acc: 0.9647 - val_loss: 0.1025 - val_acc: 0.9762\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1255 - acc: 0.9538 - val_loss: 0.1788 - val_acc: 0.9583\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1328 - acc: 0.9618 - val_loss: 0.4853 - val_acc: 0.8594\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1051 - acc: 0.9608 - val_loss: 3.1555 - val_acc: 0.4844\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1248 - acc: 0.9557 - val_loss: 0.1857 - val_acc: 0.9375\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1162 - acc: 0.9677 - val_loss: 0.0918 - val_acc: 0.9844\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0928 - acc: 0.9597 - val_loss: 0.2272 - val_acc: 0.9345\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1262 - acc: 0.9549 - val_loss: 0.1581 - val_acc: 0.9323\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1114 - acc: 0.9617 - val_loss: 0.0927 - val_acc: 0.9635\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1038 - acc: 0.9697 - val_loss: 0.0738 - val_acc: 0.9896\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1163 - acc: 0.9618 - val_loss: 0.3094 - val_acc: 0.9115\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3568 - acc: 0.9022 - val_loss: 4.3492 - val_acc: 0.2560\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2438 - acc: 0.9184 - val_loss: 3.3648 - val_acc: 0.4271\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1419 - acc: 0.9506 - val_loss: 0.3590 - val_acc: 0.9062\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1115 - acc: 0.9577 - val_loss: 0.7263 - val_acc: 0.8177\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1306 - acc: 0.9556 - val_loss: 0.3281 - val_acc: 0.9271\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1295 - acc: 0.9586 - val_loss: 1.0481 - val_acc: 0.7619\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1037 - acc: 0.9607 - val_loss: 0.9366 - val_acc: 0.7604\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1274 - acc: 0.9498 - val_loss: 1.2317 - val_acc: 0.6979\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1450 - acc: 0.9417 - val_loss: 0.2046 - val_acc: 0.9583\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1388 - acc: 0.9576 - val_loss: 0.1113 - val_acc: 0.9635\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1157 - acc: 0.9608 - val_loss: 0.4276 - val_acc: 0.8646\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0726 - acc: 0.9758 - val_loss: 0.1029 - val_acc: 0.9762\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0960 - acc: 0.9718 - val_loss: 0.1250 - val_acc: 0.9792\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0919 - acc: 0.9698 - val_loss: 0.2004 - val_acc: 0.9635\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0793 - acc: 0.9778 - val_loss: 0.0640 - val_acc: 0.9844\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1618 - acc: 0.9498 - val_loss: 0.1445 - val_acc: 0.9531\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0742 - acc: 0.9768 - val_loss: 0.1197 - val_acc: 0.9345\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0630 - acc: 0.9808 - val_loss: 0.0836 - val_acc: 0.9583\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0619 - acc: 0.9748 - val_loss: 0.1680 - val_acc: 0.9688\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1205 - acc: 0.9598 - val_loss: 0.0829 - val_acc: 0.9792\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0655 - acc: 0.9778 - val_loss: 0.3331 - val_acc: 0.9115\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0698 - acc: 0.9808 - val_loss: 0.0329 - val_acc: 0.9881\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0707 - acc: 0.9758 - val_loss: 0.1050 - val_acc: 0.9635\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0775 - acc: 0.9658 - val_loss: 0.1441 - val_acc: 0.9688\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0886 - acc: 0.9707 - val_loss: 0.0555 - val_acc: 0.9844\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0902 - acc: 0.9669 - val_loss: 0.0566 - val_acc: 0.9792\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0649 - acc: 0.9768 - val_loss: 0.1698 - val_acc: 0.9792\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0674 - acc: 0.9839 - val_loss: 0.0214 - val_acc: 0.9940\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2461 - acc: 0.9244 - val_loss: 0.4283 - val_acc: 0.8594\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1847 - acc: 0.9376 - val_loss: 0.7233 - val_acc: 0.8281\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1477 - acc: 0.9516 - val_loss: 0.7600 - val_acc: 0.8177\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.1466 - acc: 0.9496 - val_loss: 0.0677 - val_acc: 0.9844\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1174 - acc: 0.9566 - val_loss: 0.0871 - val_acc: 0.9762\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0779 - acc: 0.9758 - val_loss: 0.0846 - val_acc: 0.9896\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.978900255754\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 3.4733 - acc: 0.1380 - val_loss: 1.7248 - val_acc: 0.3698\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 2.4962 - acc: 0.1965 - val_loss: 2.6999 - val_acc: 0.1250\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.1610 - acc: 0.2387 - val_loss: 2.3884 - val_acc: 0.1607\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.0839 - acc: 0.2316 - val_loss: 1.7949 - val_acc: 0.2552\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9795 - acc: 0.2723 - val_loss: 1.5161 - val_acc: 0.4792\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.9148 - acc: 0.2762 - val_loss: 1.5923 - val_acc: 0.3802\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9066 - acc: 0.2761 - val_loss: 1.6221 - val_acc: 0.3906\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.9235 - acc: 0.2804 - val_loss: 1.5996 - val_acc: 0.3802\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8583 - acc: 0.3054 - val_loss: 1.6342 - val_acc: 0.3810\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.8804 - acc: 0.3085 - val_loss: 1.9634 - val_acc: 0.2344\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8048 - acc: 0.2994 - val_loss: 2.0694 - val_acc: 0.1875\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.8078 - acc: 0.3164 - val_loss: 1.7352 - val_acc: 0.3490\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7804 - acc: 0.3235 - val_loss: 2.5656 - val_acc: 0.2083\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7702 - acc: 0.3115 - val_loss: 2.1009 - val_acc: 0.1369\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8241 - acc: 0.3228 - val_loss: 2.3715 - val_acc: 0.1615\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7264 - acc: 0.3325 - val_loss: 2.1136 - val_acc: 0.1667\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7199 - acc: 0.3316 - val_loss: 1.6870 - val_acc: 0.3438\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7634 - acc: 0.3207 - val_loss: 2.6708 - val_acc: 0.1302\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.7192 - acc: 0.3428 - val_loss: 1.4777 - val_acc: 0.4345\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7443 - acc: 0.3196 - val_loss: 1.4899 - val_acc: 0.4688\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7254 - acc: 0.3307 - val_loss: 1.6806 - val_acc: 0.3854\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7259 - acc: 0.3266 - val_loss: 1.8633 - val_acc: 0.2552\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6512 - acc: 0.3711 - val_loss: 1.7005 - val_acc: 0.3438\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6624 - acc: 0.3640 - val_loss: 1.4620 - val_acc: 0.5365\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6756 - acc: 0.3631 - val_loss: 2.0400 - val_acc: 0.2024\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7239 - acc: 0.3417 - val_loss: 1.5028 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.7110 - acc: 0.3609 - val_loss: 2.3271 - val_acc: 0.1927\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6569 - acc: 0.3931 - val_loss: 1.7617 - val_acc: 0.3750\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6393 - acc: 0.3751 - val_loss: 1.3799 - val_acc: 0.5104\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6827 - acc: 0.3379 - val_loss: 1.4672 - val_acc: 0.4286\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6392 - acc: 0.3789 - val_loss: 1.4710 - val_acc: 0.5104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5873 - acc: 0.4082 - val_loss: 2.1963 - val_acc: 0.2135\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6212 - acc: 0.3669 - val_loss: 1.5681 - val_acc: 0.4010\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6511 - acc: 0.3649 - val_loss: 1.4339 - val_acc: 0.4896\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6459 - acc: 0.3591 - val_loss: 1.6327 - val_acc: 0.3750\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5875 - acc: 0.3852 - val_loss: 1.3129 - val_acc: 0.5260\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6232 - acc: 0.3951 - val_loss: 1.4832 - val_acc: 0.4740\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6606 - acc: 0.3590 - val_loss: 1.7581 - val_acc: 0.3177\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6657 - acc: 0.3790 - val_loss: 2.1153 - val_acc: 0.2500\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6103 - acc: 0.3799 - val_loss: 1.3530 - val_acc: 0.4844\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6294 - acc: 0.3793 - val_loss: 1.2138 - val_acc: 0.6667\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6087 - acc: 0.3769 - val_loss: 1.5544 - val_acc: 0.4271\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5958 - acc: 0.4011 - val_loss: 2.7954 - val_acc: 0.1927\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5983 - acc: 0.3811 - val_loss: 1.3555 - val_acc: 0.5156\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6208 - acc: 0.3921 - val_loss: 2.2398 - val_acc: 0.2448\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5981 - acc: 0.3821 - val_loss: 1.1420 - val_acc: 0.6190\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5733 - acc: 0.3980 - val_loss: 2.2671 - val_acc: 0.1667\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5856 - acc: 0.4133 - val_loss: 1.7163 - val_acc: 0.3385\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5706 - acc: 0.4194 - val_loss: 1.1937 - val_acc: 0.5990\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5550 - acc: 0.3944 - val_loss: 1.5659 - val_acc: 0.3854\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6265 - acc: 0.3871 - val_loss: 2.7463 - val_acc: 0.2083\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5378 - acc: 0.4194 - val_loss: 1.4044 - val_acc: 0.5260\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.6086 - acc: 0.3993 - val_loss: 1.2216 - val_acc: 0.6198\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4862 - acc: 0.4426 - val_loss: 1.2137 - val_acc: 0.6042\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5386 - acc: 0.4385 - val_loss: 1.1501 - val_acc: 0.6042\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5083 - acc: 0.4104 - val_loss: 1.4910 - val_acc: 0.4323\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.6023 - acc: 0.4083 - val_loss: 2.0664 - val_acc: 0.3452\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5080 - acc: 0.4184 - val_loss: 1.4300 - val_acc: 0.4635\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5186 - acc: 0.4121 - val_loss: 2.2198 - val_acc: 0.2188\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5344 - acc: 0.4205 - val_loss: 3.0489 - val_acc: 0.1250\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5175 - acc: 0.4123 - val_loss: 1.2149 - val_acc: 0.6042\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5120 - acc: 0.4205 - val_loss: 1.0714 - val_acc: 0.6488\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5625 - acc: 0.4050 - val_loss: 1.6459 - val_acc: 0.4062\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5078 - acc: 0.4235 - val_loss: 1.1218 - val_acc: 0.6458\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4655 - acc: 0.4453 - val_loss: 1.2228 - val_acc: 0.5781\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4896 - acc: 0.4396 - val_loss: 1.1181 - val_acc: 0.6510\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5222 - acc: 0.4263 - val_loss: 1.4262 - val_acc: 0.4821\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4727 - acc: 0.4204 - val_loss: 2.3376 - val_acc: 0.2240\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5218 - acc: 0.4153 - val_loss: 1.1346 - val_acc: 0.6094\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5105 - acc: 0.4296 - val_loss: 6.7101 - val_acc: 0.1562\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5815 - acc: 0.4328 - val_loss: 1.1297 - val_acc: 0.5885\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4739 - acc: 0.4465 - val_loss: 1.3845 - val_acc: 0.5208\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.5448 - acc: 0.4352 - val_loss: 4.2634 - val_acc: 0.1012\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4331 - acc: 0.4566 - val_loss: 2.2709 - val_acc: 0.2604\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.5114 - acc: 0.4526 - val_loss: 2.3606 - val_acc: 0.2031\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4522 - acc: 0.4708 - val_loss: 1.3620 - val_acc: 0.4740\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4582 - acc: 0.4486 - val_loss: 1.3645 - val_acc: 0.4948\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4783 - acc: 0.4486 - val_loss: 3.4639 - val_acc: 0.1429\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5350 - acc: 0.4416 - val_loss: 1.3168 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4924 - acc: 0.4508 - val_loss: 1.2139 - val_acc: 0.5885\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4548 - acc: 0.4456 - val_loss: 1.2565 - val_acc: 0.5833\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4676 - acc: 0.4516 - val_loss: 1.0351 - val_acc: 0.6979\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4345 - acc: 0.4810 - val_loss: 1.0118 - val_acc: 0.6905\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4271 - acc: 0.4617 - val_loss: 1.6310 - val_acc: 0.3854\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4166 - acc: 0.4808 - val_loss: 1.6769 - val_acc: 0.3594\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4358 - acc: 0.4496 - val_loss: 1.4885 - val_acc: 0.4323\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4316 - acc: 0.4407 - val_loss: 2.1241 - val_acc: 0.2448\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4479 - acc: 0.4516 - val_loss: 2.3340 - val_acc: 0.2083\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4232 - acc: 0.4705 - val_loss: 2.4849 - val_acc: 0.2917\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4244 - acc: 0.4607 - val_loss: 1.0928 - val_acc: 0.6719\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4371 - acc: 0.4637 - val_loss: 1.0951 - val_acc: 0.6667\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4567 - acc: 0.4538 - val_loss: 1.5531 - val_acc: 0.3906\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3906 - acc: 0.4806 - val_loss: 2.0422 - val_acc: 0.2292\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4054 - acc: 0.4808 - val_loss: 1.0605 - val_acc: 0.6667\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4702 - acc: 0.4437 - val_loss: 1.9945 - val_acc: 0.2708\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3528 - acc: 0.4869 - val_loss: 1.7285 - val_acc: 0.3698\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.3830 - acc: 0.4888 - val_loss: 1.1511 - val_acc: 0.5573\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 1.4004 - acc: 0.4961 - val_loss: 0.9824 - val_acc: 0.6719\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.3299 - acc: 0.5049 - val_loss: 0.8927 - val_acc: 0.7083\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 1.4810 - acc: 0.4527 - val_loss: 2.2359 - val_acc: 0.2344\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.269341432225\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 2.1824 - acc: 0.2610 - val_loss: 1.8422 - val_acc: 0.3646\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.8216 - acc: 0.3579 - val_loss: 2.1405 - val_acc: 0.2656\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7554 - acc: 0.3590 - val_loss: 1.3779 - val_acc: 0.4479\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6074 - acc: 0.3750 - val_loss: 2.4560 - val_acc: 0.3214\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6803 - acc: 0.3700 - val_loss: 2.6649 - val_acc: 0.1823\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6234 - acc: 0.4074 - val_loss: 2.0044 - val_acc: 0.2188\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5703 - acc: 0.4123 - val_loss: 1.8730 - val_acc: 0.3229\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5513 - acc: 0.4063 - val_loss: 1.6287 - val_acc: 0.4219\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5719 - acc: 0.4286 - val_loss: 2.3242 - val_acc: 0.2679\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4747 - acc: 0.4444 - val_loss: 1.5154 - val_acc: 0.4010\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4967 - acc: 0.4484 - val_loss: 1.4024 - val_acc: 0.4583\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4124 - acc: 0.4748 - val_loss: 1.5562 - val_acc: 0.4271\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4384 - acc: 0.4729 - val_loss: 1.2750 - val_acc: 0.4740\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4403 - acc: 0.4565 - val_loss: 1.9389 - val_acc: 0.3690\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4771 - acc: 0.4628 - val_loss: 4.6000 - val_acc: 0.1198\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3758 - acc: 0.4959 - val_loss: 1.1581 - val_acc: 0.5469\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3857 - acc: 0.4860 - val_loss: 2.5565 - val_acc: 0.2656\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4072 - acc: 0.4869 - val_loss: 3.4042 - val_acc: 0.2656\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3313 - acc: 0.4881 - val_loss: 2.2843 - val_acc: 0.2969\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3247 - acc: 0.5050 - val_loss: 2.0370 - val_acc: 0.3036\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3897 - acc: 0.4971 - val_loss: 1.4241 - val_acc: 0.5521\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3219 - acc: 0.4839 - val_loss: 1.4324 - val_acc: 0.4844\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2762 - acc: 0.5142 - val_loss: 1.3286 - val_acc: 0.4688\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3381 - acc: 0.4980 - val_loss: 2.1796 - val_acc: 0.3438\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2449 - acc: 0.5263 - val_loss: 1.2757 - val_acc: 0.5714\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2764 - acc: 0.5061 - val_loss: 0.9486 - val_acc: 0.6458\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3275 - acc: 0.4920 - val_loss: 1.3777 - val_acc: 0.5312\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1758 - acc: 0.5504 - val_loss: 1.1959 - val_acc: 0.5521\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2714 - acc: 0.5211 - val_loss: 1.0224 - val_acc: 0.6198\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2564 - acc: 0.5383 - val_loss: 1.2233 - val_acc: 0.5595\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1516 - acc: 0.5683 - val_loss: 1.6283 - val_acc: 0.4427\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1474 - acc: 0.5724 - val_loss: 1.5807 - val_acc: 0.4167\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1637 - acc: 0.5695 - val_loss: 1.6370 - val_acc: 0.4583\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1073 - acc: 0.5735 - val_loss: 1.0663 - val_acc: 0.6198\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1385 - acc: 0.5667 - val_loss: 2.4283 - val_acc: 0.2708\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1201 - acc: 0.5587 - val_loss: 0.8320 - val_acc: 0.6786\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0731 - acc: 0.5777 - val_loss: 3.0007 - val_acc: 0.3490\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0656 - acc: 0.5895 - val_loss: 3.4398 - val_acc: 0.2552\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0698 - acc: 0.5815 - val_loss: 0.6898 - val_acc: 0.7448\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0472 - acc: 0.6210 - val_loss: 0.8355 - val_acc: 0.6771\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0979 - acc: 0.5898 - val_loss: 2.0214 - val_acc: 0.4286\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9964 - acc: 0.6149 - val_loss: 0.9615 - val_acc: 0.6302\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0909 - acc: 0.5867 - val_loss: 1.3751 - val_acc: 0.5260\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0233 - acc: 0.6018 - val_loss: 0.8970 - val_acc: 0.6146\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0191 - acc: 0.6020 - val_loss: 0.8570 - val_acc: 0.6562\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0098 - acc: 0.5958 - val_loss: 0.7638 - val_acc: 0.7083\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0707 - acc: 0.5999 - val_loss: 1.0650 - val_acc: 0.5521\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0688 - acc: 0.6030 - val_loss: 0.7696 - val_acc: 0.7292\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9649 - acc: 0.6300 - val_loss: 3.4287 - val_acc: 0.2604\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9862 - acc: 0.6292 - val_loss: 1.2636 - val_acc: 0.5729\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9245 - acc: 0.6504 - val_loss: 0.8045 - val_acc: 0.6719\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9032 - acc: 0.6603 - val_loss: 1.0734 - val_acc: 0.6250\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9349 - acc: 0.6360 - val_loss: 1.4154 - val_acc: 0.5104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9296 - acc: 0.6492 - val_loss: 0.6666 - val_acc: 0.7552\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8832 - acc: 0.6703 - val_loss: 0.6232 - val_acc: 0.7552\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3473 - acc: 0.5090 - val_loss: 1.8091 - val_acc: 0.4271\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2836 - acc: 0.5141 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6032 - acc: 0.4043 - val_loss: 3.6885 - val_acc: 0.1250\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4765 - acc: 0.4577 - val_loss: 2.2836 - val_acc: 0.3385\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3576 - acc: 0.5020 - val_loss: 1.4227 - val_acc: 0.5052\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3216 - acc: 0.4860 - val_loss: 2.0585 - val_acc: 0.3125\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2436 - acc: 0.5242 - val_loss: 1.2147 - val_acc: 0.5893\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5201 - acc: 0.4497 - val_loss: 1.4216 - val_acc: 0.4792\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4636 - acc: 0.4608 - val_loss: 3.0398 - val_acc: 0.2604\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3272 - acc: 0.4827 - val_loss: 1.2775 - val_acc: 0.4740\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3622 - acc: 0.4851 - val_loss: 1.4856 - val_acc: 0.4375\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3081 - acc: 0.4868 - val_loss: 1.1818 - val_acc: 0.4375\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2739 - acc: 0.5122 - val_loss: 1.1802 - val_acc: 0.4464\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2601 - acc: 0.5091 - val_loss: 1.0482 - val_acc: 0.5938\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3220 - acc: 0.4981 - val_loss: 1.1178 - val_acc: 0.5156\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2099 - acc: 0.5241 - val_loss: 2.1166 - val_acc: 0.3385\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2023 - acc: 0.5273 - val_loss: 1.3796 - val_acc: 0.4688\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1896 - acc: 0.5495 - val_loss: 1.0558 - val_acc: 0.5595\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1769 - acc: 0.5444 - val_loss: 0.8690 - val_acc: 0.6615\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1236 - acc: 0.5756 - val_loss: 1.6128 - val_acc: 0.4271\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1700 - acc: 0.5444 - val_loss: 0.8767 - val_acc: 0.6875\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1486 - acc: 0.5663 - val_loss: 0.7840 - val_acc: 0.6927\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1430 - acc: 0.5654 - val_loss: 0.7237 - val_acc: 0.6964\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1256 - acc: 0.5807 - val_loss: 0.8138 - val_acc: 0.6875\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1446 - acc: 0.5619 - val_loss: 0.7918 - val_acc: 0.7135\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0665 - acc: 0.5935 - val_loss: 2.2457 - val_acc: 0.3750\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0884 - acc: 0.5846 - val_loss: 0.8413 - val_acc: 0.6510\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0820 - acc: 0.5795 - val_loss: 0.9660 - val_acc: 0.6562\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0752 - acc: 0.6109 - val_loss: 0.9212 - val_acc: 0.6726\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0407 - acc: 0.5967 - val_loss: 0.7174 - val_acc: 0.7031\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0359 - acc: 0.6248 - val_loss: 0.7625 - val_acc: 0.7500\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1478 - acc: 0.5776 - val_loss: 0.8397 - val_acc: 0.6875\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0310 - acc: 0.6120 - val_loss: 0.8213 - val_acc: 0.6979\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1616 - acc: 0.5779 - val_loss: 0.7053 - val_acc: 0.7321\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0880 - acc: 0.6079 - val_loss: 1.0313 - val_acc: 0.5990\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1274 - acc: 0.5788 - val_loss: 1.4363 - val_acc: 0.4740\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1254 - acc: 0.5714 - val_loss: 0.8080 - val_acc: 0.6979\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0897 - acc: 0.6001 - val_loss: 0.6626 - val_acc: 0.7292\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0821 - acc: 0.5978 - val_loss: 3.4232 - val_acc: 0.4107\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9958 - acc: 0.6119 - val_loss: 1.2430 - val_acc: 0.5260\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0796 - acc: 0.5929 - val_loss: 0.6644 - val_acc: 0.7344\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9488 - acc: 0.6653 - val_loss: 0.6704 - val_acc: 0.7448\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9503 - acc: 0.6593 - val_loss: 0.7553 - val_acc: 0.7812\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0710 - acc: 0.5867 - val_loss: 0.7296 - val_acc: 0.7135\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9946 - acc: 0.6341 - val_loss: 0.5955 - val_acc: 0.7560\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.783697047497\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 2.2885 - acc: 0.2954 - val_loss: 4.5059 - val_acc: 0.1354\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.4879 - acc: 0.4830 - val_loss: 1.5740 - val_acc: 0.4375\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1010 - acc: 0.6303 - val_loss: 1.2047 - val_acc: 0.5833\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8083 - acc: 0.7256 - val_loss: 1.2334 - val_acc: 0.6071\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6712 - acc: 0.7866 - val_loss: 1.1082 - val_acc: 0.6406\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4861 - acc: 0.8406 - val_loss: 0.7438 - val_acc: 0.7656\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4622 - acc: 0.8543 - val_loss: 1.1256 - val_acc: 0.6250\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3715 - acc: 0.8883 - val_loss: 0.6525 - val_acc: 0.7865\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2751 - acc: 0.9375 - val_loss: 0.4018 - val_acc: 0.9107\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2628 - acc: 0.9284 - val_loss: 0.6009 - val_acc: 0.8073\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2491 - acc: 0.9286 - val_loss: 0.2075 - val_acc: 0.9531\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2044 - acc: 0.9506 - val_loss: 0.2387 - val_acc: 0.9167\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1864 - acc: 0.9516 - val_loss: 0.3097 - val_acc: 0.9062\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1626 - acc: 0.9688 - val_loss: 0.1831 - val_acc: 0.9427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1473 - acc: 0.9638 - val_loss: 0.1478 - val_acc: 0.9762\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1622 - acc: 0.9598 - val_loss: 0.3768 - val_acc: 0.8958\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1229 - acc: 0.9758 - val_loss: 0.1207 - val_acc: 0.9792\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1499 - acc: 0.9650 - val_loss: 0.1798 - val_acc: 0.9531\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1072 - acc: 0.9839 - val_loss: 0.3282 - val_acc: 0.9062\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0940 - acc: 0.9849 - val_loss: 0.2587 - val_acc: 0.9107\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0854 - acc: 0.9889 - val_loss: 0.1013 - val_acc: 0.9688\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1015 - acc: 0.9829 - val_loss: 0.1516 - val_acc: 0.9531\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0889 - acc: 0.9839 - val_loss: 0.1515 - val_acc: 0.9583\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0826 - acc: 0.9799 - val_loss: 0.1185 - val_acc: 0.9688\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0653 - acc: 0.9919 - val_loss: 0.1807 - val_acc: 0.9345\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0719 - acc: 0.9879 - val_loss: 0.1237 - val_acc: 0.9688\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0722 - acc: 0.9861 - val_loss: 0.1979 - val_acc: 0.9427\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0654 - acc: 0.9899 - val_loss: 0.1356 - val_acc: 0.9583\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0682 - acc: 0.9879 - val_loss: 0.0691 - val_acc: 0.9896\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0590 - acc: 0.9919 - val_loss: 0.1862 - val_acc: 0.9375\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0573 - acc: 0.9919 - val_loss: 0.1387 - val_acc: 0.9583\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0493 - acc: 0.9939 - val_loss: 0.0939 - val_acc: 0.9635\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0531 - acc: 0.9929 - val_loss: 0.1208 - val_acc: 0.9531\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0436 - acc: 0.9939 - val_loss: 0.0796 - val_acc: 0.9844\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0486 - acc: 0.9950 - val_loss: 0.1353 - val_acc: 0.9635\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0390 - acc: 0.9960 - val_loss: 0.0674 - val_acc: 0.9762\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0516 - acc: 0.9940 - val_loss: 0.1528 - val_acc: 0.9583\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0479 - acc: 0.9900 - val_loss: 0.2511 - val_acc: 0.9115\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0383 - acc: 0.9970 - val_loss: 0.0481 - val_acc: 0.9948\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0326 - acc: 0.9960 - val_loss: 0.1013 - val_acc: 0.9688\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0333 - acc: 0.9980 - val_loss: 0.2035 - val_acc: 0.9345\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0335 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9583\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0334 - acc: 0.9960 - val_loss: 0.1063 - val_acc: 0.9635\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0326 - acc: 0.9960 - val_loss: 0.0575 - val_acc: 0.9844\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0589 - acc: 0.9871 - val_loss: 0.1452 - val_acc: 0.9531\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0279 - acc: 0.9990 - val_loss: 0.0881 - val_acc: 0.9792\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0546 - acc: 0.9930 - val_loss: 0.0819 - val_acc: 0.9881\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0332 - acc: 0.9970 - val_loss: 0.1061 - val_acc: 0.9688\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0299 - acc: 0.9990 - val_loss: 0.0880 - val_acc: 0.9740\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0367 - acc: 0.9960 - val_loss: 0.1124 - val_acc: 0.9531\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0291 - acc: 0.9970 - val_loss: 0.0860 - val_acc: 0.9740\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0380 - acc: 0.9940 - val_loss: 0.0571 - val_acc: 0.9881\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0266 - acc: 0.9970 - val_loss: 0.1161 - val_acc: 0.9583\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0330 - acc: 0.9970 - val_loss: 0.1565 - val_acc: 0.9531\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0260 - acc: 0.9990 - val_loss: 0.0449 - val_acc: 0.9896\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0317 - acc: 0.9980 - val_loss: 0.0984 - val_acc: 0.9635\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0374 - acc: 0.9950 - val_loss: 0.0683 - val_acc: 0.9762\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0253 - acc: 0.9990 - val_loss: 0.0734 - val_acc: 0.9740\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0279 - acc: 0.9980 - val_loss: 0.0540 - val_acc: 0.9792\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9792\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0363 - acc: 0.9940 - val_loss: 0.7030 - val_acc: 0.7917\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0260 - acc: 0.9990 - val_loss: 0.0763 - val_acc: 0.9844\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0259 - acc: 0.9990 - val_loss: 0.0964 - val_acc: 0.9643\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0222 - acc: 0.9970 - val_loss: 0.0475 - val_acc: 0.9792\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0229 - acc: 0.9980 - val_loss: 0.1006 - val_acc: 0.9583\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0244 - acc: 0.9940 - val_loss: 0.1917 - val_acc: 0.9479\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0196 - acc: 0.9990 - val_loss: 0.1213 - val_acc: 0.9635\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0214 - acc: 0.9970 - val_loss: 0.0986 - val_acc: 0.9702\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0191 - acc: 0.9961 - val_loss: 0.1653 - val_acc: 0.9375\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9688\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0186 - acc: 0.9990 - val_loss: 0.0594 - val_acc: 0.9844\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0230 - acc: 0.9980 - val_loss: 0.0964 - val_acc: 0.9740\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0208 - acc: 0.9980 - val_loss: 0.1137 - val_acc: 0.9702\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0191 - acc: 0.9980 - val_loss: 0.0411 - val_acc: 0.9948\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0258 - acc: 0.9980 - val_loss: 0.0952 - val_acc: 0.9740\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0195 - acc: 0.9970 - val_loss: 0.0436 - val_acc: 0.9896\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0211 - acc: 0.9980 - val_loss: 0.2550 - val_acc: 0.9115\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0204 - acc: 0.9980 - val_loss: 0.1188 - val_acc: 0.9740\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0187 - acc: 0.9990 - val_loss: 0.0871 - val_acc: 0.9643\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9583\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9792\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0258 - acc: 0.9920 - val_loss: 0.0380 - val_acc: 0.9896\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0334 - acc: 0.9921 - val_loss: 0.0878 - val_acc: 0.9792\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0145 - acc: 0.9990 - val_loss: 0.0839 - val_acc: 0.9762\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0156 - acc: 0.9990 - val_loss: 0.0544 - val_acc: 0.9896\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0165 - acc: 0.9970 - val_loss: 0.0752 - val_acc: 0.9792\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0271 - acc: 0.9939 - val_loss: 0.1683 - val_acc: 0.9479\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9896\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0156 - acc: 0.9980 - val_loss: 0.0379 - val_acc: 0.9881\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9740\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0150 - acc: 0.9990 - val_loss: 0.0253 - val_acc: 0.9948\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0129 - acc: 0.9990 - val_loss: 0.1095 - val_acc: 0.9740\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0466 - val_acc: 0.9792\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0112 - acc: 0.9990 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0213 - acc: 0.9940 - val_loss: 0.1337 - val_acc: 0.9583\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0954 - val_acc: 0.9792\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 0.9844\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 0.9688\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0131 - acc: 0.9990 - val_loss: 0.0817 - val_acc: 0.9740\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0206 - acc: 0.9961 - val_loss: 0.0654 - val_acc: 0.9762\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.976982097187\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 1.6254 - acc: 0.4536 - val_loss: 1.3901 - val_acc: 0.5156\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.0968 - acc: 0.5919 - val_loss: 10.9060 - val_acc: 0.1667\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8795 - acc: 0.6736 - val_loss: 13.4838 - val_acc: 0.1094\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.7107 - acc: 0.7318 - val_loss: 14.5298 - val_acc: 0.0774\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5279 - acc: 0.8103 - val_loss: 6.0049 - val_acc: 0.3385\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.3192 - acc: 0.8860 - val_loss: 13.8416 - val_acc: 0.0833\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2430 - acc: 0.9174 - val_loss: 0.3194 - val_acc: 0.9062\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2065 - acc: 0.9385 - val_loss: 0.2496 - val_acc: 0.9271\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1851 - acc: 0.9325 - val_loss: 1.7543 - val_acc: 0.5625\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1338 - acc: 0.9547 - val_loss: 0.3201 - val_acc: 0.8750\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1249 - acc: 0.9588 - val_loss: 0.2578 - val_acc: 0.9010\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0821 - acc: 0.9798 - val_loss: 0.5708 - val_acc: 0.7969\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1008 - acc: 0.9739 - val_loss: 0.2487 - val_acc: 0.9219\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0741 - acc: 0.9799 - val_loss: 0.4631 - val_acc: 0.8281\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0611 - acc: 0.9879 - val_loss: 1.8320 - val_acc: 0.6190\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0624 - acc: 0.9799 - val_loss: 0.6470 - val_acc: 0.8177\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0624 - acc: 0.9808 - val_loss: 0.3323 - val_acc: 0.8906\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0298 - acc: 0.9929 - val_loss: 0.1536 - val_acc: 0.9635\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0406 - acc: 0.9889 - val_loss: 0.1739 - val_acc: 0.9479\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0531 - acc: 0.9869 - val_loss: 0.2180 - val_acc: 0.9345\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0463 - acc: 0.9879 - val_loss: 0.3873 - val_acc: 0.8802\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0390 - acc: 0.9820 - val_loss: 0.5270 - val_acc: 0.8490\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0479 - acc: 0.9790 - val_loss: 0.2200 - val_acc: 0.9167\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.1869 - val_acc: 0.9635\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0483 - acc: 0.9879 - val_loss: 0.7160 - val_acc: 0.8229\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0277 - acc: 0.9909 - val_loss: 0.1988 - val_acc: 0.9702\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0320 - acc: 0.9899 - val_loss: 0.5707 - val_acc: 0.8490\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0184 - acc: 0.9960 - val_loss: 0.1533 - val_acc: 0.9323\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0211 - acc: 0.9980 - val_loss: 0.0838 - val_acc: 0.9792\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0199 - acc: 0.9960 - val_loss: 0.2205 - val_acc: 0.9375\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.2105 - val_acc: 0.9286\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0183 - acc: 0.9960 - val_loss: 0.3682 - val_acc: 0.9167\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0366 - acc: 0.9939 - val_loss: 0.0591 - val_acc: 0.9792\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.2138 - val_acc: 0.9427\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0813 - val_acc: 0.9740\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0331 - acc: 0.9910 - val_loss: 14.7225 - val_acc: 0.0833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0612 - acc: 0.9809 - val_loss: 5.9023 - val_acc: 0.3750\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0335 - acc: 0.9899 - val_loss: 0.1793 - val_acc: 0.9688\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0839 - acc: 0.9771 - val_loss: 13.6472 - val_acc: 0.1094\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1570 - acc: 0.9446 - val_loss: 3.6650 - val_acc: 0.5104\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0450 - acc: 0.9869 - val_loss: 1.2745 - val_acc: 0.7604\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0532 - acc: 0.9769 - val_loss: 0.4091 - val_acc: 0.9048\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0415 - acc: 0.9869 - val_loss: 0.9211 - val_acc: 0.7760\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0262 - acc: 0.9899 - val_loss: 0.5370 - val_acc: 0.8490\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0669 - acc: 0.9860 - val_loss: 1.6441 - val_acc: 0.6667\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0470 - acc: 0.9820 - val_loss: 1.1132 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0331 - acc: 0.9890 - val_loss: 0.3406 - val_acc: 0.8988\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0411 - acc: 0.9849 - val_loss: 1.7742 - val_acc: 0.6250\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0316 - acc: 0.9889 - val_loss: 0.0789 - val_acc: 0.9792\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.1665 - val_acc: 0.9583\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0278 - acc: 0.9890 - val_loss: 0.0381 - val_acc: 0.9948\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0247 - acc: 0.9919 - val_loss: 0.4112 - val_acc: 0.9226\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0227 - acc: 0.9909 - val_loss: 0.1363 - val_acc: 0.9583\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.3673 - val_acc: 0.9219\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0597 - acc: 0.9840 - val_loss: 0.0819 - val_acc: 0.9740\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0299 - acc: 0.9889 - val_loss: 0.2689 - val_acc: 0.9531\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0180 - acc: 0.9960 - val_loss: 0.1248 - val_acc: 0.9740\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0484 - acc: 0.9860 - val_loss: 0.2085 - val_acc: 0.9405\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0139 - acc: 0.9980 - val_loss: 0.9225 - val_acc: 0.7708\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0289 - acc: 0.9871 - val_loss: 2.1756 - val_acc: 0.5729\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0233 - acc: 0.9960 - val_loss: 1.2643 - val_acc: 0.7188\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1131 - acc: 0.9639 - val_loss: 13.0919 - val_acc: 0.0990\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1166 - acc: 0.9649 - val_loss: 0.6438 - val_acc: 0.8393\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0397 - acc: 0.9899 - val_loss: 0.1957 - val_acc: 0.9219\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0522 - acc: 0.9828 - val_loss: 0.3003 - val_acc: 0.9531\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0202 - acc: 0.9950 - val_loss: 0.1224 - val_acc: 0.9792\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0153 - acc: 0.9960 - val_loss: 0.1390 - val_acc: 0.9635\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0195 - acc: 0.9929 - val_loss: 0.1396 - val_acc: 0.9643\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0200 - acc: 0.9950 - val_loss: 0.2573 - val_acc: 0.9583\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0303 - acc: 0.9919 - val_loss: 0.1229 - val_acc: 0.9740\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0198 - acc: 0.9929 - val_loss: 0.0773 - val_acc: 0.9740\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0464 - val_acc: 0.9896\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0148 - acc: 0.9939 - val_loss: 0.2083 - val_acc: 0.9479\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0121 - acc: 0.9950 - val_loss: 0.3517 - val_acc: 0.8929\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0171 - acc: 0.9950 - val_loss: 0.3445 - val_acc: 0.9115\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0240 - acc: 0.9939 - val_loss: 0.2288 - val_acc: 0.9688\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0155 - acc: 0.9980 - val_loss: 0.1816 - val_acc: 0.9375\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0166 - acc: 0.9960 - val_loss: 0.1249 - val_acc: 0.9688\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0163 - acc: 0.9980 - val_loss: 0.1290 - val_acc: 0.9643\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.1098 - val_acc: 0.9844\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0146 - acc: 0.9980 - val_loss: 0.1275 - val_acc: 0.9688\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0481 - acc: 0.9910 - val_loss: 2.0476 - val_acc: 0.5938\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0165 - acc: 0.9960 - val_loss: 0.3612 - val_acc: 0.8646\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0116 - acc: 0.9980 - val_loss: 0.2288 - val_acc: 0.9464\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0177 - acc: 0.9929 - val_loss: 0.0688 - val_acc: 0.9740\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0089 - acc: 0.9990 - val_loss: 0.1747 - val_acc: 0.9740\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.1946 - val_acc: 0.9688\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0148 - acc: 0.9980 - val_loss: 0.4755 - val_acc: 0.8594\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.3587 - val_acc: 0.9167\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.4348 - val_acc: 0.8750\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0129 - acc: 0.9970 - val_loss: 0.0627 - val_acc: 0.9844\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0154 - acc: 0.9929 - val_loss: 0.2564 - val_acc: 0.9271\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0098 - acc: 0.9980 - val_loss: 0.0206 - val_acc: 0.9896\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0193 - acc: 0.9910 - val_loss: 0.5739 - val_acc: 0.8802\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0108 - acc: 0.9960 - val_loss: 0.1456 - val_acc: 0.9762\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.1666 - val_acc: 0.9635\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9896\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0402 - acc: 0.9890 - val_loss: 0.3033 - val_acc: 0.9219\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0247 - acc: 0.9919 - val_loss: 0.2043 - val_acc: 0.9375\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0079 - acc: 0.9990 - val_loss: 0.2738 - val_acc: 0.9702\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.975703324808\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 2.4690 - acc: 0.2328 - val_loss: 2.5530 - val_acc: 0.2135\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.7753 - acc: 0.4142 - val_loss: 1.7414 - val_acc: 0.4062\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5819 - acc: 0.4596 - val_loss: 3.0228 - val_acc: 0.2292\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3458 - acc: 0.5070 - val_loss: 2.0468 - val_acc: 0.2812\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1672 - acc: 0.5886 - val_loss: 1.5355 - val_acc: 0.4881\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0263 - acc: 0.6371 - val_loss: 3.3775 - val_acc: 0.2240\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8750 - acc: 0.6866 - val_loss: 0.6569 - val_acc: 0.8542\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8770 - acc: 0.6968 - val_loss: 0.8208 - val_acc: 0.7135\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.7180 - acc: 0.7580 - val_loss: 0.5051 - val_acc: 0.8646\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6683 - acc: 0.7711 - val_loss: 0.7107 - val_acc: 0.7857\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6212 - acc: 0.7945 - val_loss: 0.6191 - val_acc: 0.7604\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5420 - acc: 0.8318 - val_loss: 1.0219 - val_acc: 0.6198\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5382 - acc: 0.8256 - val_loss: 0.2730 - val_acc: 0.9323\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5137 - acc: 0.8278 - val_loss: 0.3945 - val_acc: 0.8646\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4420 - acc: 0.8528 - val_loss: 0.2597 - val_acc: 0.9464\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4388 - acc: 0.8520 - val_loss: 0.4447 - val_acc: 0.8646\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4510 - acc: 0.8469 - val_loss: 0.2813 - val_acc: 0.9375\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3889 - acc: 0.8851 - val_loss: 0.4695 - val_acc: 0.8281\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3531 - acc: 0.8843 - val_loss: 0.2928 - val_acc: 0.8958\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3288 - acc: 0.9032 - val_loss: 0.2314 - val_acc: 0.9583\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3432 - acc: 0.8871 - val_loss: 0.4057 - val_acc: 0.8690\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2897 - acc: 0.9153 - val_loss: 0.2140 - val_acc: 0.9427\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3253 - acc: 0.8992 - val_loss: 0.1228 - val_acc: 0.9792\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2827 - acc: 0.9193 - val_loss: 0.1997 - val_acc: 0.9219\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2958 - acc: 0.9122 - val_loss: 0.1781 - val_acc: 0.9323\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2763 - acc: 0.9215 - val_loss: 0.4038 - val_acc: 0.8452\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.2378 - acc: 0.9344 - val_loss: 0.2270 - val_acc: 0.9427\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2307 - acc: 0.9355 - val_loss: 0.2370 - val_acc: 0.9219\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3557 - acc: 0.8895 - val_loss: 0.2967 - val_acc: 0.9062\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2855 - acc: 0.9056 - val_loss: 0.2419 - val_acc: 0.9219\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2370 - acc: 0.9213 - val_loss: 0.1767 - val_acc: 0.9524\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2640 - acc: 0.9134 - val_loss: 0.1195 - val_acc: 0.9583\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2345 - acc: 0.9267 - val_loss: 0.2444 - val_acc: 0.9115\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1919 - acc: 0.9506 - val_loss: 0.1356 - val_acc: 0.9688\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2252 - acc: 0.9287 - val_loss: 0.3057 - val_acc: 0.8906\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1980 - acc: 0.9435 - val_loss: 0.4312 - val_acc: 0.8750\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1860 - acc: 0.9455 - val_loss: 0.2362 - val_acc: 0.9345\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1620 - acc: 0.9536 - val_loss: 0.2327 - val_acc: 0.9323\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1655 - acc: 0.9526 - val_loss: 0.0812 - val_acc: 0.9740\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1875 - acc: 0.9497 - val_loss: 0.1013 - val_acc: 0.9792\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1781 - acc: 0.9497 - val_loss: 0.1872 - val_acc: 0.9635\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1720 - acc: 0.9608 - val_loss: 0.1496 - val_acc: 0.9524\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1856 - acc: 0.9457 - val_loss: 0.1342 - val_acc: 0.9635\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1547 - acc: 0.9608 - val_loss: 0.1629 - val_acc: 0.9427\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1386 - acc: 0.9707 - val_loss: 0.1171 - val_acc: 0.9688\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1644 - acc: 0.9526 - val_loss: 0.1394 - val_acc: 0.9635\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1364 - acc: 0.9647 - val_loss: 0.2236 - val_acc: 0.9405\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1149 - acc: 0.9728 - val_loss: 0.1524 - val_acc: 0.9531\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1340 - acc: 0.9627 - val_loss: 0.2357 - val_acc: 0.9167\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1302 - acc: 0.9597 - val_loss: 0.3722 - val_acc: 0.8750\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1335 - acc: 0.9648 - val_loss: 0.0837 - val_acc: 0.9896\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1392 - acc: 0.9598 - val_loss: 0.0797 - val_acc: 0.9844\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1286 - acc: 0.9668 - val_loss: 0.1516 - val_acc: 0.9524\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1218 - acc: 0.9648 - val_loss: 0.1694 - val_acc: 0.9688\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1319 - acc: 0.9669 - val_loss: 0.5331 - val_acc: 0.8333\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1600 - acc: 0.9517 - val_loss: 0.0844 - val_acc: 0.9792\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1456 - acc: 0.9668 - val_loss: 0.1277 - val_acc: 0.9635\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1211 - acc: 0.9739 - val_loss: 0.1104 - val_acc: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1074 - acc: 0.9758 - val_loss: 0.1226 - val_acc: 0.9792\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1049 - acc: 0.9818 - val_loss: 0.1860 - val_acc: 0.9375\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1145 - acc: 0.9659 - val_loss: 0.3230 - val_acc: 0.8906\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1235 - acc: 0.9557 - val_loss: 0.1079 - val_acc: 0.9740\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0979 - acc: 0.9788 - val_loss: 0.6776 - val_acc: 0.7857\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0940 - acc: 0.9729 - val_loss: 0.4116 - val_acc: 0.8750\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1107 - acc: 0.9688 - val_loss: 0.1863 - val_acc: 0.9479\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0973 - acc: 0.9697 - val_loss: 0.1474 - val_acc: 0.9688\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0892 - acc: 0.9759 - val_loss: 0.4208 - val_acc: 0.8802\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0972 - acc: 0.9699 - val_loss: 0.3004 - val_acc: 0.9115\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0957 - acc: 0.9819 - val_loss: 0.0738 - val_acc: 0.9821\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0914 - acc: 0.9788 - val_loss: 0.2033 - val_acc: 0.9323\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1080 - acc: 0.9698 - val_loss: 0.0778 - val_acc: 0.9948\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0873 - acc: 0.9808 - val_loss: 0.1823 - val_acc: 0.9427\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0837 - acc: 0.9798 - val_loss: 0.0862 - val_acc: 0.9792\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0815 - acc: 0.9859 - val_loss: 0.1178 - val_acc: 0.9702\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0738 - acc: 0.9859 - val_loss: 0.0666 - val_acc: 0.9740\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0931 - acc: 0.9718 - val_loss: 0.1197 - val_acc: 0.9688\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0713 - acc: 0.9840 - val_loss: 0.1124 - val_acc: 0.9792\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0753 - acc: 0.9828 - val_loss: 0.0775 - val_acc: 0.9844\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0662 - acc: 0.9889 - val_loss: 0.2142 - val_acc: 0.9464\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0743 - acc: 0.9818 - val_loss: 0.4777 - val_acc: 0.8698\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0862 - acc: 0.9739 - val_loss: 0.1682 - val_acc: 0.9323\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0821 - acc: 0.9758 - val_loss: 0.1107 - val_acc: 0.9688\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0775 - acc: 0.9808 - val_loss: 0.1955 - val_acc: 0.9635\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0797 - acc: 0.9788 - val_loss: 0.0903 - val_acc: 0.9844\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0785 - acc: 0.9818 - val_loss: 0.0777 - val_acc: 0.9821\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0673 - acc: 0.9859 - val_loss: 0.0466 - val_acc: 0.9844\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0775 - acc: 0.9829 - val_loss: 0.0810 - val_acc: 0.9844\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0610 - acc: 0.9889 - val_loss: 0.1366 - val_acc: 0.9635\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0715 - acc: 0.9860 - val_loss: 0.0547 - val_acc: 0.9896\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0891 - acc: 0.9730 - val_loss: 0.2131 - val_acc: 0.9226\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0682 - acc: 0.9818 - val_loss: 0.2428 - val_acc: 0.9271\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0612 - acc: 0.9829 - val_loss: 0.1098 - val_acc: 0.9740\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0629 - acc: 0.9828 - val_loss: 0.0967 - val_acc: 0.9792\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0537 - acc: 0.9899 - val_loss: 0.1280 - val_acc: 0.9635\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0724 - acc: 0.9789 - val_loss: 0.0443 - val_acc: 0.9940\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0719 - acc: 0.9841 - val_loss: 0.1538 - val_acc: 0.9635\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0630 - acc: 0.9869 - val_loss: 0.0497 - val_acc: 0.9896\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0614 - acc: 0.9839 - val_loss: 0.1124 - val_acc: 0.9688\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0614 - acc: 0.9859 - val_loss: 0.0739 - val_acc: 0.9740\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.0564 - acc: 0.9909 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.98929028133\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 1.7411 - acc: 0.4103 - val_loss: 1.5725 - val_acc: 0.4323\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.2273 - acc: 0.5505 - val_loss: 0.9924 - val_acc: 0.6302\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.0270 - acc: 0.6433 - val_loss: 7.3741 - val_acc: 0.1979\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9051 - acc: 0.6552 - val_loss: 9.5146 - val_acc: 0.1719\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8835 - acc: 0.6624 - val_loss: 9.7801 - val_acc: 0.1429\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.7237 - acc: 0.7328 - val_loss: 12.3736 - val_acc: 0.0833\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6262 - acc: 0.7684 - val_loss: 11.9830 - val_acc: 0.1042\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6727 - acc: 0.7520 - val_loss: 2.2827 - val_acc: 0.4323\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5128 - acc: 0.8206 - val_loss: 8.9796 - val_acc: 0.2344\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5400 - acc: 0.8138 - val_loss: 9.4514 - val_acc: 0.2321\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3960 - acc: 0.8669 - val_loss: 9.3088 - val_acc: 0.2812\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3567 - acc: 0.8669 - val_loss: 8.6253 - val_acc: 0.3125\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3596 - acc: 0.8811 - val_loss: 9.0894 - val_acc: 0.3073\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2586 - acc: 0.9213 - val_loss: 8.2615 - val_acc: 0.3385\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2812 - acc: 0.8952 - val_loss: 2.0012 - val_acc: 0.5312\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2605 - acc: 0.9176 - val_loss: 1.2351 - val_acc: 0.6429\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2129 - acc: 0.9364 - val_loss: 0.8102 - val_acc: 0.7188\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2181 - acc: 0.9355 - val_loss: 3.8582 - val_acc: 0.3073\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1958 - acc: 0.9355 - val_loss: 0.3800 - val_acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1773 - acc: 0.9425 - val_loss: 0.1170 - val_acc: 0.9635\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2074 - acc: 0.9295 - val_loss: 0.4648 - val_acc: 0.8690\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1883 - acc: 0.9427 - val_loss: 0.7574 - val_acc: 0.7552\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2552 - acc: 0.9357 - val_loss: 0.4370 - val_acc: 0.8542\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1703 - acc: 0.9446 - val_loss: 1.8154 - val_acc: 0.5104\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1533 - acc: 0.9428 - val_loss: 0.4978 - val_acc: 0.8281\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1871 - acc: 0.9397 - val_loss: 0.2540 - val_acc: 0.9226\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2187 - acc: 0.9238 - val_loss: 0.3389 - val_acc: 0.8958\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1592 - acc: 0.9546 - val_loss: 0.7123 - val_acc: 0.8073\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2363 - acc: 0.9277 - val_loss: 5.2438 - val_acc: 0.2865\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1640 - acc: 0.9476 - val_loss: 7.6298 - val_acc: 0.2031\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.1603 - acc: 0.9476 - val_loss: 0.9688 - val_acc: 0.7396\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1471 - acc: 0.9486 - val_loss: 0.1249 - val_acc: 0.9583\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1371 - acc: 0.9608 - val_loss: 0.5683 - val_acc: 0.8333\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1853 - acc: 0.9428 - val_loss: 2.7804 - val_acc: 0.4740\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1472 - acc: 0.9486 - val_loss: 4.6457 - val_acc: 0.4948\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1337 - acc: 0.9546 - val_loss: 0.1516 - val_acc: 0.9583\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1239 - acc: 0.9548 - val_loss: 0.2328 - val_acc: 0.9345\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1022 - acc: 0.9678 - val_loss: 1.6566 - val_acc: 0.6562\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1069 - acc: 0.9576 - val_loss: 0.0796 - val_acc: 0.9792\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1611 - acc: 0.9468 - val_loss: 0.3162 - val_acc: 0.9062\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1038 - acc: 0.9687 - val_loss: 0.7002 - val_acc: 0.7969\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1047 - acc: 0.9697 - val_loss: 0.1955 - val_acc: 0.9405\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0966 - acc: 0.9669 - val_loss: 0.1147 - val_acc: 0.9583\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0706 - acc: 0.9728 - val_loss: 1.2171 - val_acc: 0.6823\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0772 - acc: 0.9788 - val_loss: 0.3634 - val_acc: 0.9323\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0885 - acc: 0.9668 - val_loss: 2.5608 - val_acc: 0.5156\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0764 - acc: 0.9779 - val_loss: 0.1700 - val_acc: 0.9583\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7343 - acc: 0.7834 - val_loss: 14.1993 - val_acc: 0.1190\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3308 - acc: 0.8900 - val_loss: 3.2297 - val_acc: 0.4062\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2372 - acc: 0.9165 - val_loss: 0.6146 - val_acc: 0.8021\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1510 - acc: 0.9465 - val_loss: 1.4057 - val_acc: 0.6458\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1232 - acc: 0.9596 - val_loss: 0.1678 - val_acc: 0.9427\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1504 - acc: 0.9447 - val_loss: 4.8299 - val_acc: 0.3393\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1674 - acc: 0.9568 - val_loss: 0.1543 - val_acc: 0.9479\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1232 - acc: 0.9547 - val_loss: 0.2838 - val_acc: 0.9010\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1117 - acc: 0.9618 - val_loss: 0.0997 - val_acc: 0.9688\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1322 - acc: 0.9619 - val_loss: 0.2076 - val_acc: 0.9479\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0693 - acc: 0.9799 - val_loss: 0.3180 - val_acc: 0.8690\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0777 - acc: 0.9728 - val_loss: 0.3165 - val_acc: 0.8854\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0632 - acc: 0.9828 - val_loss: 0.1481 - val_acc: 0.9635\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0559 - acc: 0.9849 - val_loss: 0.9986 - val_acc: 0.7188\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0729 - acc: 0.9798 - val_loss: 4.7041 - val_acc: 0.3802\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0756 - acc: 0.9698 - val_loss: 0.1557 - val_acc: 0.9583\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0744 - acc: 0.9739 - val_loss: 0.8780 - val_acc: 0.7083\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1040 - acc: 0.9671 - val_loss: 11.2964 - val_acc: 0.1458\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0955 - acc: 0.9698 - val_loss: 0.2047 - val_acc: 0.9531\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0897 - acc: 0.9729 - val_loss: 3.9663 - val_acc: 0.4219\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0717 - acc: 0.9788 - val_loss: 0.3978 - val_acc: 0.8802\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1002 - acc: 0.9679 - val_loss: 0.1906 - val_acc: 0.9524\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0878 - acc: 0.9677 - val_loss: 0.6619 - val_acc: 0.8333\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0453 - acc: 0.9899 - val_loss: 0.1957 - val_acc: 0.9479\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0564 - acc: 0.9859 - val_loss: 0.0973 - val_acc: 0.9688\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0541 - acc: 0.9818 - val_loss: 0.1456 - val_acc: 0.9635\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0496 - acc: 0.9869 - val_loss: 0.5502 - val_acc: 0.8571\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0631 - acc: 0.9788 - val_loss: 0.3023 - val_acc: 0.9271\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0897 - acc: 0.9659 - val_loss: 0.1275 - val_acc: 0.9583\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0758 - acc: 0.9729 - val_loss: 0.1186 - val_acc: 0.9479\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0644 - acc: 0.9819 - val_loss: 0.3818 - val_acc: 0.8854\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0494 - acc: 0.9798 - val_loss: 0.1812 - val_acc: 0.9688\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0774 - acc: 0.9728 - val_loss: 0.0884 - val_acc: 0.9881\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0561 - acc: 0.9799 - val_loss: 0.1317 - val_acc: 0.9635\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0457 - acc: 0.9818 - val_loss: 0.7097 - val_acc: 0.7917\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0652 - acc: 0.9789 - val_loss: 0.3241 - val_acc: 0.8958\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0669 - acc: 0.9790 - val_loss: 0.1522 - val_acc: 0.9740\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0617 - acc: 0.9799 - val_loss: 0.1826 - val_acc: 0.9702\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0429 - acc: 0.9869 - val_loss: 0.0357 - val_acc: 0.9896\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0482 - acc: 0.9789 - val_loss: 0.1526 - val_acc: 0.9531\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0620 - acc: 0.9769 - val_loss: 0.1879 - val_acc: 0.9844\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0552 - acc: 0.9828 - val_loss: 0.5622 - val_acc: 0.8385\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0577 - acc: 0.9779 - val_loss: 0.0360 - val_acc: 0.9821\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0578 - acc: 0.9840 - val_loss: 0.2252 - val_acc: 0.9479\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0514 - acc: 0.9809 - val_loss: 4.2053 - val_acc: 0.4219\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0487 - acc: 0.9808 - val_loss: 0.0352 - val_acc: 0.9896\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0406 - acc: 0.9869 - val_loss: 0.2044 - val_acc: 0.9688\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0242 - acc: 0.9929 - val_loss: 0.1266 - val_acc: 0.9740\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0579 - acc: 0.9828 - val_loss: 0.3112 - val_acc: 0.9286\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0252 - acc: 0.9950 - val_loss: 0.2108 - val_acc: 0.9531\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0491 - acc: 0.9860 - val_loss: 0.2972 - val_acc: 0.9062\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0528 - acc: 0.9839 - val_loss: 0.3815 - val_acc: 0.8906\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0405 - acc: 0.9859 - val_loss: 4.4736 - val_acc: 0.4792\n",
      "200/200 [==============================] - 3s 13ms/step\n",
      "Test accuracy: 0.464698331194\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 1.9245 - acc: 0.3154 - val_loss: 2.2901 - val_acc: 0.2656\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.6161 - acc: 0.4093 - val_loss: 2.8490 - val_acc: 0.2656\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.5688 - acc: 0.3983 - val_loss: 1.7437 - val_acc: 0.4167\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5218 - acc: 0.4288 - val_loss: 1.8615 - val_acc: 0.3542\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.4101 - acc: 0.4706 - val_loss: 2.5589 - val_acc: 0.2738\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3889 - acc: 0.4919 - val_loss: 2.3767 - val_acc: 0.2969\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4052 - acc: 0.4870 - val_loss: 1.1917 - val_acc: 0.5312\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3376 - acc: 0.5042 - val_loss: 1.2918 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2723 - acc: 0.5021 - val_loss: 2.5347 - val_acc: 0.3646\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2217 - acc: 0.5456 - val_loss: 3.9983 - val_acc: 0.1823\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2184 - acc: 0.5626 - val_loss: 2.3720 - val_acc: 0.2381\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1271 - acc: 0.5765 - val_loss: 4.2786 - val_acc: 0.1510\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0920 - acc: 0.6028 - val_loss: 2.7715 - val_acc: 0.2917\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0414 - acc: 0.5998 - val_loss: 1.7792 - val_acc: 0.4115\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0475 - acc: 0.6007 - val_loss: 1.0819 - val_acc: 0.6302\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9609 - acc: 0.6453 - val_loss: 2.5038 - val_acc: 0.3452\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9871 - acc: 0.6613 - val_loss: 1.1228 - val_acc: 0.5833\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9082 - acc: 0.6712 - val_loss: 0.9731 - val_acc: 0.6458\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8711 - acc: 0.6815 - val_loss: 0.9590 - val_acc: 0.6250\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8056 - acc: 0.6947 - val_loss: 1.5652 - val_acc: 0.4948\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.8392 - acc: 0.7018 - val_loss: 2.0543 - val_acc: 0.4226\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7536 - acc: 0.7330 - val_loss: 5.5229 - val_acc: 0.1042\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7524 - acc: 0.7149 - val_loss: 0.5034 - val_acc: 0.8177\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7212 - acc: 0.7321 - val_loss: 3.8645 - val_acc: 0.3333\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7638 - acc: 0.7352 - val_loss: 0.4632 - val_acc: 0.8906\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6146 - acc: 0.7693 - val_loss: 1.2448 - val_acc: 0.6354\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5375 - acc: 0.8113 - val_loss: 1.7687 - val_acc: 0.4940\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5312 - acc: 0.8204 - val_loss: 0.8361 - val_acc: 0.7083\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5981 - acc: 0.7864 - val_loss: 5.4267 - val_acc: 0.2135\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5496 - acc: 0.8055 - val_loss: 0.6855 - val_acc: 0.7917\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5166 - acc: 0.8014 - val_loss: 0.7352 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5099 - acc: 0.8235 - val_loss: 3.2378 - val_acc: 0.3810\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4568 - acc: 0.8295 - val_loss: 0.5779 - val_acc: 0.8125\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4077 - acc: 0.8478 - val_loss: 1.2440 - val_acc: 0.5781\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4193 - acc: 0.8456 - val_loss: 0.2779 - val_acc: 0.9115\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3833 - acc: 0.8608 - val_loss: 0.6816 - val_acc: 0.7708\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4296 - acc: 0.8547 - val_loss: 0.3562 - val_acc: 0.8929\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3947 - acc: 0.8720 - val_loss: 1.1734 - val_acc: 0.6146\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6658 - acc: 0.7795 - val_loss: 1.6918 - val_acc: 0.5833\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4242 - acc: 0.8539 - val_loss: 1.8937 - val_acc: 0.5885\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3603 - acc: 0.8689 - val_loss: 1.5835 - val_acc: 0.6146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3692 - acc: 0.8619 - val_loss: 2.2654 - val_acc: 0.4844\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3173 - acc: 0.8932 - val_loss: 0.3853 - val_acc: 0.8631\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4906 - acc: 0.8248 - val_loss: 0.6205 - val_acc: 0.8021\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3498 - acc: 0.8769 - val_loss: 0.4803 - val_acc: 0.8229\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3364 - acc: 0.8770 - val_loss: 0.9091 - val_acc: 0.6719\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3968 - acc: 0.8578 - val_loss: 3.7488 - val_acc: 0.3906\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3019 - acc: 0.9002 - val_loss: 0.6326 - val_acc: 0.7798\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3162 - acc: 0.8852 - val_loss: 0.8407 - val_acc: 0.7448\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4256 - acc: 0.8714 - val_loss: 1.8242 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2427 - acc: 0.9113 - val_loss: 0.4544 - val_acc: 0.8490\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2439 - acc: 0.9143 - val_loss: 0.3802 - val_acc: 0.8854\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1950 - acc: 0.9354 - val_loss: 0.2661 - val_acc: 0.8929\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1493 - acc: 0.9536 - val_loss: 0.4833 - val_acc: 0.8646\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2113 - acc: 0.9194 - val_loss: 0.4109 - val_acc: 0.8750\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2201 - acc: 0.9346 - val_loss: 1.4835 - val_acc: 0.6250\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2092 - acc: 0.9275 - val_loss: 0.8311 - val_acc: 0.7656\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2416 - acc: 0.9205 - val_loss: 0.3483 - val_acc: 0.8542\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1998 - acc: 0.9325 - val_loss: 0.2530 - val_acc: 0.9286\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2304 - acc: 0.9255 - val_loss: 0.6353 - val_acc: 0.8177\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1885 - acc: 0.9496 - val_loss: 0.3899 - val_acc: 0.8698\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2510 - acc: 0.9187 - val_loss: 3.9219 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1564 - acc: 0.9465 - val_loss: 0.8599 - val_acc: 0.7448\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1128 - acc: 0.9637 - val_loss: 0.4021 - val_acc: 0.8631\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1483 - acc: 0.9517 - val_loss: 0.9441 - val_acc: 0.7760\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1262 - acc: 0.9577 - val_loss: 0.2653 - val_acc: 0.8802\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5509 - acc: 0.8580 - val_loss: 1.7072 - val_acc: 0.6354\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1775 - acc: 0.9386 - val_loss: 0.3203 - val_acc: 0.9010\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1397 - acc: 0.9537 - val_loss: 0.3126 - val_acc: 0.9107\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1369 - acc: 0.9466 - val_loss: 0.7630 - val_acc: 0.7604\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2691 - acc: 0.9115 - val_loss: 0.2590 - val_acc: 0.9323\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1617 - acc: 0.9416 - val_loss: 0.2251 - val_acc: 0.9062\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1411 - acc: 0.9496 - val_loss: 0.1870 - val_acc: 0.9427\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1370 - acc: 0.9608 - val_loss: 0.3291 - val_acc: 0.9115\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1421 - acc: 0.9517 - val_loss: 0.0665 - val_acc: 0.9762\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1596 - acc: 0.9465 - val_loss: 0.1959 - val_acc: 0.9427\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1235 - acc: 0.9547 - val_loss: 0.3879 - val_acc: 0.9062\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1320 - acc: 0.9547 - val_loss: 0.4030 - val_acc: 0.9115\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1041 - acc: 0.9637 - val_loss: 0.4383 - val_acc: 0.8542\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1353 - acc: 0.9517 - val_loss: 0.2000 - val_acc: 0.9524\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1266 - acc: 0.9556 - val_loss: 0.3187 - val_acc: 0.9219\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1858 - acc: 0.9409 - val_loss: 0.3511 - val_acc: 0.8958\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0835 - acc: 0.9687 - val_loss: 0.3509 - val_acc: 0.9167\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6068 - acc: 0.6655 - val_loss: 13.3496 - val_acc: 0.1094\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8648 - acc: 0.3355 - val_loss: 11.7923 - val_acc: 0.0833\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6657 - acc: 0.3689 - val_loss: 2.7205 - val_acc: 0.2969\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4779 - acc: 0.4868 - val_loss: 2.1797 - val_acc: 0.2760\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4280 - acc: 0.4931 - val_loss: 1.5025 - val_acc: 0.4375\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3701 - acc: 0.5139 - val_loss: 2.0221 - val_acc: 0.3281\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2910 - acc: 0.5303 - val_loss: 1.5936 - val_acc: 0.4740\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2699 - acc: 0.5343 - val_loss: 1.3940 - val_acc: 0.4762\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2691 - acc: 0.5305 - val_loss: 1.0959 - val_acc: 0.6094\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2035 - acc: 0.5495 - val_loss: 1.1106 - val_acc: 0.6250\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1610 - acc: 0.5584 - val_loss: 1.0827 - val_acc: 0.6302\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1286 - acc: 0.5636 - val_loss: 1.1798 - val_acc: 0.5625\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1185 - acc: 0.5846 - val_loss: 0.8987 - val_acc: 0.6429\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0555 - acc: 0.5957 - val_loss: 0.9483 - val_acc: 0.6094\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0604 - acc: 0.6149 - val_loss: 1.1105 - val_acc: 0.5573\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0172 - acc: 0.6359 - val_loss: 0.9165 - val_acc: 0.6510\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0005 - acc: 0.6421 - val_loss: 1.1472 - val_acc: 0.5677\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.531329923274\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 1.9742 - acc: 0.3894 - val_loss: 1.1865 - val_acc: 0.5625\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.2361 - acc: 0.5454 - val_loss: 5.9455 - val_acc: 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9814 - acc: 0.6372 - val_loss: 13.2897 - val_acc: 0.1406\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8019 - acc: 0.7179 - val_loss: 12.5101 - val_acc: 0.2240\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6648 - acc: 0.7489 - val_loss: 12.7281 - val_acc: 0.1979\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6163 - acc: 0.7714 - val_loss: 10.9801 - val_acc: 0.1845\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4669 - acc: 0.8279 - val_loss: 8.3804 - val_acc: 0.1458\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3889 - acc: 0.8567 - val_loss: 8.5757 - val_acc: 0.2031\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3781 - acc: 0.8581 - val_loss: 5.5722 - val_acc: 0.2292\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2909 - acc: 0.9043 - val_loss: 2.1907 - val_acc: 0.4740\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2721 - acc: 0.9094 - val_loss: 0.4515 - val_acc: 0.8571\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2431 - acc: 0.9205 - val_loss: 0.2909 - val_acc: 0.9323\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1909 - acc: 0.9456 - val_loss: 0.4189 - val_acc: 0.8333\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1940 - acc: 0.9356 - val_loss: 0.2312 - val_acc: 0.9427\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1999 - acc: 0.9346 - val_loss: 1.3645 - val_acc: 0.6198\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1759 - acc: 0.9387 - val_loss: 0.3853 - val_acc: 0.8631\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1396 - acc: 0.9576 - val_loss: 0.5787 - val_acc: 0.8229\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1378 - acc: 0.9558 - val_loss: 0.7836 - val_acc: 0.7760\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1336 - acc: 0.9607 - val_loss: 0.3024 - val_acc: 0.8698\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1261 - acc: 0.9638 - val_loss: 0.3543 - val_acc: 0.8958\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1604 - acc: 0.9538 - val_loss: 2.4526 - val_acc: 0.5312\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1224 - acc: 0.9577 - val_loss: 14.2952 - val_acc: 0.1131\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2003 - acc: 0.9485 - val_loss: 0.1743 - val_acc: 0.9375\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0937 - acc: 0.9758 - val_loss: 0.0839 - val_acc: 0.9740\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1352 - acc: 0.9639 - val_loss: 0.6343 - val_acc: 0.7812\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1198 - acc: 0.9637 - val_loss: 0.8984 - val_acc: 0.7448\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1031 - acc: 0.9707 - val_loss: 0.3248 - val_acc: 0.8929\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0955 - acc: 0.9798 - val_loss: 0.1084 - val_acc: 0.9792\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1094 - acc: 0.9588 - val_loss: 0.1700 - val_acc: 0.9479\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1122 - acc: 0.9596 - val_loss: 0.2958 - val_acc: 0.8906\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0912 - acc: 0.9728 - val_loss: 0.1216 - val_acc: 0.9479\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0956 - acc: 0.9738 - val_loss: 0.4240 - val_acc: 0.8333\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0701 - acc: 0.9828 - val_loss: 0.4387 - val_acc: 0.8490\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0830 - acc: 0.9708 - val_loss: 0.2788 - val_acc: 0.9115\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0729 - acc: 0.9798 - val_loss: 0.2016 - val_acc: 0.9167\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0673 - acc: 0.9828 - val_loss: 0.1288 - val_acc: 0.9688\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0866 - acc: 0.9759 - val_loss: 0.0870 - val_acc: 0.9740\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0868 - acc: 0.9679 - val_loss: 0.2082 - val_acc: 0.9345\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0709 - acc: 0.9778 - val_loss: 0.1598 - val_acc: 0.9635\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0773 - acc: 0.9788 - val_loss: 0.1199 - val_acc: 0.9688\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0842 - acc: 0.9698 - val_loss: 0.1452 - val_acc: 0.9635\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.1150 - acc: 0.9679 - val_loss: 0.0685 - val_acc: 0.9896\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0804 - acc: 0.9769 - val_loss: 0.2619 - val_acc: 0.9286\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0612 - acc: 0.9869 - val_loss: 0.2848 - val_acc: 0.9010\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0607 - acc: 0.9788 - val_loss: 0.2615 - val_acc: 0.9375\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0407 - acc: 0.9869 - val_loss: 0.0686 - val_acc: 0.9792\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0515 - acc: 0.9849 - val_loss: 0.5419 - val_acc: 0.8125\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0583 - acc: 0.9819 - val_loss: 0.0450 - val_acc: 0.9881\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0477 - acc: 0.9828 - val_loss: 0.1462 - val_acc: 0.9635\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0753 - acc: 0.9749 - val_loss: 0.3280 - val_acc: 0.9219\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0528 - acc: 0.9808 - val_loss: 0.0582 - val_acc: 0.9792\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0561 - acc: 0.9828 - val_loss: 0.1109 - val_acc: 0.9740\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0531 - acc: 0.9849 - val_loss: 0.0848 - val_acc: 0.9740\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0457 - acc: 0.9889 - val_loss: 0.2776 - val_acc: 0.8929\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0722 - acc: 0.9740 - val_loss: 0.1417 - val_acc: 0.9531\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0532 - acc: 0.9818 - val_loss: 0.1245 - val_acc: 0.9740\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0592 - acc: 0.9789 - val_loss: 0.2294 - val_acc: 0.9531\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0401 - acc: 0.9899 - val_loss: 0.1390 - val_acc: 0.9479\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0413 - acc: 0.9879 - val_loss: 0.4071 - val_acc: 0.8810\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0344 - acc: 0.9929 - val_loss: 0.0947 - val_acc: 0.9479\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0349 - acc: 0.9889 - val_loss: 0.0914 - val_acc: 0.9844\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0320 - acc: 0.9939 - val_loss: 0.2617 - val_acc: 0.9375\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0350 - acc: 0.9899 - val_loss: 0.0437 - val_acc: 0.9948\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0355 - acc: 0.9929 - val_loss: 0.2007 - val_acc: 0.9345\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0253 - acc: 0.9929 - val_loss: 0.0713 - val_acc: 0.9792\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0404 - acc: 0.9899 - val_loss: 0.2507 - val_acc: 0.9115\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0386 - acc: 0.9880 - val_loss: 0.3347 - val_acc: 0.9219\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0386 - acc: 0.9939 - val_loss: 0.3376 - val_acc: 0.9062\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0439 - acc: 0.9880 - val_loss: 0.4047 - val_acc: 0.8854\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0433 - acc: 0.9889 - val_loss: 0.2133 - val_acc: 0.8988\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0469 - acc: 0.9800 - val_loss: 0.1897 - val_acc: 0.9583\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0428 - acc: 0.9870 - val_loss: 1.1024 - val_acc: 0.6927\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0301 - acc: 0.9920 - val_loss: 0.6198 - val_acc: 0.8281\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0612 - acc: 0.9850 - val_loss: 0.1074 - val_acc: 0.9688\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0482 - acc: 0.9850 - val_loss: 0.2290 - val_acc: 0.9286\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0378 - acc: 0.9850 - val_loss: 0.7309 - val_acc: 0.8021\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0376 - acc: 0.9859 - val_loss: 0.1129 - val_acc: 0.9740\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0201 - acc: 0.9980 - val_loss: 0.0509 - val_acc: 0.9948\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0340 - acc: 0.9869 - val_loss: 0.6242 - val_acc: 0.8229\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0319 - acc: 0.9929 - val_loss: 0.2164 - val_acc: 0.9643\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0368 - acc: 0.9919 - val_loss: 0.4633 - val_acc: 0.8177\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0175 - acc: 0.9960 - val_loss: 0.2223 - val_acc: 0.9479\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0222 - acc: 0.9929 - val_loss: 0.2402 - val_acc: 0.9531\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0315 - acc: 0.9939 - val_loss: 0.0998 - val_acc: 0.9688\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0237 - acc: 0.9939 - val_loss: 0.0323 - val_acc: 0.9844\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0235 - acc: 0.9909 - val_loss: 0.1746 - val_acc: 0.9643\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0276 - acc: 0.9929 - val_loss: 1.0565 - val_acc: 0.7604\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0345 - acc: 0.9869 - val_loss: 0.1154 - val_acc: 0.9740\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0344 - acc: 0.9899 - val_loss: 0.1875 - val_acc: 0.9635\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0235 - acc: 0.9940 - val_loss: 2.3350 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0216 - acc: 0.9960 - val_loss: 0.2359 - val_acc: 0.9464\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0272 - acc: 0.9929 - val_loss: 0.2535 - val_acc: 0.9531\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0399 - acc: 0.9869 - val_loss: 0.4798 - val_acc: 0.8646\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0352 - acc: 0.9870 - val_loss: 7.1209 - val_acc: 0.2031\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0559 - acc: 0.9748 - val_loss: 0.7477 - val_acc: 0.8073\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0303 - acc: 0.9900 - val_loss: 0.3965 - val_acc: 0.8631\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0521 - acc: 0.9799 - val_loss: 0.3440 - val_acc: 0.9271\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0353 - acc: 0.9899 - val_loss: 0.8431 - val_acc: 0.7656\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0271 - acc: 0.9889 - val_loss: 0.1395 - val_acc: 0.9531\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.0253 - acc: 0.9909 - val_loss: 0.0407 - val_acc: 0.9896\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.949808184143\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 78ms/step - loss: 2.3717 - acc: 0.2178 - val_loss: 10.5595 - val_acc: 0.0774\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.8779 - acc: 0.3033 - val_loss: 2.6614 - val_acc: 0.1927\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8195 - acc: 0.3197 - val_loss: 1.5218 - val_acc: 0.4219\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7954 - acc: 0.3217 - val_loss: 1.4226 - val_acc: 0.4740\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7585 - acc: 0.3299 - val_loss: 1.5744 - val_acc: 0.4948\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6344 - acc: 0.3982 - val_loss: 1.3686 - val_acc: 0.5119\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7087 - acc: 0.3640 - val_loss: 1.6167 - val_acc: 0.3906\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5856 - acc: 0.3780 - val_loss: 2.6137 - val_acc: 0.1667\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6200 - acc: 0.3844 - val_loss: 2.3533 - val_acc: 0.2135\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6197 - acc: 0.3992 - val_loss: 2.3191 - val_acc: 0.2656\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5633 - acc: 0.4132 - val_loss: 1.7554 - val_acc: 0.3452\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4540 - acc: 0.4566 - val_loss: 1.9544 - val_acc: 0.3385\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5126 - acc: 0.4224 - val_loss: 2.6730 - val_acc: 0.2760\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4908 - acc: 0.4204 - val_loss: 1.6624 - val_acc: 0.4010\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4187 - acc: 0.4709 - val_loss: 1.9423 - val_acc: 0.2812\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4433 - acc: 0.4366 - val_loss: 3.3850 - val_acc: 0.1875\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4554 - acc: 0.4435 - val_loss: 5.3338 - val_acc: 0.1786\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3517 - acc: 0.4768 - val_loss: 1.8979 - val_acc: 0.4062\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3474 - acc: 0.4869 - val_loss: 6.6514 - val_acc: 0.0677\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4806 - acc: 0.4649 - val_loss: 0.9010 - val_acc: 0.6771\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3910 - acc: 0.4617 - val_loss: 6.2203 - val_acc: 0.0990\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3396 - acc: 0.5002 - val_loss: 1.3824 - val_acc: 0.4881\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3505 - acc: 0.4781 - val_loss: 0.9840 - val_acc: 0.6406\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3078 - acc: 0.4850 - val_loss: 1.6781 - val_acc: 0.3802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3012 - acc: 0.5030 - val_loss: 1.2025 - val_acc: 0.5208\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3238 - acc: 0.5294 - val_loss: 6.3702 - val_acc: 0.1146\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3470 - acc: 0.5244 - val_loss: 4.2868 - val_acc: 0.1310\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3153 - acc: 0.5030 - val_loss: 1.3568 - val_acc: 0.4792\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2669 - acc: 0.5012 - val_loss: 2.0304 - val_acc: 0.3385\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2145 - acc: 0.5537 - val_loss: 0.7175 - val_acc: 0.8594\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3685 - acc: 0.4770 - val_loss: 6.4544 - val_acc: 0.0729\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.3494 - acc: 0.4770 - val_loss: 2.3172 - val_acc: 0.3177\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3312 - acc: 0.4950 - val_loss: 1.4169 - val_acc: 0.4702\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2904 - acc: 0.5243 - val_loss: 1.0927 - val_acc: 0.6042\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2619 - acc: 0.5353 - val_loss: 2.0976 - val_acc: 0.3490\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2369 - acc: 0.5373 - val_loss: 1.8948 - val_acc: 0.3958\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1993 - acc: 0.5533 - val_loss: 1.1697 - val_acc: 0.5990\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3916 - acc: 0.4880 - val_loss: 9.7384 - val_acc: 0.1429\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1744 - acc: 0.5473 - val_loss: 4.0727 - val_acc: 0.1979\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1766 - acc: 0.5404 - val_loss: 0.6088 - val_acc: 0.8698\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1715 - acc: 0.5393 - val_loss: 1.5562 - val_acc: 0.4115\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.1329 - acc: 0.5746 - val_loss: 1.4668 - val_acc: 0.4844\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1735 - acc: 0.5503 - val_loss: 0.5827 - val_acc: 0.8571\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1349 - acc: 0.5686 - val_loss: 0.6740 - val_acc: 0.7552\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1229 - acc: 0.5768 - val_loss: 0.6354 - val_acc: 0.8229\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1966 - acc: 0.5690 - val_loss: 2.4823 - val_acc: 0.3073\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2020 - acc: 0.5567 - val_loss: 0.7204 - val_acc: 0.7083\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1252 - acc: 0.5767 - val_loss: 0.6286 - val_acc: 0.8750\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1349 - acc: 0.5676 - val_loss: 2.0188 - val_acc: 0.3750\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1057 - acc: 0.5546 - val_loss: 1.0272 - val_acc: 0.6354\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2316 - acc: 0.5537 - val_loss: 0.8382 - val_acc: 0.7135\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1267 - acc: 0.5727 - val_loss: 1.8138 - val_acc: 0.3385\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1597 - acc: 0.5726 - val_loss: 1.2222 - val_acc: 0.5365\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1569 - acc: 0.5636 - val_loss: 1.5749 - val_acc: 0.4762\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0827 - acc: 0.5959 - val_loss: 2.3658 - val_acc: 0.4219\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0801 - acc: 0.6098 - val_loss: 0.7782 - val_acc: 0.7240\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0557 - acc: 0.5959 - val_loss: 1.4604 - val_acc: 0.4740\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0214 - acc: 0.6108 - val_loss: 0.5044 - val_acc: 0.8542\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9923 - acc: 0.6430 - val_loss: 0.6193 - val_acc: 0.8036\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0318 - acc: 0.6129 - val_loss: 0.4734 - val_acc: 0.9062\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0258 - acc: 0.6323 - val_loss: 0.6009 - val_acc: 0.8125\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0332 - acc: 0.5958 - val_loss: 0.4256 - val_acc: 0.8958\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0567 - acc: 0.5888 - val_loss: 2.0181 - val_acc: 0.4167\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0103 - acc: 0.6179 - val_loss: 1.5906 - val_acc: 0.4635\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9087 - acc: 0.6642 - val_loss: 4.0556 - val_acc: 0.3274\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0467 - acc: 0.6020 - val_loss: 0.7021 - val_acc: 0.7865\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9181 - acc: 0.6462 - val_loss: 2.8697 - val_acc: 0.3594\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9462 - acc: 0.6232 - val_loss: 0.4646 - val_acc: 0.8646\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9135 - acc: 0.6471 - val_loss: 1.1076 - val_acc: 0.6198\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8953 - acc: 0.6433 - val_loss: 0.4159 - val_acc: 0.8929\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0031 - acc: 0.6169 - val_loss: 2.0619 - val_acc: 0.4479\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0146 - acc: 0.6132 - val_loss: 0.7391 - val_acc: 0.7031\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8780 - acc: 0.6621 - val_loss: 0.3674 - val_acc: 0.9167\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9347 - acc: 0.6581 - val_loss: 0.4283 - val_acc: 0.9115\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9380 - acc: 0.6460 - val_loss: 2.1514 - val_acc: 0.3929\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9380 - acc: 0.6543 - val_loss: 0.4405 - val_acc: 0.8542\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9391 - acc: 0.6453 - val_loss: 3.0015 - val_acc: 0.3854\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9516 - acc: 0.6552 - val_loss: 1.1365 - val_acc: 0.5729\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8421 - acc: 0.6681 - val_loss: 2.9301 - val_acc: 0.3646\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8503 - acc: 0.6814 - val_loss: 0.3163 - val_acc: 0.9635\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9090 - acc: 0.6502 - val_loss: 0.9349 - val_acc: 0.6726\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9142 - acc: 0.6655 - val_loss: 0.3098 - val_acc: 0.9479\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8735 - acc: 0.6724 - val_loss: 4.9053 - val_acc: 0.2188\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9515 - acc: 0.6542 - val_loss: 0.3804 - val_acc: 0.8958\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8554 - acc: 0.6744 - val_loss: 1.2881 - val_acc: 0.5365\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8854 - acc: 0.6594 - val_loss: 0.3569 - val_acc: 0.8869\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8690 - acc: 0.6684 - val_loss: 0.7157 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8724 - acc: 0.6694 - val_loss: 1.7229 - val_acc: 0.5156\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8941 - acc: 0.6672 - val_loss: 2.1077 - val_acc: 0.4531\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9330 - acc: 0.6502 - val_loss: 1.3119 - val_acc: 0.6094\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8686 - acc: 0.6813 - val_loss: 1.1591 - val_acc: 0.6250\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8422 - acc: 0.6744 - val_loss: 0.6608 - val_acc: 0.7812\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8419 - acc: 0.6813 - val_loss: 1.5851 - val_acc: 0.5260\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9288 - acc: 0.6786 - val_loss: 0.5018 - val_acc: 0.8281\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9732 - acc: 0.6494 - val_loss: 3.0948 - val_acc: 0.3333\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8477 - acc: 0.6876 - val_loss: 0.5609 - val_acc: 0.8073\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9126 - acc: 0.6787 - val_loss: 4.1771 - val_acc: 0.2738\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8595 - acc: 0.6935 - val_loss: 0.5969 - val_acc: 0.7917\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9466 - acc: 0.6221 - val_loss: 0.3850 - val_acc: 0.8698\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9010 - acc: 0.6563 - val_loss: 0.4780 - val_acc: 0.8490\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.837451861361\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 2.0453 - acc: 0.4407 - val_loss: 11.1336 - val_acc: 0.1726\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.5116 - acc: 0.5528 - val_loss: 1.3584 - val_acc: 0.5469\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.0137 - acc: 0.5667 - val_loss: 4.5615 - val_acc: 0.3802\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0908 - acc: 0.6706 - val_loss: 3.2075 - val_acc: 0.3594\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8916 - acc: 0.7117 - val_loss: 13.8851 - val_acc: 0.1094\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7230 - acc: 0.7482 - val_loss: 14.8047 - val_acc: 0.0774\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5756 - acc: 0.8006 - val_loss: 14.5789 - val_acc: 0.0938\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5392 - acc: 0.8217 - val_loss: 14.3480 - val_acc: 0.0938\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7095 - acc: 0.7954 - val_loss: 7.0606 - val_acc: 0.3229\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3363 - acc: 0.8799 - val_loss: 13.9765 - val_acc: 0.1250\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3064 - acc: 0.8993 - val_loss: 14.1615 - val_acc: 0.1094\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3531 - acc: 0.8892 - val_loss: 14.1145 - val_acc: 0.1190\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2271 - acc: 0.9275 - val_loss: 9.5474 - val_acc: 0.2656\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2151 - acc: 0.9365 - val_loss: 0.3300 - val_acc: 0.8906\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2614 - acc: 0.9244 - val_loss: 2.7377 - val_acc: 0.5521\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1618 - acc: 0.9497 - val_loss: 0.5279 - val_acc: 0.8594\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2260 - acc: 0.9226 - val_loss: 0.2037 - val_acc: 0.9583\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1506 - acc: 0.9455 - val_loss: 0.6005 - val_acc: 0.8229\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1409 - acc: 0.9607 - val_loss: 2.8305 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2452 - acc: 0.9355 - val_loss: 2.8208 - val_acc: 0.5573\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2257 - acc: 0.9376 - val_loss: 0.8535 - val_acc: 0.8333\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1593 - acc: 0.9538 - val_loss: 0.1321 - val_acc: 0.9643\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0956 - acc: 0.9637 - val_loss: 0.1539 - val_acc: 0.9531\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0933 - acc: 0.9677 - val_loss: 1.4749 - val_acc: 0.6979\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0692 - acc: 0.9769 - val_loss: 1.2932 - val_acc: 0.7656\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0756 - acc: 0.9798 - val_loss: 4.3336 - val_acc: 0.5104\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0650 - acc: 0.9769 - val_loss: 0.2443 - val_acc: 0.9271\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0828 - acc: 0.9799 - val_loss: 0.2284 - val_acc: 0.9345\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1253 - acc: 0.9577 - val_loss: 1.6804 - val_acc: 0.7188\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1142 - acc: 0.9657 - val_loss: 5.2559 - val_acc: 0.4062\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0768 - acc: 0.9759 - val_loss: 0.4133 - val_acc: 0.9010\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0641 - acc: 0.9798 - val_loss: 0.0370 - val_acc: 0.9792\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0479 - acc: 0.9839 - val_loss: 0.4573 - val_acc: 0.9345\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1262 - acc: 0.9679 - val_loss: 0.4598 - val_acc: 0.8802\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1249 - acc: 0.9578 - val_loss: 0.8703 - val_acc: 0.8073\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0760 - acc: 0.9768 - val_loss: 1.5849 - val_acc: 0.7396\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0625 - acc: 0.9788 - val_loss: 0.5856 - val_acc: 0.8698\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1298 - acc: 0.9619 - val_loss: 0.3706 - val_acc: 0.9226\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0392 - acc: 0.9839 - val_loss: 0.3075 - val_acc: 0.9375\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1718 - acc: 0.9559 - val_loss: 2.2819 - val_acc: 0.6458\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0690 - acc: 0.9739 - val_loss: 0.6301 - val_acc: 0.8438\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1266 - acc: 0.9598 - val_loss: 0.1181 - val_acc: 0.9740\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0894 - acc: 0.9729 - val_loss: 1.0859 - val_acc: 0.8594\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0532 - acc: 0.9779 - val_loss: 0.9232 - val_acc: 0.8274\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0470 - acc: 0.9889 - val_loss: 0.5530 - val_acc: 0.8802\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0386 - acc: 0.9859 - val_loss: 0.1944 - val_acc: 0.9479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0281 - acc: 0.9909 - val_loss: 0.1948 - val_acc: 0.9531\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0456 - acc: 0.9809 - val_loss: 2.0748 - val_acc: 0.6667\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1854 - acc: 0.9539 - val_loss: 0.9654 - val_acc: 0.8274\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0666 - acc: 0.9699 - val_loss: 1.2926 - val_acc: 0.7917\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1222 - acc: 0.9708 - val_loss: 13.3295 - val_acc: 0.1198\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0537 - acc: 0.9778 - val_loss: 0.0232 - val_acc: 0.9948\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0442 - acc: 0.9839 - val_loss: 1.7844 - val_acc: 0.6875\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0514 - acc: 0.9809 - val_loss: 0.5974 - val_acc: 0.8810\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0288 - acc: 0.9899 - val_loss: 7.6145 - val_acc: 0.2917\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0411 - acc: 0.9899 - val_loss: 0.1435 - val_acc: 0.9531\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0467 - acc: 0.9890 - val_loss: 0.6523 - val_acc: 0.8698\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0330 - acc: 0.9919 - val_loss: 0.0687 - val_acc: 0.9844\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0761 - acc: 0.9750 - val_loss: 0.2200 - val_acc: 0.9479\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0434 - acc: 0.9830 - val_loss: 0.5396 - val_acc: 0.8988\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0932 - acc: 0.9589 - val_loss: 2.4623 - val_acc: 0.5885\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1118 - acc: 0.9700 - val_loss: 0.4810 - val_acc: 0.8750\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0485 - acc: 0.9899 - val_loss: 7.3623 - val_acc: 0.3281\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0380 - acc: 0.9869 - val_loss: 0.9136 - val_acc: 0.8125\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.4188 - val_acc: 0.9107\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0361 - acc: 0.9859 - val_loss: 1.3258 - val_acc: 0.7812\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0476 - acc: 0.9899 - val_loss: 0.3077 - val_acc: 0.9531\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.1236 - val_acc: 0.9688\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0598 - acc: 0.9860 - val_loss: 0.1519 - val_acc: 0.9635\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0280 - acc: 0.9929 - val_loss: 0.0577 - val_acc: 0.9702\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0260 - acc: 0.9910 - val_loss: 0.9416 - val_acc: 0.8177\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0374 - acc: 0.9899 - val_loss: 0.0227 - val_acc: 0.9896\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0254 - acc: 0.9880 - val_loss: 0.3691 - val_acc: 0.9115\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0182 - acc: 0.9960 - val_loss: 0.1500 - val_acc: 0.9844\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.4568 - val_acc: 0.9115\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.1869 - val_acc: 0.9464\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0582 - acc: 0.9770 - val_loss: 12.2092 - val_acc: 0.2188\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0815 - acc: 0.9840 - val_loss: 3.4758 - val_acc: 0.5729\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0355 - acc: 0.9869 - val_loss: 0.6918 - val_acc: 0.8333\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0615 - acc: 0.9860 - val_loss: 1.8057 - val_acc: 0.6875\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0430 - acc: 0.9890 - val_loss: 2.3141 - val_acc: 0.6786\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0635 - acc: 0.9850 - val_loss: 0.4497 - val_acc: 0.9219\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0877 - acc: 0.9799 - val_loss: 0.9306 - val_acc: 0.8125\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.1140 - val_acc: 0.9688\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0424 - acc: 0.9850 - val_loss: 0.0944 - val_acc: 0.9792\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0222 - acc: 0.9919 - val_loss: 0.2305 - val_acc: 0.9643\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0310 - acc: 0.9899 - val_loss: 0.2470 - val_acc: 0.9531\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0122 - acc: 0.9950 - val_loss: 0.2160 - val_acc: 0.9531\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.3252 - val_acc: 0.9167\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0338 - acc: 0.9929 - val_loss: 0.1212 - val_acc: 0.9792\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0058 - acc: 0.9990 - val_loss: 0.1319 - val_acc: 0.9740\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0596 - acc: 0.9840 - val_loss: 2.1377 - val_acc: 0.6964\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0237 - acc: 0.9939 - val_loss: 0.1802 - val_acc: 0.9635\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0243 - val_acc: 0.9896\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0173 - acc: 0.9919 - val_loss: 0.1969 - val_acc: 0.9792\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1182 - acc: 0.9731 - val_loss: 2.9680 - val_acc: 0.6458\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0217 - acc: 0.9910 - val_loss: 0.1421 - val_acc: 0.9762\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0696 - acc: 0.9820 - val_loss: 0.5093 - val_acc: 0.9010\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0205 - acc: 0.9899 - val_loss: 0.1159 - val_acc: 0.9792\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0266 - acc: 0.9930 - val_loss: 0.1608 - val_acc: 0.9688\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.976822250639\n",
      "nesterov is False\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 83ms/step - loss: 4.3084 - acc: 0.1399 - val_loss: 1.6812 - val_acc: 0.3750\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 3.4169 - acc: 0.1815 - val_loss: 2.8309 - val_acc: 0.1719\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 3.3128 - acc: 0.2018 - val_loss: 2.9725 - val_acc: 0.2604\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 3.2707 - acc: 0.1927 - val_loss: 1.4625 - val_acc: 0.4583\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 3.0258 - acc: 0.2157 - val_loss: 1.5007 - val_acc: 0.4010\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.7226 - acc: 0.2338 - val_loss: 1.5999 - val_acc: 0.4219\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.8457 - acc: 0.2218 - val_loss: 1.4956 - val_acc: 0.4286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.6584 - acc: 0.2329 - val_loss: 2.6599 - val_acc: 0.1458\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.7326 - acc: 0.2318 - val_loss: 13.4716 - val_acc: 0.1146\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.7021 - acc: 0.2129 - val_loss: 8.1774 - val_acc: 0.0990\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.6937 - acc: 0.2197 - val_loss: 4.1599 - val_acc: 0.0938\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.4842 - acc: 0.2498 - val_loss: 2.1325 - val_acc: 0.1786\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.3732 - acc: 0.2632 - val_loss: 1.8191 - val_acc: 0.2865\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.3712 - acc: 0.2360 - val_loss: 1.5350 - val_acc: 0.4219\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.2962 - acc: 0.2783 - val_loss: 1.4865 - val_acc: 0.4010\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.2433 - acc: 0.2742 - val_loss: 1.5685 - val_acc: 0.3906\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.3457 - acc: 0.2409 - val_loss: 1.5595 - val_acc: 0.4107\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.2518 - acc: 0.2531 - val_loss: 1.5839 - val_acc: 0.3542\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2301 - acc: 0.2672 - val_loss: 1.5750 - val_acc: 0.3333\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.3010 - acc: 0.2461 - val_loss: 1.4388 - val_acc: 0.4583\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.2000 - acc: 0.2518 - val_loss: 1.7067 - val_acc: 0.2604\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.1626 - acc: 0.2631 - val_loss: 1.5469 - val_acc: 0.4271\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1448 - acc: 0.2750 - val_loss: 1.5274 - val_acc: 0.3929\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1065 - acc: 0.2651 - val_loss: 1.6470 - val_acc: 0.3281\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1097 - acc: 0.2650 - val_loss: 1.7938 - val_acc: 0.2396\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9831 - acc: 0.2790 - val_loss: 1.7051 - val_acc: 0.3438\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1073 - acc: 0.2611 - val_loss: 1.6393 - val_acc: 0.3229\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9790 - acc: 0.2912 - val_loss: 1.7072 - val_acc: 0.2798\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.0807 - acc: 0.2724 - val_loss: 1.5880 - val_acc: 0.3438\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9789 - acc: 0.2861 - val_loss: 1.6290 - val_acc: 0.3594\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.0137 - acc: 0.2732 - val_loss: 1.6383 - val_acc: 0.3021\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9409 - acc: 0.3035 - val_loss: 1.5799 - val_acc: 0.4115\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0547 - acc: 0.2581 - val_loss: 1.6620 - val_acc: 0.3214\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.0204 - acc: 0.2824 - val_loss: 1.6691 - val_acc: 0.3125\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9030 - acc: 0.3035 - val_loss: 1.5619 - val_acc: 0.4792\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 2.0735 - acc: 0.2740 - val_loss: 1.5865 - val_acc: 0.3854\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9926 - acc: 0.2752 - val_loss: 1.6071 - val_acc: 0.3490\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9963 - acc: 0.2863 - val_loss: 1.5244 - val_acc: 0.4740\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9007 - acc: 0.2984 - val_loss: 1.6018 - val_acc: 0.4226\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9433 - acc: 0.2723 - val_loss: 1.5102 - val_acc: 0.4479\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8986 - acc: 0.2843 - val_loss: 1.6516 - val_acc: 0.3125\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8888 - acc: 0.2863 - val_loss: 1.6013 - val_acc: 0.3802\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9768 - acc: 0.2662 - val_loss: 1.5444 - val_acc: 0.4062\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9288 - acc: 0.2903 - val_loss: 1.5561 - val_acc: 0.3810\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9227 - acc: 0.2713 - val_loss: 1.6977 - val_acc: 0.3385\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9020 - acc: 0.3138 - val_loss: 1.7244 - val_acc: 0.3333\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8874 - acc: 0.2964 - val_loss: 1.6689 - val_acc: 0.2917\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9118 - acc: 0.2954 - val_loss: 1.7064 - val_acc: 0.3073\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8453 - acc: 0.3012 - val_loss: 1.5980 - val_acc: 0.3690\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8395 - acc: 0.3045 - val_loss: 1.7321 - val_acc: 0.2760\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7677 - acc: 0.3267 - val_loss: 1.7336 - val_acc: 0.2552\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9051 - acc: 0.2783 - val_loss: 1.5975 - val_acc: 0.3542\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8649 - acc: 0.2964 - val_loss: 1.6509 - val_acc: 0.3177\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8656 - acc: 0.2670 - val_loss: 1.7097 - val_acc: 0.3333\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8072 - acc: 0.3167 - val_loss: 1.7591 - val_acc: 0.2619\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8296 - acc: 0.2873 - val_loss: 1.9182 - val_acc: 0.2656\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8537 - acc: 0.2944 - val_loss: 1.7168 - val_acc: 0.3698\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7451 - acc: 0.3066 - val_loss: 1.8103 - val_acc: 0.2917\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7994 - acc: 0.3046 - val_loss: 2.0108 - val_acc: 0.2500\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.9134 - acc: 0.2773 - val_loss: 2.2673 - val_acc: 0.1964\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8038 - acc: 0.3116 - val_loss: 2.0373 - val_acc: 0.2344\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8147 - acc: 0.2985 - val_loss: 1.6622 - val_acc: 0.3281\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8129 - acc: 0.3125 - val_loss: 1.6837 - val_acc: 0.2969\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7989 - acc: 0.3015 - val_loss: 1.6358 - val_acc: 0.3542\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7934 - acc: 0.3114 - val_loss: 2.2205 - val_acc: 0.2143\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7528 - acc: 0.3105 - val_loss: 1.9503 - val_acc: 0.2448\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8335 - acc: 0.3075 - val_loss: 2.1002 - val_acc: 0.2292\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8166 - acc: 0.3226 - val_loss: 1.6528 - val_acc: 0.3125\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8151 - acc: 0.3026 - val_loss: 2.2201 - val_acc: 0.2656\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7051 - acc: 0.3396 - val_loss: 2.0601 - val_acc: 0.2135\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8048 - acc: 0.2976 - val_loss: 2.2338 - val_acc: 0.1488\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8164 - acc: 0.3158 - val_loss: 1.5985 - val_acc: 0.3750\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8026 - acc: 0.2995 - val_loss: 7.7521 - val_acc: 0.1094\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7710 - acc: 0.2915 - val_loss: 4.5937 - val_acc: 0.1094\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7416 - acc: 0.3438 - val_loss: 1.8008 - val_acc: 0.3281\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.8045 - acc: 0.3085 - val_loss: 2.6157 - val_acc: 0.1964\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7260 - acc: 0.3206 - val_loss: 2.3803 - val_acc: 0.2656\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6781 - acc: 0.3356 - val_loss: 2.2582 - val_acc: 0.2448\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7390 - acc: 0.3348 - val_loss: 1.5302 - val_acc: 0.4062\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7157 - acc: 0.3337 - val_loss: 1.5329 - val_acc: 0.4167\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6636 - acc: 0.3495 - val_loss: 1.5099 - val_acc: 0.4167\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6966 - acc: 0.3216 - val_loss: 1.6779 - val_acc: 0.2812\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7408 - acc: 0.3177 - val_loss: 1.8627 - val_acc: 0.2917\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.7146 - acc: 0.3387 - val_loss: 2.1095 - val_acc: 0.2760\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.7370 - acc: 0.3409 - val_loss: 1.7078 - val_acc: 0.2396\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7212 - acc: 0.3326 - val_loss: 2.2876 - val_acc: 0.2969\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7053 - acc: 0.3185 - val_loss: 1.8101 - val_acc: 0.2857\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6865 - acc: 0.3367 - val_loss: 2.2932 - val_acc: 0.2292\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7433 - acc: 0.3308 - val_loss: 1.4504 - val_acc: 0.5312\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7366 - acc: 0.3116 - val_loss: 2.7820 - val_acc: 0.2396\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6997 - acc: 0.3308 - val_loss: 1.4703 - val_acc: 0.4896\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7573 - acc: 0.3205 - val_loss: 1.4775 - val_acc: 0.4643\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7657 - acc: 0.2934 - val_loss: 1.6478 - val_acc: 0.3281\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6757 - acc: 0.3399 - val_loss: 1.5954 - val_acc: 0.3438\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6729 - acc: 0.3516 - val_loss: 1.3853 - val_acc: 0.5156\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.6817 - acc: 0.3388 - val_loss: 2.7537 - val_acc: 0.2500\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7004 - acc: 0.3346 - val_loss: 1.7459 - val_acc: 0.3452\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6082 - acc: 0.3890 - val_loss: 1.5452 - val_acc: 0.4115\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6422 - acc: 0.3607 - val_loss: 3.8978 - val_acc: 0.2083\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6640 - acc: 0.3508 - val_loss: 1.4394 - val_acc: 0.4635\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.494405370844\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 88ms/step - loss: 2.7914 - acc: 0.2279 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.9041 - acc: 0.4399 - val_loss: 14.6790 - val_acc: 0.0893\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.3349 - acc: 0.5343 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2958 - acc: 0.5576 - val_loss: 13.8594 - val_acc: 0.1302\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2505 - acc: 0.5625 - val_loss: 13.3837 - val_acc: 0.1250\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0634 - acc: 0.6259 - val_loss: 13.2743 - val_acc: 0.1615\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.9859 - acc: 0.6582 - val_loss: 13.4549 - val_acc: 0.1488\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0451 - acc: 0.6129 - val_loss: 10.5041 - val_acc: 0.1979\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9029 - acc: 0.7128 - val_loss: 4.8879 - val_acc: 0.2656\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.7729 - acc: 0.7289 - val_loss: 0.6218 - val_acc: 0.7708\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7861 - acc: 0.7130 - val_loss: 1.7155 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.7884 - acc: 0.7218 - val_loss: 1.7713 - val_acc: 0.5060\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7633 - acc: 0.7605 - val_loss: 0.5217 - val_acc: 0.8073\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6480 - acc: 0.7863 - val_loss: 0.7873 - val_acc: 0.7448\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6167 - acc: 0.7705 - val_loss: 0.5011 - val_acc: 0.7969\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5346 - acc: 0.8036 - val_loss: 2.3444 - val_acc: 0.4635\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5882 - acc: 0.8008 - val_loss: 9.0174 - val_acc: 0.1823\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5191 - acc: 0.8248 - val_loss: 2.2930 - val_acc: 0.4107\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.5274 - acc: 0.8378 - val_loss: 1.3786 - val_acc: 0.6458\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4401 - acc: 0.8499 - val_loss: 10.3217 - val_acc: 0.1146\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4518 - acc: 0.8387 - val_loss: 0.7887 - val_acc: 0.7812\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4282 - acc: 0.8559 - val_loss: 0.7407 - val_acc: 0.7240\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4642 - acc: 0.8418 - val_loss: 0.6019 - val_acc: 0.8393\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3392 - acc: 0.8751 - val_loss: 2.1176 - val_acc: 0.6042\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3353 - acc: 0.8762 - val_loss: 1.2135 - val_acc: 0.6667\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3491 - acc: 0.8723 - val_loss: 2.1508 - val_acc: 0.5417\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3097 - acc: 0.8871 - val_loss: 7.5166 - val_acc: 0.2396\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2515 - acc: 0.9063 - val_loss: 2.3684 - val_acc: 0.5357\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3059 - acc: 0.8841 - val_loss: 1.4024 - val_acc: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2702 - acc: 0.9044 - val_loss: 4.0631 - val_acc: 0.4167\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3120 - acc: 0.9093 - val_loss: 3.8485 - val_acc: 0.4167\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2072 - acc: 0.9344 - val_loss: 0.7324 - val_acc: 0.8542\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2126 - acc: 0.9234 - val_loss: 2.2475 - val_acc: 0.5312\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2220 - acc: 0.9144 - val_loss: 0.9282 - val_acc: 0.7381\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2334 - acc: 0.9195 - val_loss: 0.3663 - val_acc: 0.8906\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2123 - acc: 0.9124 - val_loss: 2.8346 - val_acc: 0.4844\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1486 - acc: 0.9475 - val_loss: 1.2732 - val_acc: 0.6719\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2481 - acc: 0.9186 - val_loss: 2.4913 - val_acc: 0.4792\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2305 - acc: 0.9296 - val_loss: 2.0280 - val_acc: 0.5357\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1413 - acc: 0.9485 - val_loss: 0.4229 - val_acc: 0.8594\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1745 - acc: 0.9295 - val_loss: 1.1499 - val_acc: 0.7969\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1629 - acc: 0.9445 - val_loss: 0.3013 - val_acc: 0.9115\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1790 - acc: 0.9387 - val_loss: 0.2042 - val_acc: 0.9219\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1432 - acc: 0.9597 - val_loss: 2.3669 - val_acc: 0.5714\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1694 - acc: 0.9355 - val_loss: 0.2237 - val_acc: 0.9427\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1512 - acc: 0.9497 - val_loss: 0.1955 - val_acc: 0.9219\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1374 - acc: 0.9497 - val_loss: 0.3440 - val_acc: 0.9010\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1372 - acc: 0.9477 - val_loss: 0.2482 - val_acc: 0.9427\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1469 - acc: 0.9558 - val_loss: 1.8240 - val_acc: 0.6146\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1330 - acc: 0.9538 - val_loss: 0.5140 - val_acc: 0.8393\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1695 - acc: 0.9449 - val_loss: 0.2040 - val_acc: 0.9427\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1078 - acc: 0.9567 - val_loss: 1.1414 - val_acc: 0.7135\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1093 - acc: 0.9567 - val_loss: 2.2114 - val_acc: 0.5729\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1142 - acc: 0.9598 - val_loss: 0.5692 - val_acc: 0.8281\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1126 - acc: 0.9638 - val_loss: 0.2768 - val_acc: 0.9048\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1077 - acc: 0.9688 - val_loss: 0.2424 - val_acc: 0.9375\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1241 - acc: 0.9587 - val_loss: 0.2035 - val_acc: 0.9375\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1130 - acc: 0.9658 - val_loss: 2.6890 - val_acc: 0.5521\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0966 - acc: 0.9637 - val_loss: 0.2221 - val_acc: 0.9323\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0963 - acc: 0.9708 - val_loss: 0.2150 - val_acc: 0.9167\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1220 - acc: 0.9627 - val_loss: 2.4638 - val_acc: 0.5885\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2330 - acc: 0.9095 - val_loss: 1.3496 - val_acc: 0.7135\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1709 - acc: 0.9437 - val_loss: 4.7948 - val_acc: 0.3906\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1677 - acc: 0.9357 - val_loss: 5.6689 - val_acc: 0.3021\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1154 - acc: 0.9629 - val_loss: 2.6123 - val_acc: 0.5156\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1154 - acc: 0.9507 - val_loss: 0.3417 - val_acc: 0.8929\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1912 - acc: 0.9336 - val_loss: 13.6642 - val_acc: 0.1510\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3611 - acc: 0.8943 - val_loss: 12.0579 - val_acc: 0.2031\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4206 - acc: 0.8835 - val_loss: 10.7356 - val_acc: 0.2396\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2081 - acc: 0.9325 - val_loss: 2.8825 - val_acc: 0.5156\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2140 - acc: 0.9314 - val_loss: 2.3360 - val_acc: 0.5536\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2555 - acc: 0.9306 - val_loss: 3.3674 - val_acc: 0.4323\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2687 - acc: 0.9216 - val_loss: 13.3107 - val_acc: 0.1406\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4971 - acc: 0.8479 - val_loss: 14.4707 - val_acc: 0.0833\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3552 - acc: 0.8771 - val_loss: 0.7716 - val_acc: 0.7969\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3301 - acc: 0.9104 - val_loss: 4.5568 - val_acc: 0.3810\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3164 - acc: 0.8934 - val_loss: 4.6271 - val_acc: 0.4219\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3204 - acc: 0.8955 - val_loss: 3.6005 - val_acc: 0.4531\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3067 - acc: 0.8942 - val_loss: 2.3057 - val_acc: 0.5365\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2978 - acc: 0.9033 - val_loss: 1.9370 - val_acc: 0.5729\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2012 - acc: 0.9274 - val_loss: 0.4415 - val_acc: 0.8750\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1986 - acc: 0.9254 - val_loss: 0.3239 - val_acc: 0.9107\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1834 - acc: 0.9336 - val_loss: 0.4927 - val_acc: 0.9062\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1747 - acc: 0.9336 - val_loss: 0.1806 - val_acc: 0.9375\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1377 - acc: 0.9536 - val_loss: 0.2440 - val_acc: 0.9167\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1404 - acc: 0.9518 - val_loss: 0.2440 - val_acc: 0.9479\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1340 - acc: 0.9486 - val_loss: 0.1171 - val_acc: 0.9702\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1730 - acc: 0.9418 - val_loss: 0.4453 - val_acc: 0.8958\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1249 - acc: 0.9607 - val_loss: 0.1894 - val_acc: 0.9375\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0918 - acc: 0.9677 - val_loss: 0.2387 - val_acc: 0.9375\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1091 - acc: 0.9557 - val_loss: 0.1418 - val_acc: 0.9427\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1054 - acc: 0.9628 - val_loss: 0.2302 - val_acc: 0.9345\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1265 - acc: 0.9639 - val_loss: 0.1866 - val_acc: 0.9427\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0793 - acc: 0.9698 - val_loss: 0.3812 - val_acc: 0.9219\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0977 - acc: 0.9729 - val_loss: 0.2729 - val_acc: 0.9271\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0654 - acc: 0.9818 - val_loss: 0.2182 - val_acc: 0.9583\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1062 - acc: 0.9598 - val_loss: 0.1600 - val_acc: 0.9479\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0623 - acc: 0.9788 - val_loss: 0.1788 - val_acc: 0.9524\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0788 - acc: 0.9739 - val_loss: 0.1009 - val_acc: 0.9635\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0708 - acc: 0.9809 - val_loss: 0.1711 - val_acc: 0.9427\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.954283887468\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 89ms/step - loss: 2.0656 - acc: 0.3590 - val_loss: 1.2458 - val_acc: 0.5156\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2311 - acc: 0.5707 - val_loss: 2.0939 - val_acc: 0.4702\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8371 - acc: 0.6887 - val_loss: 1.0578 - val_acc: 0.6146\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7155 - acc: 0.7572 - val_loss: 12.9834 - val_acc: 0.1875\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5090 - acc: 0.8337 - val_loss: 3.6477 - val_acc: 0.2604\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3992 - acc: 0.8722 - val_loss: 5.6235 - val_acc: 0.2396\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2974 - acc: 0.8910 - val_loss: 7.7110 - val_acc: 0.1964\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2626 - acc: 0.9105 - val_loss: 0.2160 - val_acc: 0.9479\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1831 - acc: 0.9415 - val_loss: 0.3384 - val_acc: 0.8698\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2292 - acc: 0.9276 - val_loss: 11.9846 - val_acc: 0.1510\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1623 - acc: 0.9548 - val_loss: 6.4808 - val_acc: 0.3073\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1725 - acc: 0.9367 - val_loss: 0.8850 - val_acc: 0.7292\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1083 - acc: 0.9667 - val_loss: 10.3914 - val_acc: 0.1429\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1025 - acc: 0.9718 - val_loss: 7.3895 - val_acc: 0.2500\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0958 - acc: 0.9708 - val_loss: 2.0812 - val_acc: 0.6198\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1377 - acc: 0.9639 - val_loss: 4.4080 - val_acc: 0.3698\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1502 - acc: 0.9519 - val_loss: 11.0554 - val_acc: 0.1562\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0901 - acc: 0.9728 - val_loss: 0.3162 - val_acc: 0.9048\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0772 - acc: 0.9768 - val_loss: 0.3000 - val_acc: 0.8958\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0946 - acc: 0.9690 - val_loss: 0.2427 - val_acc: 0.9479\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0669 - acc: 0.9779 - val_loss: 0.1047 - val_acc: 0.9688\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0395 - acc: 0.9919 - val_loss: 0.4487 - val_acc: 0.8542\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0630 - acc: 0.9689 - val_loss: 0.1653 - val_acc: 0.9464\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0407 - acc: 0.9869 - val_loss: 0.4069 - val_acc: 0.9010\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0519 - acc: 0.9859 - val_loss: 0.2356 - val_acc: 0.9635\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0485 - acc: 0.9879 - val_loss: 0.1446 - val_acc: 0.9479\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0572 - acc: 0.9850 - val_loss: 0.6899 - val_acc: 0.7917\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0502 - acc: 0.9859 - val_loss: 0.9835 - val_acc: 0.7188\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0301 - acc: 0.9890 - val_loss: 1.3612 - val_acc: 0.7321\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0627 - acc: 0.9789 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0747 - acc: 0.9780 - val_loss: 0.2556 - val_acc: 0.9219\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0389 - acc: 0.9899 - val_loss: 0.0852 - val_acc: 0.9740\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0292 - acc: 0.9899 - val_loss: 0.5914 - val_acc: 0.8542\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0476 - acc: 0.9870 - val_loss: 0.0919 - val_acc: 0.9464\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0252 - acc: 0.9939 - val_loss: 0.0981 - val_acc: 0.9792\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0598 - val_acc: 0.9844\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0138 - acc: 0.9980 - val_loss: 0.1951 - val_acc: 0.9635\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0182 - acc: 0.9960 - val_loss: 0.2329 - val_acc: 0.9531\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0186 - acc: 0.9970 - val_loss: 0.1424 - val_acc: 0.9524\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.1886 - val_acc: 0.9531\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0099 - acc: 0.9990 - val_loss: 0.0510 - val_acc: 0.9896\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0189 - acc: 0.9950 - val_loss: 0.3695 - val_acc: 0.9375\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0480 - acc: 0.9792 - val_loss: 9.1595 - val_acc: 0.2135\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0394 - acc: 0.9829 - val_loss: 1.5296 - val_acc: 0.6615\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.5782 - val_acc: 0.8690\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0250 - acc: 0.9950 - val_loss: 0.4476 - val_acc: 0.8698\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0269 - acc: 0.9950 - val_loss: 1.8152 - val_acc: 0.6875\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0679 - val_acc: 0.9844\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0219 - acc: 0.9920 - val_loss: 0.3620 - val_acc: 0.8854\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0137 - acc: 0.9980 - val_loss: 0.2587 - val_acc: 0.9464\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0201 - acc: 0.9960 - val_loss: 0.0788 - val_acc: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0140 - acc: 0.9960 - val_loss: 0.1147 - val_acc: 0.9844\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0181 - acc: 0.9970 - val_loss: 0.1317 - val_acc: 0.9688\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0585 - acc: 0.9831 - val_loss: 0.1132 - val_acc: 0.9635\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0278 - acc: 0.9909 - val_loss: 0.1966 - val_acc: 0.9643\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0249 - acc: 0.9930 - val_loss: 0.1222 - val_acc: 0.9531\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0127 - acc: 0.9970 - val_loss: 0.0681 - val_acc: 0.9740\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0192 - acc: 0.9950 - val_loss: 0.1095 - val_acc: 0.9896\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0097 - acc: 0.9990 - val_loss: 0.1134 - val_acc: 0.9740\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.2150 - val_acc: 0.9635\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0226 - acc: 0.9910 - val_loss: 0.0810 - val_acc: 0.9702\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0179 - acc: 0.9930 - val_loss: 0.0860 - val_acc: 0.9792\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 1.4551 - val_acc: 0.7865\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0251 - acc: 0.9950 - val_loss: 0.3968 - val_acc: 0.9271\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1586 - acc: 0.9438 - val_loss: 14.3287 - val_acc: 0.0990\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0773 - acc: 0.9759 - val_loss: 1.9282 - val_acc: 0.5595\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0299 - acc: 0.9889 - val_loss: 0.3016 - val_acc: 0.9062\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0352 - acc: 0.9869 - val_loss: 0.2979 - val_acc: 0.9271\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0168 - acc: 0.9980 - val_loss: 0.1720 - val_acc: 0.9271\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0315 - acc: 0.9919 - val_loss: 0.6333 - val_acc: 0.8490\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0139 - acc: 0.9939 - val_loss: 0.1604 - val_acc: 0.9524\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0133 - acc: 0.9939 - val_loss: 0.3038 - val_acc: 0.9323\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0201 - acc: 0.9950 - val_loss: 0.4328 - val_acc: 0.8906\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.1472 - val_acc: 0.9479\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0546 - acc: 0.9809 - val_loss: 3.6257 - val_acc: 0.5677\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0232 - acc: 0.9939 - val_loss: 1.2429 - val_acc: 0.7188\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0220 - acc: 0.9960 - val_loss: 2.4326 - val_acc: 0.6905\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0172 - acc: 0.9939 - val_loss: 12.9842 - val_acc: 0.1406\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0189 - acc: 0.9939 - val_loss: 2.2699 - val_acc: 0.6615\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0220 - acc: 0.9940 - val_loss: 0.0750 - val_acc: 0.9635\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0320 - acc: 0.9940 - val_loss: 2.8927 - val_acc: 0.4219\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.3525 - val_acc: 0.9048\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0172 - acc: 0.9929 - val_loss: 0.3052 - val_acc: 0.9219\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0133 - acc: 0.9970 - val_loss: 1.2846 - val_acc: 0.6979\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0167 - acc: 0.9970 - val_loss: 0.2303 - val_acc: 0.9531\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0141 - acc: 0.9970 - val_loss: 0.0341 - val_acc: 0.9844\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0178 - acc: 0.9950 - val_loss: 0.1214 - val_acc: 0.9583\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0130 - acc: 0.9970 - val_loss: 0.6675 - val_acc: 0.8594\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0469 - acc: 0.9920 - val_loss: 0.1941 - val_acc: 0.9375\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0127 - acc: 0.9990 - val_loss: 0.0725 - val_acc: 0.9635\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.2892 - val_acc: 0.9427\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 0.9844\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0107 - acc: 0.9980 - val_loss: 11.1687 - val_acc: 0.1845\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0184 - acc: 0.9939 - val_loss: 8.6506 - val_acc: 0.2708\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0172 - acc: 0.9950 - val_loss: 3.5149 - val_acc: 0.4375\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0190 - acc: 0.9960 - val_loss: 0.1734 - val_acc: 0.9479\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0174 - acc: 0.9920 - val_loss: 1.1592 - val_acc: 0.7292\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0206 - acc: 0.9919 - val_loss: 1.8555 - val_acc: 0.6488\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.4489 - val_acc: 0.8854\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0104 - acc: 0.9990 - val_loss: 0.7531 - val_acc: 0.8177\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.84242618742\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 84ms/step - loss: 1.8403 - acc: 0.3729 - val_loss: 7.1730 - val_acc: 0.1458\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.4744 - acc: 0.4499 - val_loss: 2.4251 - val_acc: 0.3274\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3623 - acc: 0.4800 - val_loss: 2.0812 - val_acc: 0.3698\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2570 - acc: 0.5361 - val_loss: 2.8234 - val_acc: 0.2083\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2114 - acc: 0.5545 - val_loss: 6.2895 - val_acc: 0.1146\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2688 - acc: 0.5332 - val_loss: 4.6191 - val_acc: 0.1406\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1130 - acc: 0.5603 - val_loss: 12.8722 - val_acc: 0.1302\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1214 - acc: 0.5817 - val_loss: 2.6217 - val_acc: 0.2619\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1619 - acc: 0.6057 - val_loss: 13.1989 - val_acc: 0.1354\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1118 - acc: 0.5686 - val_loss: 12.8127 - val_acc: 0.1615\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0648 - acc: 0.6058 - val_loss: 4.9178 - val_acc: 0.2292\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.1180 - acc: 0.5918 - val_loss: 0.7624 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.9097 - acc: 0.6461 - val_loss: 3.2813 - val_acc: 0.3155\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9595 - acc: 0.6434 - val_loss: 9.5830 - val_acc: 0.2135\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9664 - acc: 0.6472 - val_loss: 5.5737 - val_acc: 0.4115\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8586 - acc: 0.6795 - val_loss: 9.4880 - val_acc: 0.2031\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8721 - acc: 0.6684 - val_loss: 10.9711 - val_acc: 0.1146\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8369 - acc: 0.7066 - val_loss: 7.7605 - val_acc: 0.1905\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7185 - acc: 0.7288 - val_loss: 0.9247 - val_acc: 0.6979\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8108 - acc: 0.6826 - val_loss: 0.4967 - val_acc: 0.8281\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7598 - acc: 0.7229 - val_loss: 0.4913 - val_acc: 0.8073\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7043 - acc: 0.7388 - val_loss: 0.5796 - val_acc: 0.7708\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6486 - acc: 0.7700 - val_loss: 1.0087 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6193 - acc: 0.7692 - val_loss: 0.7030 - val_acc: 0.7321\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6332 - acc: 0.7722 - val_loss: 0.8046 - val_acc: 0.7240\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6682 - acc: 0.7814 - val_loss: 0.4975 - val_acc: 0.8438\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5630 - acc: 0.7855 - val_loss: 0.7700 - val_acc: 0.7708\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.7301 - acc: 0.7460 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0625 - acc: 0.6141 - val_loss: 14.4871 - val_acc: 0.1012\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8106 - acc: 0.7057 - val_loss: 10.2034 - val_acc: 0.1094\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.7419 - acc: 0.7401 - val_loss: 1.1983 - val_acc: 0.6302\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7258 - acc: 0.7410 - val_loss: 2.8473 - val_acc: 0.3958\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6618 - acc: 0.7614 - val_loss: 6.6479 - val_acc: 0.2344\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5782 - acc: 0.8004 - val_loss: 12.7832 - val_acc: 0.1071\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5415 - acc: 0.7995 - val_loss: 7.0386 - val_acc: 0.2240\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4894 - acc: 0.8185 - val_loss: 7.4870 - val_acc: 0.2552\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5472 - acc: 0.7854 - val_loss: 1.1996 - val_acc: 0.6667\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5327 - acc: 0.8125 - val_loss: 10.2203 - val_acc: 0.1302\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4387 - acc: 0.8468 - val_loss: 3.1838 - val_acc: 0.4375\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4372 - acc: 0.8548 - val_loss: 6.5952 - val_acc: 0.2440\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4558 - acc: 0.8459 - val_loss: 7.9635 - val_acc: 0.2031\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4884 - acc: 0.8316 - val_loss: 0.3118 - val_acc: 0.8958\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3503 - acc: 0.8780 - val_loss: 0.6523 - val_acc: 0.8438\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3981 - acc: 0.8509 - val_loss: 2.3709 - val_acc: 0.5469\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3618 - acc: 0.8629 - val_loss: 0.3515 - val_acc: 0.8810\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3793 - acc: 0.8599 - val_loss: 0.7157 - val_acc: 0.8021\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3476 - acc: 0.8740 - val_loss: 0.3661 - val_acc: 0.9062\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4019 - acc: 0.8649 - val_loss: 0.1574 - val_acc: 0.9531\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3367 - acc: 0.8771 - val_loss: 0.7111 - val_acc: 0.7917\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3981 - acc: 0.8670 - val_loss: 0.6521 - val_acc: 0.8452\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3869 - acc: 0.8709 - val_loss: 0.3704 - val_acc: 0.8802\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3783 - acc: 0.8731 - val_loss: 0.5239 - val_acc: 0.8802\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4482 - acc: 0.8457 - val_loss: 0.3997 - val_acc: 0.8750\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3870 - acc: 0.8550 - val_loss: 0.6452 - val_acc: 0.8177\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3030 - acc: 0.8962 - val_loss: 0.2210 - val_acc: 0.9167\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2847 - acc: 0.8982 - val_loss: 0.1814 - val_acc: 0.9583\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2908 - acc: 0.9083 - val_loss: 0.4338 - val_acc: 0.9010\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4059 - acc: 0.8550 - val_loss: 0.6613 - val_acc: 0.8281\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3294 - acc: 0.8821 - val_loss: 0.1814 - val_acc: 0.9479\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3200 - acc: 0.8982 - val_loss: 0.2358 - val_acc: 0.9427\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2893 - acc: 0.8931 - val_loss: 0.7963 - val_acc: 0.7798\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3353 - acc: 0.8742 - val_loss: 0.5390 - val_acc: 0.8333\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2650 - acc: 0.8922 - val_loss: 0.2385 - val_acc: 0.9427\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2710 - acc: 0.9043 - val_loss: 0.4541 - val_acc: 0.8906\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3614 - acc: 0.8901 - val_loss: 0.9936 - val_acc: 0.7240\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2953 - acc: 0.8962 - val_loss: 0.1264 - val_acc: 0.9524\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2748 - acc: 0.9132 - val_loss: 1.3355 - val_acc: 0.7344\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2754 - acc: 0.9063 - val_loss: 0.4830 - val_acc: 0.8958\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2845 - acc: 0.8981 - val_loss: 0.2812 - val_acc: 0.9271\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2979 - acc: 0.9025 - val_loss: 0.6903 - val_acc: 0.8385\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2909 - acc: 0.8973 - val_loss: 0.2173 - val_acc: 0.9323\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2690 - acc: 0.9053 - val_loss: 0.2038 - val_acc: 0.9167\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3043 - acc: 0.8952 - val_loss: 2.8055 - val_acc: 0.5052\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2954 - acc: 0.9021 - val_loss: 0.5770 - val_acc: 0.8125\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2371 - acc: 0.9163 - val_loss: 0.3414 - val_acc: 0.9219\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3011 - acc: 0.8971 - val_loss: 0.2373 - val_acc: 0.9375\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2608 - acc: 0.9042 - val_loss: 0.2420 - val_acc: 0.9405\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3225 - acc: 0.8891 - val_loss: 0.1355 - val_acc: 0.9531\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2281 - acc: 0.9315 - val_loss: 0.2142 - val_acc: 0.9635\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3714 - acc: 0.8891 - val_loss: 0.1262 - val_acc: 0.9635\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1991 - acc: 0.9245 - val_loss: 2.3321 - val_acc: 0.5885\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2533 - acc: 0.9063 - val_loss: 0.3425 - val_acc: 0.9405\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2018 - acc: 0.9284 - val_loss: 0.2780 - val_acc: 0.9323\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3249 - acc: 0.8943 - val_loss: 0.2692 - val_acc: 0.9271\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3008 - acc: 0.9104 - val_loss: 0.4298 - val_acc: 0.8958\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2024 - acc: 0.9214 - val_loss: 0.2186 - val_acc: 0.9323\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1834 - acc: 0.9435 - val_loss: 0.6648 - val_acc: 0.8542\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2191 - acc: 0.9224 - val_loss: 0.1245 - val_acc: 0.9643\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2604 - acc: 0.9243 - val_loss: 1.3440 - val_acc: 0.7292\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2937 - acc: 0.8993 - val_loss: 0.2072 - val_acc: 0.9375\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1987 - acc: 0.9314 - val_loss: 0.3198 - val_acc: 0.9115\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2221 - acc: 0.9233 - val_loss: 0.3879 - val_acc: 0.9167\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1848 - acc: 0.9325 - val_loss: 0.6551 - val_acc: 0.8512\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2634 - acc: 0.9095 - val_loss: 1.0567 - val_acc: 0.7969\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2471 - acc: 0.9193 - val_loss: 0.1288 - val_acc: 0.9635\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2364 - acc: 0.9255 - val_loss: 3.0942 - val_acc: 0.5469\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2740 - acc: 0.9021 - val_loss: 0.9481 - val_acc: 0.8229\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3399 - acc: 0.9116 - val_loss: 0.6526 - val_acc: 0.8571\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4035 - acc: 0.8824 - val_loss: 1.0966 - val_acc: 0.7760\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4600 - acc: 0.8702 - val_loss: 1.5179 - val_acc: 0.7240\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.686061381074\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 94ms/step - loss: 2.0526 - acc: 0.3869 - val_loss: 6.9367 - val_acc: 0.2760\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.4860 - acc: 0.5240 - val_loss: 2.4483 - val_acc: 0.4479\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.2469 - acc: 0.5475 - val_loss: 2.4625 - val_acc: 0.3036\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1016 - acc: 0.5956 - val_loss: 4.9836 - val_acc: 0.2448\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0677 - acc: 0.6152 - val_loss: 3.4910 - val_acc: 0.3333\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9272 - acc: 0.6704 - val_loss: 12.8464 - val_acc: 0.1458\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8348 - acc: 0.6886 - val_loss: 13.1834 - val_acc: 0.1406\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7644 - acc: 0.7017 - val_loss: 14.4749 - val_acc: 0.0655\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7659 - acc: 0.7141 - val_loss: 14.8589 - val_acc: 0.0781\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7183 - acc: 0.7399 - val_loss: 13.5898 - val_acc: 0.1458\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6212 - acc: 0.7693 - val_loss: 3.2205 - val_acc: 0.4479\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5339 - acc: 0.8075 - val_loss: 12.4597 - val_acc: 0.1302\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4732 - acc: 0.8328 - val_loss: 13.3002 - val_acc: 0.1429\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5465 - acc: 0.8198 - val_loss: 12.5253 - val_acc: 0.1562\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4524 - acc: 0.8316 - val_loss: 4.8865 - val_acc: 0.3594\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3789 - acc: 0.8681 - val_loss: 8.6424 - val_acc: 0.1979\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3649 - acc: 0.8740 - val_loss: 4.7063 - val_acc: 0.3594\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3826 - acc: 0.8661 - val_loss: 5.5285 - val_acc: 0.3854\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3382 - acc: 0.8770 - val_loss: 0.6525 - val_acc: 0.8155\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2575 - acc: 0.9092 - val_loss: 1.9529 - val_acc: 0.5885\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2554 - acc: 0.9082 - val_loss: 5.9530 - val_acc: 0.2812\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2480 - acc: 0.9114 - val_loss: 0.9733 - val_acc: 0.7396\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1801 - acc: 0.9304 - val_loss: 0.3303 - val_acc: 0.8906\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2533 - acc: 0.9113 - val_loss: 1.1414 - val_acc: 0.6786\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4476 - acc: 0.8733 - val_loss: 12.3166 - val_acc: 0.1250\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3015 - acc: 0.8851 - val_loss: 11.0999 - val_acc: 0.1615\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2455 - acc: 0.9256 - val_loss: 0.8645 - val_acc: 0.7448\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2644 - acc: 0.9305 - val_loss: 1.2688 - val_acc: 0.6510\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2014 - acc: 0.9335 - val_loss: 2.5315 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3111 - acc: 0.9096 - val_loss: 3.9101 - val_acc: 0.4323\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3203 - acc: 0.9045 - val_loss: 1.0238 - val_acc: 0.6927\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2208 - acc: 0.9234 - val_loss: 0.3582 - val_acc: 0.9010\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2096 - acc: 0.9167 - val_loss: 6.9393 - val_acc: 0.2969\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1714 - acc: 0.9426 - val_loss: 0.4477 - val_acc: 0.8802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1642 - acc: 0.9365 - val_loss: 1.8871 - val_acc: 0.6012\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1562 - acc: 0.9507 - val_loss: 0.8343 - val_acc: 0.7812\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2026 - acc: 0.9446 - val_loss: 0.5228 - val_acc: 0.8125\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1682 - acc: 0.9367 - val_loss: 6.8867 - val_acc: 0.3021\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2295 - acc: 0.9295 - val_loss: 5.6831 - val_acc: 0.4167\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1510 - acc: 0.9557 - val_loss: 1.1056 - val_acc: 0.7976\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1225 - acc: 0.9596 - val_loss: 1.7249 - val_acc: 0.6250\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2130 - acc: 0.9408 - val_loss: 13.5842 - val_acc: 0.1302\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3136 - acc: 0.9004 - val_loss: 3.6265 - val_acc: 0.4219\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2182 - acc: 0.9315 - val_loss: 2.6747 - val_acc: 0.4948\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2117 - acc: 0.9327 - val_loss: 0.3838 - val_acc: 0.9107\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1980 - acc: 0.9366 - val_loss: 0.2040 - val_acc: 0.9375\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1975 - acc: 0.9427 - val_loss: 1.0286 - val_acc: 0.7500\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1071 - acc: 0.9617 - val_loss: 0.1739 - val_acc: 0.9271\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2048 - acc: 0.9408 - val_loss: 0.1818 - val_acc: 0.9375\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1292 - acc: 0.9526 - val_loss: 0.1480 - val_acc: 0.9479\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1158 - acc: 0.9597 - val_loss: 0.8066 - val_acc: 0.7738\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0942 - acc: 0.9677 - val_loss: 1.9316 - val_acc: 0.6042\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0890 - acc: 0.9677 - val_loss: 0.1894 - val_acc: 0.9271\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0922 - acc: 0.9728 - val_loss: 0.3618 - val_acc: 0.8906\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1250 - acc: 0.9597 - val_loss: 0.7806 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1480 - acc: 0.9608 - val_loss: 0.1468 - val_acc: 0.9643\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0834 - acc: 0.9718 - val_loss: 0.4533 - val_acc: 0.8646\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1427 - acc: 0.9579 - val_loss: 0.7846 - val_acc: 0.8021\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0805 - acc: 0.9708 - val_loss: 0.8764 - val_acc: 0.7656\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3022 - acc: 0.9043 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3161 - acc: 0.9003 - val_loss: 11.8800 - val_acc: 0.1369\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1450 - acc: 0.9516 - val_loss: 1.8321 - val_acc: 0.6562\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1200 - acc: 0.9546 - val_loss: 0.1237 - val_acc: 0.9583\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1058 - acc: 0.9586 - val_loss: 1.0530 - val_acc: 0.7604\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0993 - acc: 0.9617 - val_loss: 0.6594 - val_acc: 0.8542\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0903 - acc: 0.9677 - val_loss: 2.4631 - val_acc: 0.5990\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0857 - acc: 0.9729 - val_loss: 0.4045 - val_acc: 0.8929\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1137 - acc: 0.9608 - val_loss: 1.1413 - val_acc: 0.7083\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1635 - acc: 0.9548 - val_loss: 7.6441 - val_acc: 0.2396\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1788 - acc: 0.9325 - val_loss: 0.6630 - val_acc: 0.8333\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1295 - acc: 0.9547 - val_loss: 1.5882 - val_acc: 0.7188\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1035 - acc: 0.9617 - val_loss: 0.6161 - val_acc: 0.8214\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1045 - acc: 0.9670 - val_loss: 1.3138 - val_acc: 0.6979\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0698 - acc: 0.9738 - val_loss: 2.3048 - val_acc: 0.5885\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1123 - acc: 0.9668 - val_loss: 5.4896 - val_acc: 0.3594\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0986 - acc: 0.9597 - val_loss: 2.2280 - val_acc: 0.6042\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0703 - acc: 0.9738 - val_loss: 6.1097 - val_acc: 0.3214\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0764 - acc: 0.9729 - val_loss: 0.5496 - val_acc: 0.8490\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0456 - acc: 0.9889 - val_loss: 0.1621 - val_acc: 0.9479\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0821 - acc: 0.9729 - val_loss: 0.1457 - val_acc: 0.9635\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0924 - acc: 0.9739 - val_loss: 0.3075 - val_acc: 0.9271\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0836 - acc: 0.9729 - val_loss: 0.1144 - val_acc: 0.9688\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0448 - acc: 0.9798 - val_loss: 0.2489 - val_acc: 0.9524\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0904 - acc: 0.9729 - val_loss: 0.3252 - val_acc: 0.8906\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0766 - acc: 0.9768 - val_loss: 0.1450 - val_acc: 0.9688\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0911 - acc: 0.9660 - val_loss: 0.5517 - val_acc: 0.8542\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0778 - acc: 0.9738 - val_loss: 0.2085 - val_acc: 0.9427\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0528 - acc: 0.9828 - val_loss: 0.3380 - val_acc: 0.8929\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1318 - acc: 0.9649 - val_loss: 0.2179 - val_acc: 0.9375\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1135 - acc: 0.9638 - val_loss: 0.5750 - val_acc: 0.8542\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0724 - acc: 0.9779 - val_loss: 0.4698 - val_acc: 0.8750\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0801 - acc: 0.9707 - val_loss: 0.2059 - val_acc: 0.9531\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0692 - acc: 0.9779 - val_loss: 0.4938 - val_acc: 0.8690\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0414 - acc: 0.9879 - val_loss: 0.1435 - val_acc: 0.9583\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0527 - acc: 0.9818 - val_loss: 0.3074 - val_acc: 0.9219\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0491 - acc: 0.9839 - val_loss: 0.1955 - val_acc: 0.9479\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0457 - acc: 0.9818 - val_loss: 0.0618 - val_acc: 0.9896\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0296 - acc: 0.9929 - val_loss: 0.0540 - val_acc: 0.9844\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0823 - acc: 0.9761 - val_loss: 0.2250 - val_acc: 0.9345\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0549 - acc: 0.9808 - val_loss: 0.3700 - val_acc: 0.9062\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.916879795396\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 90ms/step - loss: 1.7848 - acc: 0.4355 - val_loss: 14.1033 - val_acc: 0.1250\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.1578 - acc: 0.5726 - val_loss: 1.7357 - val_acc: 0.4635\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8474 - acc: 0.6842 - val_loss: 11.6790 - val_acc: 0.1250\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.8174 - acc: 0.7090 - val_loss: 14.7383 - val_acc: 0.0833\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6400 - acc: 0.7630 - val_loss: 14.8569 - val_acc: 0.0781\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5196 - acc: 0.7986 - val_loss: 11.5512 - val_acc: 0.1406\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3947 - acc: 0.8570 - val_loss: 2.6836 - val_acc: 0.4479\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3674 - acc: 0.8591 - val_loss: 0.7117 - val_acc: 0.7619\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3163 - acc: 0.8974 - val_loss: 4.7152 - val_acc: 0.2969\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2953 - acc: 0.8881 - val_loss: 0.1821 - val_acc: 0.9375\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3098 - acc: 0.8913 - val_loss: 0.1694 - val_acc: 0.9427\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2479 - acc: 0.9143 - val_loss: 0.5932 - val_acc: 0.8125\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1999 - acc: 0.9295 - val_loss: 0.6503 - val_acc: 0.7760\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1968 - acc: 0.9276 - val_loss: 0.1863 - val_acc: 0.9405\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1832 - acc: 0.9336 - val_loss: 0.1906 - val_acc: 0.9323\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1390 - acc: 0.9566 - val_loss: 0.2549 - val_acc: 0.9271\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1452 - acc: 0.9465 - val_loss: 0.0810 - val_acc: 0.9688\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1482 - acc: 0.9437 - val_loss: 0.3015 - val_acc: 0.9010\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1609 - acc: 0.9445 - val_loss: 0.0895 - val_acc: 0.9643\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1524 - acc: 0.9446 - val_loss: 5.2961 - val_acc: 0.2760\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1189 - acc: 0.9607 - val_loss: 0.1899 - val_acc: 0.9479\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1163 - acc: 0.9587 - val_loss: 0.3831 - val_acc: 0.8906\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1140 - acc: 0.9627 - val_loss: 1.6524 - val_acc: 0.6146\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1070 - acc: 0.9657 - val_loss: 0.1728 - val_acc: 0.9345\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0890 - acc: 0.9748 - val_loss: 0.0936 - val_acc: 0.9740\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0927 - acc: 0.9679 - val_loss: 0.2312 - val_acc: 0.9219\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0665 - acc: 0.9788 - val_loss: 0.9899 - val_acc: 0.7083\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1159 - acc: 0.9668 - val_loss: 0.1398 - val_acc: 0.9583\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1340 - acc: 0.9538 - val_loss: 0.3627 - val_acc: 0.8906\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1277 - acc: 0.9547 - val_loss: 0.1432 - val_acc: 0.9524\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1186 - acc: 0.9598 - val_loss: 1.1247 - val_acc: 0.7083\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0749 - acc: 0.9788 - val_loss: 1.1590 - val_acc: 0.6875\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0602 - acc: 0.9758 - val_loss: 0.4828 - val_acc: 0.8854\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0592 - acc: 0.9798 - val_loss: 0.1561 - val_acc: 0.9479\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0506 - acc: 0.9879 - val_loss: 0.5079 - val_acc: 0.8690\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0997 - acc: 0.9699 - val_loss: 2.8027 - val_acc: 0.4688\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0724 - acc: 0.9718 - val_loss: 0.5604 - val_acc: 0.8750\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0495 - acc: 0.9859 - val_loss: 0.4819 - val_acc: 0.8750\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0632 - acc: 0.9750 - val_loss: 0.8267 - val_acc: 0.7969\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0556 - acc: 0.9818 - val_loss: 0.0689 - val_acc: 0.9762\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0521 - acc: 0.9869 - val_loss: 0.2642 - val_acc: 0.9062\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0591 - acc: 0.9808 - val_loss: 0.2657 - val_acc: 0.9375\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0417 - acc: 0.9849 - val_loss: 0.1436 - val_acc: 0.9583\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0768 - acc: 0.9749 - val_loss: 0.1538 - val_acc: 0.9479\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0376 - acc: 0.9889 - val_loss: 0.4758 - val_acc: 0.8854\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0565 - acc: 0.9819 - val_loss: 0.2086 - val_acc: 0.9524\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0451 - acc: 0.9869 - val_loss: 0.1576 - val_acc: 0.9688\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0748 - acc: 0.9769 - val_loss: 0.0364 - val_acc: 0.9896\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0409 - acc: 0.9899 - val_loss: 0.1183 - val_acc: 0.9688\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0471 - acc: 0.9860 - val_loss: 0.0794 - val_acc: 0.9635\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0414 - acc: 0.9859 - val_loss: 0.2775 - val_acc: 0.9048\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0496 - acc: 0.9818 - val_loss: 0.1334 - val_acc: 0.9583\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0375 - acc: 0.9889 - val_loss: 1.3318 - val_acc: 0.6771\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0313 - acc: 0.9919 - val_loss: 0.1469 - val_acc: 0.9688\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0314 - acc: 0.9939 - val_loss: 0.0914 - val_acc: 0.9688\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0712 - acc: 0.9818 - val_loss: 0.2180 - val_acc: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0342 - acc: 0.9899 - val_loss: 0.1500 - val_acc: 0.9688\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0324 - acc: 0.9889 - val_loss: 0.2998 - val_acc: 0.9062\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0523 - acc: 0.9769 - val_loss: 0.5883 - val_acc: 0.8594\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0421 - acc: 0.9869 - val_loss: 0.0570 - val_acc: 0.9792\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0361 - acc: 0.9859 - val_loss: 0.4974 - val_acc: 0.8542\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0479 - acc: 0.9849 - val_loss: 0.1030 - val_acc: 0.9821\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0659 - acc: 0.9748 - val_loss: 0.5935 - val_acc: 0.8646\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0369 - acc: 0.9840 - val_loss: 0.0665 - val_acc: 0.9844\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0784 - val_acc: 0.9792\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0286 - acc: 0.9889 - val_loss: 0.0477 - val_acc: 0.9792\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0551 - acc: 0.9870 - val_loss: 3.7673 - val_acc: 0.5119\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0595 - acc: 0.9808 - val_loss: 3.4916 - val_acc: 0.5625\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0436 - acc: 0.9869 - val_loss: 0.0878 - val_acc: 0.9688\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0439 - acc: 0.9840 - val_loss: 0.0818 - val_acc: 0.9792\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0719 - acc: 0.9739 - val_loss: 7.6375 - val_acc: 0.4062\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0482 - acc: 0.9808 - val_loss: 0.2457 - val_acc: 0.9643\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0875 - acc: 0.9759 - val_loss: 1.1048 - val_acc: 0.7448\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0511 - acc: 0.9819 - val_loss: 0.0638 - val_acc: 0.9844\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0281 - acc: 0.9899 - val_loss: 0.3052 - val_acc: 0.9375\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.1875 - val_acc: 0.9583\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0418 - acc: 0.9809 - val_loss: 0.1195 - val_acc: 0.9844\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0767 - acc: 0.9780 - val_loss: 0.3866 - val_acc: 0.8988\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0840 - acc: 0.9900 - val_loss: 0.1013 - val_acc: 0.9740\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.2115 - val_acc: 0.9792\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0825 - acc: 0.9740 - val_loss: 3.6162 - val_acc: 0.4531\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0724 - acc: 0.9780 - val_loss: 0.1474 - val_acc: 0.9531\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0466 - acc: 0.9779 - val_loss: 2.9190 - val_acc: 0.5298\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0313 - acc: 0.9899 - val_loss: 0.1908 - val_acc: 0.9375\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0207 - acc: 0.9909 - val_loss: 1.0272 - val_acc: 0.7135\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0230 - acc: 0.9909 - val_loss: 0.2265 - val_acc: 0.9635\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0327 - acc: 0.9899 - val_loss: 0.4959 - val_acc: 0.8646\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.1117 - val_acc: 0.9821\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0330 - acc: 0.9849 - val_loss: 0.4184 - val_acc: 0.8750\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0608 - acc: 0.9840 - val_loss: 0.1146 - val_acc: 0.9688\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0250 - acc: 0.9889 - val_loss: 0.1403 - val_acc: 0.9583\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0176 - acc: 0.9950 - val_loss: 0.1639 - val_acc: 0.9688\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0202 - acc: 0.9930 - val_loss: 0.2615 - val_acc: 0.9531\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0378 - acc: 0.9879 - val_loss: 0.8851 - val_acc: 0.7619\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0346 - acc: 0.9860 - val_loss: 0.9183 - val_acc: 0.7604\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0238 - acc: 0.9909 - val_loss: 0.2469 - val_acc: 0.9271\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0241 - acc: 0.9910 - val_loss: 0.4158 - val_acc: 0.8906\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0416 - acc: 0.9890 - val_loss: 0.8142 - val_acc: 0.8385\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0302 - acc: 0.9929 - val_loss: 0.2159 - val_acc: 0.9405\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0159 - acc: 0.9970 - val_loss: 0.1029 - val_acc: 0.9583\n",
      "200/200 [==============================] - 3s 14ms/step\n",
      "Test accuracy: 0.966142490372\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 2.6475 - acc: 0.1603 - val_loss: 2.3253 - val_acc: 0.1979\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.2278 - acc: 0.2095 - val_loss: 2.5289 - val_acc: 0.0938\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0624 - acc: 0.2551 - val_loss: 2.2587 - val_acc: 0.1429\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0026 - acc: 0.2813 - val_loss: 1.8988 - val_acc: 0.2656\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.9330 - acc: 0.2723 - val_loss: 1.8837 - val_acc: 0.2656\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8781 - acc: 0.2955 - val_loss: 1.6920 - val_acc: 0.3333\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8829 - acc: 0.3095 - val_loss: 1.6575 - val_acc: 0.3542\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8262 - acc: 0.3255 - val_loss: 2.1862 - val_acc: 0.1719\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7967 - acc: 0.3244 - val_loss: 5.0836 - val_acc: 0.0893\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.8086 - acc: 0.3095 - val_loss: 1.7307 - val_acc: 0.2500\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.7385 - acc: 0.3437 - val_loss: 2.1503 - val_acc: 0.2292\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7776 - acc: 0.3236 - val_loss: 1.9577 - val_acc: 0.2344\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7962 - acc: 0.3336 - val_loss: 1.6935 - val_acc: 0.3385\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7500 - acc: 0.3389 - val_loss: 1.7684 - val_acc: 0.2500\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7719 - acc: 0.3468 - val_loss: 1.5795 - val_acc: 0.4219\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6535 - acc: 0.3739 - val_loss: 1.6065 - val_acc: 0.3906\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6997 - acc: 0.3669 - val_loss: 1.9003 - val_acc: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6969 - acc: 0.3378 - val_loss: 2.0322 - val_acc: 0.2292\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7020 - acc: 0.3650 - val_loss: 1.4412 - val_acc: 0.4167\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6900 - acc: 0.3368 - val_loss: 2.9763 - val_acc: 0.1562\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7071 - acc: 0.3761 - val_loss: 1.5018 - val_acc: 0.4115\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6797 - acc: 0.3821 - val_loss: 3.0272 - val_acc: 0.1406\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6899 - acc: 0.3599 - val_loss: 1.6615 - val_acc: 0.3906\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6991 - acc: 0.3659 - val_loss: 1.4679 - val_acc: 0.4271\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7019 - acc: 0.3450 - val_loss: 1.6717 - val_acc: 0.3571\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6551 - acc: 0.3601 - val_loss: 2.2624 - val_acc: 0.2344\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6325 - acc: 0.3934 - val_loss: 1.5681 - val_acc: 0.4010\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6768 - acc: 0.3540 - val_loss: 2.5457 - val_acc: 0.1667\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6368 - acc: 0.3809 - val_loss: 2.8367 - val_acc: 0.1510\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6092 - acc: 0.3951 - val_loss: 1.4055 - val_acc: 0.5060\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6230 - acc: 0.3810 - val_loss: 2.7741 - val_acc: 0.1979\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6243 - acc: 0.3750 - val_loss: 1.6986 - val_acc: 0.3281\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6116 - acc: 0.3832 - val_loss: 1.4612 - val_acc: 0.4375\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5631 - acc: 0.4053 - val_loss: 1.7678 - val_acc: 0.2812\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5897 - acc: 0.4010 - val_loss: 1.8886 - val_acc: 0.2917\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6389 - acc: 0.3810 - val_loss: 1.4038 - val_acc: 0.4531\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5949 - acc: 0.4075 - val_loss: 1.9461 - val_acc: 0.2917\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6194 - acc: 0.3831 - val_loss: 1.3699 - val_acc: 0.4375\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6044 - acc: 0.3669 - val_loss: 1.4526 - val_acc: 0.4010\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5607 - acc: 0.4013 - val_loss: 1.4067 - val_acc: 0.4115\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5758 - acc: 0.4043 - val_loss: 2.8913 - val_acc: 0.1845\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.6165 - acc: 0.3883 - val_loss: 3.7300 - val_acc: 0.1198\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5982 - acc: 0.4052 - val_loss: 4.3575 - val_acc: 0.1354\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5863 - acc: 0.4001 - val_loss: 1.6433 - val_acc: 0.3750\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5556 - acc: 0.4063 - val_loss: 2.7291 - val_acc: 0.2083\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.6044 - acc: 0.3821 - val_loss: 1.6351 - val_acc: 0.3333\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5854 - acc: 0.4003 - val_loss: 1.4188 - val_acc: 0.4427\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5863 - acc: 0.3922 - val_loss: 1.3797 - val_acc: 0.4479\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5847 - acc: 0.4052 - val_loss: 1.2772 - val_acc: 0.5208\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5393 - acc: 0.4001 - val_loss: 1.4424 - val_acc: 0.4219\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5705 - acc: 0.4064 - val_loss: 1.3740 - val_acc: 0.4702\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5918 - acc: 0.3852 - val_loss: 5.7300 - val_acc: 0.1354\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5454 - acc: 0.4155 - val_loss: 3.7663 - val_acc: 0.1302\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5660 - acc: 0.4022 - val_loss: 1.3728 - val_acc: 0.4740\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5418 - acc: 0.4184 - val_loss: 1.2528 - val_acc: 0.5052\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5817 - acc: 0.4166 - val_loss: 1.8707 - val_acc: 0.3125\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5025 - acc: 0.4105 - val_loss: 1.2113 - val_acc: 0.5655\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5469 - acc: 0.4254 - val_loss: 1.3209 - val_acc: 0.4792\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5220 - acc: 0.4285 - val_loss: 1.3388 - val_acc: 0.5260\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5908 - acc: 0.4082 - val_loss: 1.2581 - val_acc: 0.5104\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5633 - acc: 0.4022 - val_loss: 1.3982 - val_acc: 0.4583\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5254 - acc: 0.4284 - val_loss: 5.1747 - val_acc: 0.1429\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5328 - acc: 0.4333 - val_loss: 1.5784 - val_acc: 0.3958\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5759 - acc: 0.4123 - val_loss: 9.7008 - val_acc: 0.1042\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5490 - acc: 0.4275 - val_loss: 1.5050 - val_acc: 0.3802\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5182 - acc: 0.4297 - val_loss: 1.2288 - val_acc: 0.5417\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5023 - acc: 0.4204 - val_loss: 1.8871 - val_acc: 0.3571\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5268 - acc: 0.4244 - val_loss: 1.9719 - val_acc: 0.3125\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5459 - acc: 0.4143 - val_loss: 1.8227 - val_acc: 0.3229\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5354 - acc: 0.4103 - val_loss: 3.5290 - val_acc: 0.1510\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4860 - acc: 0.4183 - val_loss: 1.4194 - val_acc: 0.4688\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4909 - acc: 0.4103 - val_loss: 2.7013 - val_acc: 0.2240\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5360 - acc: 0.4174 - val_loss: 1.1550 - val_acc: 0.5952\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4951 - acc: 0.4333 - val_loss: 1.1286 - val_acc: 0.5677\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5321 - acc: 0.4063 - val_loss: 2.3230 - val_acc: 0.2604\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5326 - acc: 0.4154 - val_loss: 1.8546 - val_acc: 0.3646\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5221 - acc: 0.4175 - val_loss: 1.7227 - val_acc: 0.3646\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5506 - acc: 0.4454 - val_loss: 1.9266 - val_acc: 0.3274\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4789 - acc: 0.4467 - val_loss: 2.4273 - val_acc: 0.2656\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5765 - acc: 0.4054 - val_loss: 1.2672 - val_acc: 0.5052\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5513 - acc: 0.4155 - val_loss: 1.6636 - val_acc: 0.3490\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.5074 - acc: 0.4562 - val_loss: 1.2026 - val_acc: 0.5573\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5077 - acc: 0.4425 - val_loss: 1.7465 - val_acc: 0.3452\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4912 - acc: 0.4570 - val_loss: 2.3824 - val_acc: 0.2500\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4980 - acc: 0.4405 - val_loss: 1.4795 - val_acc: 0.3802\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4689 - acc: 0.4352 - val_loss: 1.1691 - val_acc: 0.5625\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4662 - acc: 0.4417 - val_loss: 1.2146 - val_acc: 0.5156\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4880 - acc: 0.4505 - val_loss: 3.2027 - val_acc: 0.2500\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4884 - acc: 0.4396 - val_loss: 1.2395 - val_acc: 0.5119\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4704 - acc: 0.4656 - val_loss: 3.1164 - val_acc: 0.1927\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4538 - acc: 0.4585 - val_loss: 1.2235 - val_acc: 0.5104\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4620 - acc: 0.4476 - val_loss: 1.0538 - val_acc: 0.6146\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4686 - acc: 0.4385 - val_loss: 1.3358 - val_acc: 0.4635\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4580 - acc: 0.4637 - val_loss: 1.2341 - val_acc: 0.5179\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4967 - acc: 0.4363 - val_loss: 1.1754 - val_acc: 0.5677\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4791 - acc: 0.4427 - val_loss: 1.0494 - val_acc: 0.6042\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4626 - acc: 0.4707 - val_loss: 1.1990 - val_acc: 0.4792\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4565 - acc: 0.4535 - val_loss: 2.7354 - val_acc: 0.2292\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.4483 - acc: 0.4598 - val_loss: 1.1683 - val_acc: 0.5655\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.4494 - acc: 0.4456 - val_loss: 4.5068 - val_acc: 0.1562\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.12915601023\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 101ms/step - loss: 3.2901 - acc: 0.3175 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 8.2131 - acc: 0.3226 - val_loss: 13.9354 - val_acc: 0.1354\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 10.9904 - acc: 0.3115 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 12.2940 - acc: 0.2340 - val_loss: 14.1993 - val_acc: 0.1190\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 13.2097 - acc: 0.1804 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 13.5452 - acc: 0.1593 - val_loss: 14.8589 - val_acc: 0.0781\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2172 - acc: 0.1179 - val_loss: 15.7823 - val_acc: 0.0208\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3472 - acc: 0.1099 - val_loss: 15.7823 - val_acc: 0.0208\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3472 - acc: 0.1099 - val_loss: 14.4871 - val_acc: 0.1012\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3310 - acc: 0.1109 - val_loss: 14.9428 - val_acc: 0.0729\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 14.4270 - acc: 0.1049 - val_loss: 13.5996 - val_acc: 0.1562\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3813 - acc: 0.1078 - val_loss: 13.5996 - val_acc: 0.1562\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3960 - acc: 0.1068 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4107 - acc: 0.1059 - val_loss: 14.4871 - val_acc: 0.1012\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 14.2187 - acc: 0.1178 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5896 - acc: 0.0948 - val_loss: 13.2638 - val_acc: 0.1771\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3651 - acc: 0.1088 - val_loss: 13.4317 - val_acc: 0.1667\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5571 - acc: 0.0968 - val_loss: 13.5996 - val_acc: 0.1562\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3294 - acc: 0.1110 - val_loss: 13.8515 - val_acc: 0.1406\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4773 - acc: 0.1018 - val_loss: 13.9115 - val_acc: 0.1369\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4432 - acc: 0.1039 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6872 - acc: 0.0888 - val_loss: 15.1107 - val_acc: 0.0625\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.1180 - acc: 0.1241 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3325 - acc: 0.1108 - val_loss: 14.1033 - val_acc: 0.1250\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4758 - acc: 0.1019 - val_loss: 14.5830 - val_acc: 0.0952\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2156 - acc: 0.1180 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4595 - acc: 0.1029 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3960 - acc: 0.1068 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3813 - acc: 0.1078 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.1862 - acc: 0.1199 - val_loss: 14.4871 - val_acc: 0.1012\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3310 - acc: 0.1109 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3798 - acc: 0.1078 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4138 - acc: 0.1057 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4285 - acc: 0.1048 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2969 - acc: 0.1130 - val_loss: 14.3552 - val_acc: 0.1094\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3976 - acc: 0.1067 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 14.4770 - acc: 0.1018 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3310 - acc: 0.1109 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 20ms/step - loss: 14.3960 - acc: 0.1068 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4515 - acc: 0.1029 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5245 - acc: 0.0989 - val_loss: 14.6790 - val_acc: 0.0893\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 14.3798 - acc: 0.1078 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.7522 - acc: 0.0847 - val_loss: 14.8589 - val_acc: 0.0781\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2675 - acc: 0.1148 - val_loss: 14.3552 - val_acc: 0.1094\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 14.7847 - acc: 0.0827 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5749 - acc: 0.0957 - val_loss: 14.3912 - val_acc: 0.1071\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3619 - acc: 0.1090 - val_loss: 15.0268 - val_acc: 0.0677\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6074 - acc: 0.0937 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3472 - acc: 0.1099 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4123 - acc: 0.1058 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4285 - acc: 0.1048 - val_loss: 13.6836 - val_acc: 0.1510\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 14.6546 - acc: 0.0908 - val_loss: 14.4871 - val_acc: 0.1012\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3945 - acc: 0.1069 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5261 - acc: 0.0988 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5571 - acc: 0.0968 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4464 - acc: 0.1037 - val_loss: 14.8589 - val_acc: 0.0781\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5245 - acc: 0.0989 - val_loss: 14.8709 - val_acc: 0.0774\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4920 - acc: 0.1009 - val_loss: 14.1033 - val_acc: 0.1250\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3341 - acc: 0.1107 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3976 - acc: 0.1067 - val_loss: 14.9428 - val_acc: 0.0729\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6059 - acc: 0.0938 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3310 - acc: 0.1109 - val_loss: 14.1993 - val_acc: 0.1190\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4758 - acc: 0.1019 - val_loss: 14.3552 - val_acc: 0.1094\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4920 - acc: 0.1009 - val_loss: 14.4391 - val_acc: 0.1042\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4789 - acc: 0.1017 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4432 - acc: 0.1039 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5245 - acc: 0.0989 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5424 - acc: 0.0978 - val_loss: 14.9668 - val_acc: 0.0714\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4283 - acc: 0.1048 - val_loss: 14.8589 - val_acc: 0.0781\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3016 - acc: 0.1127 - val_loss: 13.9354 - val_acc: 0.1354\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5245 - acc: 0.0989 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5083 - acc: 0.0999 - val_loss: 14.1033 - val_acc: 0.1250\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6546 - acc: 0.0908 - val_loss: 13.4317 - val_acc: 0.1667\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 14.4789 - acc: 0.1017 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2481 - acc: 0.1160 - val_loss: 14.9428 - val_acc: 0.0729\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.7212 - acc: 0.0867 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2822 - acc: 0.1139 - val_loss: 14.4391 - val_acc: 0.1042\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4464 - acc: 0.1037 - val_loss: 15.1587 - val_acc: 0.0595\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2985 - acc: 0.1129 - val_loss: 14.4391 - val_acc: 0.1042\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4138 - acc: 0.1057 - val_loss: 14.4391 - val_acc: 0.1042\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.3163 - acc: 0.1118 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4920 - acc: 0.1009 - val_loss: 14.6070 - val_acc: 0.0938\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 14.4123 - acc: 0.1058 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.7685 - acc: 0.0837 - val_loss: 14.9668 - val_acc: 0.0714\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.2319 - acc: 0.1170 - val_loss: 14.3552 - val_acc: 0.1094\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4773 - acc: 0.1018 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5408 - acc: 0.0979 - val_loss: 14.0194 - val_acc: 0.1302\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4646 - acc: 0.1018 - val_loss: 14.9428 - val_acc: 0.0729\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4595 - acc: 0.1029 - val_loss: 14.9668 - val_acc: 0.0714\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6384 - acc: 0.0918 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4285 - acc: 0.1048 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4432 - acc: 0.1039 - val_loss: 14.1873 - val_acc: 0.1198\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4895 - acc: 0.1009 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5733 - acc: 0.0958 - val_loss: 13.7196 - val_acc: 0.1488\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4301 - acc: 0.1047 - val_loss: 15.1107 - val_acc: 0.0625\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6578 - acc: 0.0906 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.5571 - acc: 0.0968 - val_loss: 14.2712 - val_acc: 0.1146\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6059 - acc: 0.0938 - val_loss: 14.6910 - val_acc: 0.0885\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.6872 - acc: 0.0888 - val_loss: 14.2712 - val_acc: 0.1146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 14.4611 - acc: 0.1028 - val_loss: 14.5830 - val_acc: 0.0952\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.101662404092\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 97ms/step - loss: 2.0292 - acc: 0.3778 - val_loss: 12.6565 - val_acc: 0.1094\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.2161 - acc: 0.5645 - val_loss: 4.7951 - val_acc: 0.1667\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0455 - acc: 0.6131 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 1.0958 - acc: 0.6289 - val_loss: 13.7838 - val_acc: 0.0952\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8447 - acc: 0.6853 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7375 - acc: 0.7188 - val_loss: 14.5231 - val_acc: 0.0990\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6437 - acc: 0.7693 - val_loss: 13.0204 - val_acc: 0.1354\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.5749 - acc: 0.8085 - val_loss: 11.6865 - val_acc: 0.0938\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4494 - acc: 0.8467 - val_loss: 13.6534 - val_acc: 0.1131\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3666 - acc: 0.8790 - val_loss: 14.6828 - val_acc: 0.0833\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3462 - acc: 0.8709 - val_loss: 12.2468 - val_acc: 0.0781\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3134 - acc: 0.8854 - val_loss: 14.2598 - val_acc: 0.0781\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2787 - acc: 0.8923 - val_loss: 6.5294 - val_acc: 0.2500\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.3164 - acc: 0.8903 - val_loss: 1.7009 - val_acc: 0.6458\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2106 - acc: 0.9345 - val_loss: 3.9532 - val_acc: 0.3452\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2500 - acc: 0.9195 - val_loss: 2.3745 - val_acc: 0.5365\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2642 - acc: 0.9176 - val_loss: 0.4752 - val_acc: 0.8646\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2067 - acc: 0.9276 - val_loss: 7.2533 - val_acc: 0.2865\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1763 - acc: 0.9395 - val_loss: 0.7066 - val_acc: 0.8490\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1347 - acc: 0.9557 - val_loss: 0.3250 - val_acc: 0.9345\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1535 - acc: 0.9597 - val_loss: 1.8194 - val_acc: 0.6250\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1460 - acc: 0.9526 - val_loss: 0.2228 - val_acc: 0.9062\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1032 - acc: 0.9707 - val_loss: 4.0518 - val_acc: 0.3594\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1139 - acc: 0.9596 - val_loss: 1.1569 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0950 - acc: 0.9668 - val_loss: 1.2641 - val_acc: 0.7024\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1177 - acc: 0.9677 - val_loss: 0.3278 - val_acc: 0.9062\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0949 - acc: 0.9678 - val_loss: 14.3552 - val_acc: 0.1094\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2352 - acc: 0.9378 - val_loss: 0.6150 - val_acc: 0.8698\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1789 - acc: 0.9487 - val_loss: 0.8569 - val_acc: 0.7708\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0766 - acc: 0.9828 - val_loss: 1.1330 - val_acc: 0.7135\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1052 - acc: 0.9628 - val_loss: 7.1441 - val_acc: 0.2857\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0911 - acc: 0.9687 - val_loss: 0.3257 - val_acc: 0.8958\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0956 - acc: 0.9699 - val_loss: 11.1829 - val_acc: 0.1615\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.1112 - acc: 0.9627 - val_loss: 1.3638 - val_acc: 0.6719\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0798 - acc: 0.9708 - val_loss: 0.7360 - val_acc: 0.7604\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0898 - acc: 0.9697 - val_loss: 0.6708 - val_acc: 0.8214\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1677 - acc: 0.9396 - val_loss: 13.9787 - val_acc: 0.1146\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1514 - acc: 0.9507 - val_loss: 0.9211 - val_acc: 0.7344\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0976 - acc: 0.9647 - val_loss: 0.2467 - val_acc: 0.9375\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0710 - acc: 0.9818 - val_loss: 0.4792 - val_acc: 0.8542\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0609 - acc: 0.9799 - val_loss: 0.3599 - val_acc: 0.9226\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0971 - acc: 0.9669 - val_loss: 0.1511 - val_acc: 0.9479\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1060 - acc: 0.9759 - val_loss: 0.7696 - val_acc: 0.7604\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0720 - acc: 0.9728 - val_loss: 6.5293 - val_acc: 0.2812\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0683 - acc: 0.9779 - val_loss: 0.3163 - val_acc: 0.9167\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0470 - acc: 0.9828 - val_loss: 0.5209 - val_acc: 0.8646\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0599 - acc: 0.9819 - val_loss: 0.4116 - val_acc: 0.9226\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0511 - acc: 0.9849 - val_loss: 0.0860 - val_acc: 0.9531\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0638 - acc: 0.9789 - val_loss: 0.1297 - val_acc: 0.9479\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0660 - acc: 0.9759 - val_loss: 0.2795 - val_acc: 0.9062\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0401 - acc: 0.9869 - val_loss: 0.3246 - val_acc: 0.9271\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0457 - acc: 0.9818 - val_loss: 0.0225 - val_acc: 0.9940\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0649 - acc: 0.9730 - val_loss: 0.2106 - val_acc: 0.9479\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0741 - acc: 0.9750 - val_loss: 8.9777 - val_acc: 0.2344\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0674 - acc: 0.9818 - val_loss: 1.9466 - val_acc: 0.6042\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0327 - acc: 0.9879 - val_loss: 3.5222 - val_acc: 0.5052\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0599 - acc: 0.9819 - val_loss: 8.0083 - val_acc: 0.1607\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0839 - acc: 0.9789 - val_loss: 7.1505 - val_acc: 0.4062\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0656 - acc: 0.9839 - val_loss: 0.7602 - val_acc: 0.8125\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0564 - acc: 0.9839 - val_loss: 0.1588 - val_acc: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0576 - acc: 0.9798 - val_loss: 8.2277 - val_acc: 0.3073\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0568 - acc: 0.9840 - val_loss: 2.3774 - val_acc: 0.6354\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0481 - acc: 0.9860 - val_loss: 14.7339 - val_acc: 0.0774\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0631 - acc: 0.9809 - val_loss: 1.6557 - val_acc: 0.7083\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0418 - acc: 0.9849 - val_loss: 1.7556 - val_acc: 0.7135\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0432 - acc: 0.9819 - val_loss: 0.1326 - val_acc: 0.9740\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0330 - acc: 0.9909 - val_loss: 0.1441 - val_acc: 0.9792\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0380 - acc: 0.9899 - val_loss: 0.1455 - val_acc: 0.9464\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0279 - acc: 0.9939 - val_loss: 0.3687 - val_acc: 0.8854\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0265 - acc: 0.9950 - val_loss: 0.0876 - val_acc: 0.9792\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0379 - acc: 0.9899 - val_loss: 0.4495 - val_acc: 0.8698\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0571 - acc: 0.9818 - val_loss: 3.0856 - val_acc: 0.5625\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0456 - acc: 0.9869 - val_loss: 0.1127 - val_acc: 0.9940\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0237 - acc: 0.9939 - val_loss: 0.1490 - val_acc: 0.9531\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0291 - acc: 0.9889 - val_loss: 1.0430 - val_acc: 0.7708\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0218 - acc: 0.9929 - val_loss: 0.1920 - val_acc: 0.9531\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0194 - acc: 0.9919 - val_loss: 0.2552 - val_acc: 0.9427\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0385 - acc: 0.9860 - val_loss: 0.5276 - val_acc: 0.8281\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0385 - acc: 0.9800 - val_loss: 0.5367 - val_acc: 0.8869\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0237 - acc: 0.9950 - val_loss: 0.1249 - val_acc: 0.9740\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0218 - acc: 0.9930 - val_loss: 0.1203 - val_acc: 0.9688\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0196 - acc: 0.9960 - val_loss: 0.1469 - val_acc: 0.9531\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0265 - acc: 0.9899 - val_loss: 0.8028 - val_acc: 0.7812\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0224 - acc: 0.9939 - val_loss: 0.5062 - val_acc: 0.8929\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0175 - acc: 0.9939 - val_loss: 0.3434 - val_acc: 0.9323\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0261 - acc: 0.9889 - val_loss: 0.8269 - val_acc: 0.7812\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0216 - acc: 0.9929 - val_loss: 0.5908 - val_acc: 0.8854\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0282 - acc: 0.9919 - val_loss: 0.0679 - val_acc: 0.9844\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0182 - acc: 0.9910 - val_loss: 1.0060 - val_acc: 0.7798\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0130 - acc: 0.9970 - val_loss: 0.2174 - val_acc: 0.9583\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0171 - acc: 0.9970 - val_loss: 0.2103 - val_acc: 0.9531\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0305 - acc: 0.9889 - val_loss: 0.3537 - val_acc: 0.8854\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0189 - acc: 0.9950 - val_loss: 0.2421 - val_acc: 0.9323\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0259 - acc: 0.9919 - val_loss: 0.3212 - val_acc: 0.9271\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.2954 - val_acc: 0.9286\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0144 - acc: 0.9970 - val_loss: 0.2828 - val_acc: 0.9167\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0189 - acc: 0.9960 - val_loss: 0.6961 - val_acc: 0.8906\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.995 - 1s 19ms/step - loss: 0.0132 - acc: 0.9960 - val_loss: 4.2605 - val_acc: 0.4010\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0239 - acc: 0.9939 - val_loss: 9.3514 - val_acc: 0.2135\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.0493 - val_acc: 0.9821\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.971707161125\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 4s 114ms/step - loss: 3.4290 - acc: 0.1553 - val_loss: 7.0431 - val_acc: 0.1927\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 2.6210 - acc: 0.2690 - val_loss: 4.7516 - val_acc: 0.1771\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.3771 - acc: 0.2851 - val_loss: 1.7649 - val_acc: 0.3646\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.1178 - acc: 0.3206 - val_loss: 10.4976 - val_acc: 0.1190\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 2.0232 - acc: 0.3437 - val_loss: 1.5691 - val_acc: 0.4167\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 2.0717 - acc: 0.3306 - val_loss: 3.8367 - val_acc: 0.1406\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7445 - acc: 0.3841 - val_loss: 1.4374 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.8393 - acc: 0.3630 - val_loss: 1.5332 - val_acc: 0.4844\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7742 - acc: 0.3753 - val_loss: 1.8822 - val_acc: 0.3490\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.7842 - acc: 0.3783 - val_loss: 1.7884 - val_acc: 0.3333\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6396 - acc: 0.4053 - val_loss: 3.5393 - val_acc: 0.1875\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6521 - acc: 0.4123 - val_loss: 2.6046 - val_acc: 0.2083\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.6111 - acc: 0.4195 - val_loss: 2.3323 - val_acc: 0.2865\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.5495 - acc: 0.4305 - val_loss: 2.7579 - val_acc: 0.2031\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.5149 - acc: 0.4496 - val_loss: 4.7944 - val_acc: 0.1667\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4918 - acc: 0.4800 - val_loss: 2.8154 - val_acc: 0.1927\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4729 - acc: 0.4619 - val_loss: 1.6174 - val_acc: 0.3906\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4508 - acc: 0.4707 - val_loss: 3.1614 - val_acc: 0.2292\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.3736 - acc: 0.4741 - val_loss: 1.5127 - val_acc: 0.4479\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.4564 - acc: 0.4659 - val_loss: 4.0524 - val_acc: 0.1845\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.3838 - acc: 0.4779 - val_loss: 2.5506 - val_acc: 0.2448\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2945 - acc: 0.5292 - val_loss: 2.7833 - val_acc: 0.1615\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.2785 - acc: 0.5222 - val_loss: 4.4796 - val_acc: 0.1979\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2378 - acc: 0.5483 - val_loss: 3.7841 - val_acc: 0.1406\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.2620 - acc: 0.5544 - val_loss: 3.3231 - val_acc: 0.1615\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.1707 - acc: 0.5577 - val_loss: 1.7466 - val_acc: 0.3988\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.1611 - acc: 0.5726 - val_loss: 3.9380 - val_acc: 0.2135\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1999 - acc: 0.5565 - val_loss: 1.8598 - val_acc: 0.3698\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.1160 - acc: 0.5594 - val_loss: 3.2589 - val_acc: 0.1562\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.1339 - acc: 0.5929 - val_loss: 6.1577 - val_acc: 0.0677\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.0678 - acc: 0.6190 - val_loss: 2.3830 - val_acc: 0.2679\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.0935 - acc: 0.6011 - val_loss: 4.8548 - val_acc: 0.1719\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0539 - acc: 0.6079 - val_loss: 1.8228 - val_acc: 0.4115\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9730 - acc: 0.6382 - val_loss: 1.5793 - val_acc: 0.4375\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9012 - acc: 0.6663 - val_loss: 2.1040 - val_acc: 0.3229\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9323 - acc: 0.6613 - val_loss: 1.9472 - val_acc: 0.3988\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9004 - acc: 0.6895 - val_loss: 2.5379 - val_acc: 0.2604\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 1.0225 - acc: 0.6282 - val_loss: 7.3709 - val_acc: 0.0885\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 1.0447 - acc: 0.6566 - val_loss: 6.4266 - val_acc: 0.1250\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9424 - acc: 0.6683 - val_loss: 9.1108 - val_acc: 0.1198\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8361 - acc: 0.6957 - val_loss: 1.1571 - val_acc: 0.5781\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.9012 - acc: 0.6734 - val_loss: 1.3050 - val_acc: 0.5595\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8491 - acc: 0.6805 - val_loss: 1.5374 - val_acc: 0.4531\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8159 - acc: 0.6977 - val_loss: 1.9534 - val_acc: 0.4167\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8822 - acc: 0.6877 - val_loss: 1.6811 - val_acc: 0.4219\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8293 - acc: 0.6948 - val_loss: 3.2209 - val_acc: 0.2448\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.8322 - acc: 0.7069 - val_loss: 0.9911 - val_acc: 0.6548\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7848 - acc: 0.7280 - val_loss: 0.6908 - val_acc: 0.7604\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7127 - acc: 0.7239 - val_loss: 0.6034 - val_acc: 0.7656\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6935 - acc: 0.7380 - val_loss: 1.5912 - val_acc: 0.4531\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6964 - acc: 0.7299 - val_loss: 0.9870 - val_acc: 0.6302\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7600 - acc: 0.7451 - val_loss: 0.6381 - val_acc: 0.7679\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.7773 - acc: 0.7511 - val_loss: 0.6629 - val_acc: 0.7552\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6727 - acc: 0.7398 - val_loss: 0.6472 - val_acc: 0.7760\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.7024 - acc: 0.7371 - val_loss: 2.1456 - val_acc: 0.4635\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5995 - acc: 0.8063 - val_loss: 0.6465 - val_acc: 0.7708\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5530 - acc: 0.8014 - val_loss: 0.9050 - val_acc: 0.6719\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6886 - acc: 0.7713 - val_loss: 0.6599 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6161 - acc: 0.7855 - val_loss: 0.8604 - val_acc: 0.7396\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6343 - acc: 0.7805 - val_loss: 0.4131 - val_acc: 0.8594\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5892 - acc: 0.7883 - val_loss: 3.0613 - val_acc: 0.3594\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5214 - acc: 0.8197 - val_loss: 0.3629 - val_acc: 0.8698\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5673 - acc: 0.7954 - val_loss: 0.9228 - val_acc: 0.7024\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5849 - acc: 0.7855 - val_loss: 0.3687 - val_acc: 0.8698\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5553 - acc: 0.8189 - val_loss: 0.2646 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4703 - acc: 0.8256 - val_loss: 0.9207 - val_acc: 0.6667\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8986 - acc: 0.6986 - val_loss: 6.9018 - val_acc: 0.2500\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.6429 - acc: 0.7602 - val_loss: 0.3404 - val_acc: 0.8631\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6040 - acc: 0.7975 - val_loss: 0.7564 - val_acc: 0.7865\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.5739 - acc: 0.7793 - val_loss: 0.7669 - val_acc: 0.7552\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4989 - acc: 0.8205 - val_loss: 0.7642 - val_acc: 0.7760\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4927 - acc: 0.8396 - val_loss: 0.3409 - val_acc: 0.8802\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4677 - acc: 0.8356 - val_loss: 1.2376 - val_acc: 0.6302\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4556 - acc: 0.8509 - val_loss: 0.4903 - val_acc: 0.8155\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.5560 - acc: 0.8277 - val_loss: 0.4611 - val_acc: 0.8385\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4608 - acc: 0.8468 - val_loss: 0.4809 - val_acc: 0.8490\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4556 - acc: 0.8449 - val_loss: 0.2528 - val_acc: 0.9323\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4993 - acc: 0.8299 - val_loss: 0.6160 - val_acc: 0.8073\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4409 - acc: 0.8660 - val_loss: 0.2053 - val_acc: 0.9048\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4414 - acc: 0.8650 - val_loss: 0.2137 - val_acc: 0.9167\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4826 - acc: 0.8348 - val_loss: 0.3818 - val_acc: 0.8750\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4343 - acc: 0.8517 - val_loss: 1.5702 - val_acc: 0.5781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3715 - acc: 0.8750 - val_loss: 0.4613 - val_acc: 0.8438\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3728 - acc: 0.8630 - val_loss: 0.7820 - val_acc: 0.7917\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4019 - acc: 0.8711 - val_loss: 0.7225 - val_acc: 0.7969\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4526 - acc: 0.8410 - val_loss: 0.5656 - val_acc: 0.7760\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3905 - acc: 0.8689 - val_loss: 0.2814 - val_acc: 0.9062\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.4523 - acc: 0.8670 - val_loss: 0.7879 - val_acc: 0.8021\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4141 - acc: 0.8500 - val_loss: 0.3586 - val_acc: 0.8854\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4629 - acc: 0.8550 - val_loss: 0.1463 - val_acc: 0.9583\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3355 - acc: 0.8951 - val_loss: 0.2099 - val_acc: 0.9167\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3097 - acc: 0.8961 - val_loss: 3.8676 - val_acc: 0.3281\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3313 - acc: 0.8931 - val_loss: 0.3860 - val_acc: 0.8594\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3308 - acc: 0.9002 - val_loss: 0.5927 - val_acc: 0.8021\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2788 - acc: 0.9103 - val_loss: 1.7584 - val_acc: 0.5238\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3147 - acc: 0.8853 - val_loss: 0.5717 - val_acc: 0.8281\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2849 - acc: 0.9093 - val_loss: 0.2121 - val_acc: 0.9583\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.2694 - acc: 0.9083 - val_loss: 0.2244 - val_acc: 0.9167\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3250 - acc: 0.8882 - val_loss: 0.2330 - val_acc: 0.9271\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.3727 - acc: 0.8922 - val_loss: 0.2163 - val_acc: 0.8988\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.944801026958\n",
      "nesterov is True\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 1.6870 - acc: 0.4374 - val_loss: 11.7555 - val_acc: 0.1198\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1206 - acc: 0.5847 - val_loss: 14.4405 - val_acc: 0.0938\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9717 - acc: 0.6261 - val_loss: 6.2691 - val_acc: 0.1719\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.9600 - acc: 0.6566 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6863 - acc: 0.7540 - val_loss: 14.7749 - val_acc: 0.0833\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4598 - acc: 0.8297 - val_loss: 14.5972 - val_acc: 0.0938\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3354 - acc: 0.8730 - val_loss: 13.7628 - val_acc: 0.1302\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.4065 - acc: 0.8722 - val_loss: 6.5120 - val_acc: 0.2344\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3508 - acc: 0.8770 - val_loss: 7.3357 - val_acc: 0.2135\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.3292 - acc: 0.8923 - val_loss: 0.5130 - val_acc: 0.8333\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2266 - acc: 0.9223 - val_loss: 0.7638 - val_acc: 0.7812\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.2255 - acc: 0.9206 - val_loss: 7.6963 - val_acc: 0.2396\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.2611 - acc: 0.9065 - val_loss: 0.9337 - val_acc: 0.6927\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1597 - acc: 0.9455 - val_loss: 0.1551 - val_acc: 0.9583\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1309 - acc: 0.9546 - val_loss: 0.0513 - val_acc: 0.9762\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1417 - acc: 0.9486 - val_loss: 3.8596 - val_acc: 0.3490\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1523 - acc: 0.9436 - val_loss: 0.1415 - val_acc: 0.9427\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1285 - acc: 0.9557 - val_loss: 0.3095 - val_acc: 0.8854\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0989 - acc: 0.9617 - val_loss: 0.1508 - val_acc: 0.9583\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1064 - acc: 0.9618 - val_loss: 7.2081 - val_acc: 0.2344\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0998 - acc: 0.9697 - val_loss: 0.2616 - val_acc: 0.8869\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.1230 - acc: 0.9638 - val_loss: 6.0377 - val_acc: 0.2604\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1013 - acc: 0.9667 - val_loss: 0.7141 - val_acc: 0.7656\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0906 - acc: 0.9668 - val_loss: 0.1560 - val_acc: 0.9427\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0892 - acc: 0.9677 - val_loss: 12.1165 - val_acc: 0.1406\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0760 - acc: 0.9709 - val_loss: 0.0681 - val_acc: 0.9702\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1092 - acc: 0.9627 - val_loss: 0.0990 - val_acc: 0.9688\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0801 - acc: 0.9728 - val_loss: 0.1709 - val_acc: 0.9427\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0652 - acc: 0.9819 - val_loss: 0.0493 - val_acc: 0.9844\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0859 - acc: 0.9708 - val_loss: 0.1824 - val_acc: 0.9740\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0701 - acc: 0.9739 - val_loss: 0.6533 - val_acc: 0.8095\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0773 - acc: 0.9748 - val_loss: 0.1703 - val_acc: 0.9479\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0482 - acc: 0.9828 - val_loss: 0.1638 - val_acc: 0.9323\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0587 - acc: 0.9769 - val_loss: 0.2510 - val_acc: 0.9115\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0583 - acc: 0.9818 - val_loss: 0.1138 - val_acc: 0.9688\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0628 - acc: 0.9758 - val_loss: 0.7533 - val_acc: 0.8490\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0602 - acc: 0.9788 - val_loss: 0.1536 - val_acc: 0.9405\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0644 - acc: 0.9749 - val_loss: 0.1981 - val_acc: 0.9635\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0492 - acc: 0.9818 - val_loss: 0.3874 - val_acc: 0.8698\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0431 - acc: 0.9859 - val_loss: 0.0405 - val_acc: 0.9792\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0531 - acc: 0.9808 - val_loss: 0.2040 - val_acc: 0.9688\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0488 - acc: 0.9849 - val_loss: 0.1403 - val_acc: 0.9583\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0653 - acc: 0.9770 - val_loss: 0.1408 - val_acc: 0.9427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0406 - acc: 0.9839 - val_loss: 0.1557 - val_acc: 0.9635\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0384 - acc: 0.9859 - val_loss: 0.1929 - val_acc: 0.9531\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0565 - acc: 0.9828 - val_loss: 0.2700 - val_acc: 0.9167\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0354 - acc: 0.9919 - val_loss: 0.2410 - val_acc: 0.9405\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0418 - acc: 0.9860 - val_loss: 0.1530 - val_acc: 0.9635\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0332 - acc: 0.9889 - val_loss: 0.1101 - val_acc: 0.9740\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0530 - acc: 0.9839 - val_loss: 0.2406 - val_acc: 0.9531\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0365 - acc: 0.9869 - val_loss: 0.1986 - val_acc: 0.9479\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0402 - acc: 0.9889 - val_loss: 0.2635 - val_acc: 0.9323\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0248 - acc: 0.9939 - val_loss: 0.2846 - val_acc: 0.9464\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0292 - acc: 0.9889 - val_loss: 0.1225 - val_acc: 0.9531\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0558 - acc: 0.9829 - val_loss: 0.5032 - val_acc: 0.8438\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0216 - acc: 0.9950 - val_loss: 0.1783 - val_acc: 0.9792\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0488 - acc: 0.9869 - val_loss: 0.6049 - val_acc: 0.8438\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0197 - acc: 0.9929 - val_loss: 0.0369 - val_acc: 0.9821\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0477 - acc: 0.9829 - val_loss: 3.9876 - val_acc: 0.4740\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0455 - acc: 0.9839 - val_loss: 0.1182 - val_acc: 0.9740\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0222 - acc: 0.9940 - val_loss: 0.4465 - val_acc: 0.8750\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0625 - acc: 0.9769 - val_loss: 1.9484 - val_acc: 0.5990\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0288 - acc: 0.9929 - val_loss: 0.1799 - val_acc: 0.9464\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0422 - acc: 0.9899 - val_loss: 0.2307 - val_acc: 0.9479\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0444 - acc: 0.9859 - val_loss: 0.3481 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0688 - acc: 0.9799 - val_loss: 3.0794 - val_acc: 0.4479\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 0.5893 - val_acc: 0.8542\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0340 - acc: 0.9870 - val_loss: 0.2976 - val_acc: 0.9115\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0383 - acc: 0.9870 - val_loss: 0.5908 - val_acc: 0.8512\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0552 - acc: 0.9859 - val_loss: 0.0871 - val_acc: 0.9688\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0391 - acc: 0.9830 - val_loss: 0.0527 - val_acc: 0.9948\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0527 - acc: 0.9859 - val_loss: 0.1951 - val_acc: 0.9740\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0282 - acc: 0.9919 - val_loss: 0.1068 - val_acc: 0.9792\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0315 - acc: 0.9879 - val_loss: 2.1048 - val_acc: 0.6488\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0343 - acc: 0.9850 - val_loss: 0.0220 - val_acc: 0.9844\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0579 - acc: 0.9780 - val_loss: 1.3236 - val_acc: 0.7188\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0208 - acc: 0.9939 - val_loss: 0.2433 - val_acc: 0.9792\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0510 - acc: 0.9819 - val_loss: 0.8483 - val_acc: 0.7865\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0345 - acc: 0.9879 - val_loss: 0.5777 - val_acc: 0.8750\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.0382 - acc: 0.9829 - val_loss: 0.0309 - val_acc: 0.9896\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0654 - acc: 0.9779 - val_loss: 0.4426 - val_acc: 0.9167\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0489 - acc: 0.9779 - val_loss: 0.8140 - val_acc: 0.7917\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0326 - acc: 0.9869 - val_loss: 0.1926 - val_acc: 0.9583\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0278 - acc: 0.9909 - val_loss: 0.1081 - val_acc: 0.9583\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1116 - acc: 0.9779 - val_loss: 0.4758 - val_acc: 0.9107\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0348 - acc: 0.9850 - val_loss: 0.1660 - val_acc: 0.9427\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0412 - acc: 0.9890 - val_loss: 0.1403 - val_acc: 0.9688\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0257 - acc: 0.9879 - val_loss: 0.4840 - val_acc: 0.8542\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0202 - acc: 0.9950 - val_loss: 0.1453 - val_acc: 0.9740\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0239 - acc: 0.9919 - val_loss: 0.1538 - val_acc: 0.9702\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0133 - acc: 0.9950 - val_loss: 0.2290 - val_acc: 0.9635\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0594 - acc: 0.9840 - val_loss: 7.9282 - val_acc: 0.2396\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0357 - acc: 0.9879 - val_loss: 0.1137 - val_acc: 0.9896\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0317 - acc: 0.9909 - val_loss: 0.1490 - val_acc: 0.9531\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0297 - acc: 0.9851 - val_loss: 0.1172 - val_acc: 0.9643\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0257 - acc: 0.9880 - val_loss: 0.0814 - val_acc: 0.9844\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0215 - acc: 0.9939 - val_loss: 0.2615 - val_acc: 0.9375\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.0823 - acc: 0.9720 - val_loss: 2.0836 - val_acc: 0.5990\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0590 - acc: 0.9839 - val_loss: 0.1872 - val_acc: 0.9635\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.0215 - acc: 0.9929 - val_loss: 0.0727 - val_acc: 0.9792\n",
      "200/200 [==============================] - 3s 15ms/step\n",
      "Test accuracy: 0.980019181586\n",
      "Evalutation of best performing model:\n",
      "[0.045213151886306528, 0.98897058823529416]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 2, 'Dense_1': 3, 'Dropout': 0.8232978920685093, 'Dropout_1': 0.7585898935293622, 'Dropout_2': 0.10466253116015645, 'Dropout_3': 0.006030364039549152, 'Dropout_4': 0.3090642664069536, 'conv_second': 1, 'conv_second_1': 1, 'lr': 0.007873681469020732, 'nesterov': 0}\n"
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    img_size = (32, 32)\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255.,)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory='./Synthetic_dataset/train',\n",
    "        batch_size=32,   \n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        directory='./Synthetic_dataset/val',\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory='./Synthetic_dataset/test',\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        target_size=img_size)\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "def model(train_generator, validation_generator, test_generator):\n",
    "    \n",
    "    nb_train_samples = 1000\n",
    "    nb_validation_samples = 200\n",
    "    nb_test_samples = 200\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    conv_second = {{choice(['yes', 'no'])}}\n",
    "    if conv_second == 'yes':\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense({{choice([32, 64, 128, 256])}}, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    dense_second = {{choice(['yes', 'no'])}}\n",
    "    if dense_second == 'yes':\n",
    "        model.add(Dense({{choice([32, 64, 128, 256])}}, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "        \n",
    "    nesterov = {{choice([True, False])}}\n",
    "    print('nesterov is', nesterov)\n",
    "    sgd = SGD(lr = {{uniform(0, 0.3)}}, momentum = {{uniform(0, 1)}}, nesterov=nesterov)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        verbose=1,\n",
    "        workers=1,#f you want multiprocessing change it\n",
    "        use_multiprocessing=False,)\n",
    "    \n",
    "    score, acc = model.evaluate_generator(generator=test_generator, steps=nb_test_samples, verbose = 1)\n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "train_generator, validation_generator, test_generator = data()\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=30,\n",
    "                                      verbose=1,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='fonts_classifier')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate_generator(generator=test_generator, steps=200))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model.save_weights('best_model_top_sgd_weights')\n",
    "best_model.save('best_model_top_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_sgd = keras.models.load_model('best_model_top_sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate test score of best_model_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "0.9889386189258312\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5):\n",
    "    acc.append(best_model_sgd.evaluate_generator(generator=test_generator, steps=200, verbose = 1)[1])\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAEWCAYAAADIE4vrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4VGXah+93Jr2TQijpoUPovYOo\ngAVUBEFRsaLiYltXd1fFtra162fXtYJYKYo0kSK9SQklIZQUSCWV9DnfH88MmSSTQgkJ8N7XlWsy\nc86c855p53ee8nuVYRhoNBqNRqPRaBoPU2MPQKPRaDQajeZiRwsyjUaj0Wg0mkZGCzKNRqPRaDSa\nRkYLMo1Go9FoNJpGRgsyjUaj0Wg0mkZGCzKNRqPRaDSaRkYLMo1G0+RRSkUopQyllFM91r1VKbXm\nXIxLo9FozhZakGk0mrOKUuqQUqpEKRVY5fHtVlEV0Tgj02g0mqaLFmQajaYhOAhMtt1RSsUA7o03\nnKZBfSJ8Go3m4kQLMo1G0xB8Cdxsd/8W4Av7FZRSvkqpL5RS6Uqpw0qpfyulTNZlZqXUf5VSGUqp\nBOAKB8/9RCl1VCmVrJR6Tillrs/AlFLfKaWOKaVylFKrlFKd7Za5K6VetY4nRym1Rinlbl02WCm1\nVimVrZRKVErdan38D6XUHXbbqJQytUYF71NKxQFx1sfetG4jVym1RSk1xG59s1Lqn0qpA0qpPOvy\nUKXUu0qpV6scywKl1AP1OW6NRtO00YJMo9E0BOsBH6VUR6tQmgR8VWWdtwFfIAoYhgi4adZldwJX\nAj2A3sCEKs/9HCgD2ljXuQy4g/qxCGgLNAe2Al/bLfsv0AsYCPgDjwIWpVSY9XlvA0FAd2B7PfcH\nMB7oB3Sy3t9k3YY/8A3wnVLKzbrsISS6OBbwAW4DTliPebKdaA0ELgFmn8I4NBpNE0ULMo1G01DY\nomSXAnuBZNsCO5H2uGEYeYZhHAJeBaZaV5kIvGEYRqJhGFnAC3bPDQbGAA8YhlFgGEYa8DpwQ30G\nZRjGp9Z9FgOzgG7WiJsJET8zDcNINgyj3DCMtdb1bgSWGYYx2zCMUsMwMg3DOBVB9oJhGFmGYRRa\nx/CVdRtlhmG8CrgC7a3r3gH82zCMfYbwl3XdjUAOIsKwHu8fhmGknsI4NBpNE0XXM2g0mobiS2AV\nEEmVdCUQCLgAh+0eOwy0tv7fCkisssxGOOAMHFVK2R4zVVnfIVYh+DxwPRLpstiNxxVwAw44eGpo\nDY/Xl0pjU0o9jAivVoCBRMJsTRC17etz4CZgqfX2zTMYk0ajaULoCJlGo2kQDMM4jBT3jwV+rLI4\nAyhFxJWNMCqiaEcRYWK/zEYiUAwEGobhZ/3zMQyjM3UzBRgHjELSpRHWx5V1TEVAtIPnJdbwOEAB\n4GF3v4WDdQzbP9Z6sX8gUcBmhmH4IZEvm7qsbV9fAeOUUt2AjsDPNayn0WjOM7Qg02g0DcntwEjD\nMArsHzQMoxyYCzyvlPJWSoUjtVO2OrO5wN+UUiFKqWbAY3bPPQosAV5VSvkopUxKqWil1LB6jMcb\nEXOZiIj6j912LcCnwGtKqVbW4voBSilXpM5slFJqolLKSSkVoJTqbn3qduBapZSHUqqN9ZjrGkMZ\nkA44KaWeRCJkNj4GnlVKtVVCV6VUgHWMSUj92ZfAD7YUqEajOf/Rgkyj0TQYhmEcMAxjcw2L70ei\nSwnAGqS4/VPrso+AxcBfSOF91QjbzUjKMxY4DnwPtKzHkL5A0p/J1ueur7L8EWAnInqygJcAk2EY\nR5BI38PWx7cD3azPeR0oAVKRlOLX1M5ipEFgv3UsRVROab6GCNIlQC7wCZUtQz4HYhBRptFoLhCU\nYRh1r6XRaDSaJoFSaigSSYywRvU0Gs0FgI6QaTQazXmCUsoZmAl8rMWYRnNhoQWZRqPRnAcopToC\n2Uhq9o1GHo5GoznL6JSlRqPRaDQaTSOjI2QajUaj0Wg0jcx5ZwwbGBhoRERENPYwNBqNRqPRaOpk\ny5YtGYZhBNW13nknyCIiIti8uaYueo1Go9FoNJqmg1LqcN1r6ZSlRqPRaDQaTaOjBZlGo9FoNBpN\nI6MFmUaj0Wg0Gk0jc97VkDmitLSUpKQkioqKGnso5ww3NzdCQkJwdnZu7KFoNBqNRqM5Qy4IQZaU\nlIS3tzcREREopRp7OA2OYRhkZmaSlJREZGRkYw9Ho9FoNBrNGdJgKUul1KdKqTSl1K4aliul1FtK\nqXil1A6lVM/T3VdRUREBAQEXhRgDUEoREBBwUUUENRqNRqO5kGnIGrL/AaNrWT4GaGv9uwt470x2\ndrGIMRsX2/FqNBqNRnMh02CCzDCMVUBWLauMA74whPWAn1KqZUONR6PRaDQajQYAw4BlsyAjrrFH\ncpLG7LJsDSTa3U+yPlYNpdRdSqnNSqnN6enp52Rwp0JmZibdu3ene/futGjRgtatW5+8X1JSUq9t\nTJs2jX379jXwSDUajeY8pbQQCo839ig054qGnmd73buw5nXYt6hh93MKNGZRv6Ocm8N3wDCMD4EP\nAXr37t3kZkMPCAhg+/btAMyaNQsvLy8eeeSRSusYhoFhGJhMjjXwZ5991uDj1Gg0mvOWhQ/C4bVw\n/1YwXxD9aJqaWPggpO+HqT+Bk8vZ3/7B1RhLn+RE1BgKYu6k+dnfw2nRmJ/qJCDU7n4IkNJIY2kQ\n4uPjGT9+PIMHD2bDhg0sXLiQp59+mq1bt1JYWMikSZN48sknARg8eDDvvPMOXbp0ITAwkOnTp7No\n0SI8PDyYN28ezZs3lY+MRnMBU1IAX4wHjwCIHAqRQ6B5Z6jhQkpzjigthNj5UFoAB5ZDu8vP6e6L\nSssBcHM2O1xuGAa7U3JZGptKUVk5V8S0JKa1b5Ot9TUMg/S8YhIyCkhILyAhPZ+0vOJK68TkreGy\n7G8pnvw97UJbnPUxpOUWsWDHURbuSMHNycwNfUMZ3aUFrvt/gc2fykqrX8Uy7DFWx2fw9frD7D2W\nR3iAB1GBnkQFedGnaC3R8Z/hfM17mILa1HnMiVmFbI/dzYg/ppJlBHNF7HXMCE9h+rDos358p0Nj\nCrL5wAyl1BygH5BjGMbRM93o0wt2E5uSe8aDs6dTKx+euqrzaT03NjaWzz77jPfffx+AF198EX9/\nf8rKyhgxYgQTJkygU6dOlZ6Tk5PDsGHDePHFF3nooYf49NNPeeyxx874ODQaTR2kbIekjeAZBPut\nqQx3f4gYDCP+Bc07nPsxGQY00RP7mZKWV8S3GxMxmxVD2wbRqaUPJpODY41fLmJMmWHrF/UWZIUl\n5ayJz2BZbCobD2VRWm6ptNzZbOK2QRHc1D+8RvG0fE8qD839i/ziMto296J7a0+GeyXRrXwX6Z7t\nmJvTgWWxaRzLLcKkwGxSfLAygahAT67u3orx3VsTEeh5yq9NjZSXwYb3oTgPfFqBT2vrbUtKiwtJ\nPBRPSuIBjh89RMnxJLnIqMLWski+Lh588r6rk4kWvm6YrK9BmCWRG088hwdF3PP+ezh1Gc/MS9rQ\nprl3jcMqKC4j9mguO5Jy2JmUzZ6jeXi7OREVJOIpKtCTiEBP/krMZt72FNYeyMBiQJfWPmQVlDBz\nznaiPIpYYHoYp6AYCGiD06r/cueG5vye3YIATxf6RfmTdLyQH7Ym07LkEBNcnsBVFXP0nUt53Pdl\nPIOjiQrypJWfO9knSknNLSItr4jU3GKSjp8gK7eAOS7PYjYV8kX4a/yjYy+Gt6tzzu9zRoMJMqXU\nbGA4EKiUSgKeApwBDMN4H/gVGAvEAyeAaQ01lsYkOjqaPn36nLw/e/ZsPvnkE8rKykhJSSE2Nraa\nIHN3d2fMmDEA9OrVi9WrV5/TMZ/3FOfBiSxoFt7YI7nwyD0qP/CBtV+Nnrekxcrt3avAsMDB1XBo\nNez9BdL3wfTV4OR65vspK4a8o9Asovb1tn8Dvz4Kbr4QEAX+0RDQRoRh9CUYwJ6jeSzbk8qf8Rl0\nC/XjrqFRBHqd+hjLLQZmR2LoNCkrt2A2KYdCJz4tj49WHeSnbcl8aZ7FJkt7rvxtEoFergxtG8jQ\ndkEMaxdEM09rumrPfHBvBt0mw4YPIC+VEvcglsQeY9uRbDxczHi6OuHpYsbTReGauZefU/xYFZ9F\ncZkFb1cnBkQH4OVW+ZR3JPMET8zbzYp96bw8oWul162s3MIrS/bxwcoERgdnM9k3lmZpG2izewce\nSDTJ03BnufE23dtGMapTMCPaB+FkMrFo11F+3p7Mm8vjeGNZHF1a+zAoOpD+0QH0ifDHy7XuU+/x\nghI2HMxkW2I2ni5OBPu40tzLmR5bHscv/icMFKpKlY8zEGX9AyjFmWKzR6V1zEY516lFXNvFREHf\nB0TA+LpXCOGiXPjoEVDeWMrduDdwP5P2pLJwRwrjurXizqFRFJVaSEjPJyGjgIPpBcSn55OQno/F\nOpwWPm50auVDflEZv+9NZ+7mJMyU004lkWgE4e8fyIwRbbi6e2vaNPfCYjH480AGbvPuxDkvl6uS\nbiQjOYBFzit4quxtrpn0M5fFhOLqJBFKoyiH8g8ex1LoxYour9F/22P8t+Bf3JP0HIt2eZ4ch5er\nE819XAn2dmNgdCB358+lQ2IcxoTPeKLLtXW+B+eaBhNkhmFMrmO5Adx3tvd7upGshsLTs+LKKC4u\njjfffJONGzfi5+fHTTfd5NBLzMWlImduNpspKys7J2O9YPj+dolyPLQXnN0aezTnNwUZIkgOrhJx\nkmntSBr8IIz494VXy5O6C9z8wLulRKW6T5a/uKXw9QQpAh5+FqLV69+DZU/BkEdgxD/BVD0VZqx5\nE7XsSZJ8upPn2pKAzCR8k37AtVQyAEta3cOszEtJySlCKWgf7M3HqxP4ct1hbhkYwV1Do/D3rLv+\npqi0nPtnb+P3vWmENHMn2hrNiAryom2wF51a+uBZDwFhY39qHh+tSmDe9hTcnE0SHQnyJDrIi5a+\nbvyy4yjL96bh6mRielfot2cvfdySaH3Jv1iRcIIV+9L4cVsyZpNiQFQAV3YKYOLeXzF1Gge9b4P1\n/8cfc9/kkaMjyMgvwdXJREm55WQN+INO3zPT6Uc6q9aMi5yC/8Bb6N22NS5O1dPOFovB5+sO8cKi\nvYx+YxWvTOjGiA7NSc0t4v5vtnH88A4WBv9Kl5w/IAcIbI8RczOZQX2JK3Cn36qbWd13G05jrq+0\n3Rv6hnFD3zCO5hQyf3sKy/ek8emfB/lgVQJmk6JriC89w5rh5+6Mp6sTXq5OJ1/jzYezWHcgk73H\n8gBwNitKyw0UFl52+hA/p1W8XDqRD8uvpDnZtFBZdPLMo6NnHv6+Pvi3jCAkvA0tQ6Nx9gzEuWq6\n3VIOP91Nr53vQGQwtPtbxTLDgHn3QVYC3DwP07aviIlbwupHPubDNUf4fN0hft5eUVnkZFKEBXgQ\nFejFlV0lTRvT2pfmPm5gscj36dBWSuP/wHRkHebSPEo8W+I86XNUWPuT2zGZFENK/oT8FeQPfowr\nTaPILymjLOB1wn+dRnj2N+D0z5NjVD/fi1P2IbhlPiMiBkPPzrh/Po7v3J6n+O8LSCOQZp4ulYXv\nX3Pgp29hwAxUExRjcIE49Z8v5Obm4u3tjY+PD0ePHmXx4sWMHl2bVZvmlDnwO8Qtlv/jFkOncY07\nnvOZ1a/B8qflfxcvCB8IvW6RSNGa1yFpM1z3CXgHN+447TAMgw0HszicWcCVXVudkpAAIDUWgrtU\nTxG2vRS6TIDVr0LnayCovePnV+FoTiHrEzLxdXdmZAe71yl1FygTrP6vXDxc9yl4Seok7lgOx+c9\nTt+jX7OgvD8Pp99LiVFxHH7k8ZbzO/RO/ooekVfwwKh2jOjQnCBvVw6k5/P28jg+WHWAL9cd4tZB\nEdw1JBpfD7sp1hY9JgLw8ucpLivn3q+38vveNCb3DSW3sIwD6fn8GZ9BcZmk95SCNkFecrIN8aVz\nK19a+rrR3Me1ImJhGKxLyOSjVQms2JeOu7OZ63qFYFKQkF7An/EZ/Lg1GQB/TxceGNWWqf3DCdj9\nP9gDppJ8rjH/yTWTb8NiMdiZnMOS2GP8uvMYvy2cww0uebyc2J7d849zr6UDEYe/p0f0NUzpH87Q\ntkGYFBSWlnMi4wj+n/5KUVBfwikmIvEVmPcR9J4G3W+CE5mQuhNSd8OxXZgy45kW1J6r+vXj5b3N\nmf6/fK7oEcnh/duZVjaXK1zXogq9YNg/RAx6t0ABAdY/cqbgtPkjGHAP+NmXRAstfd25e1g0dw+L\nprCknC2Hj7MuIYP1CVl8uf4wJWWWas9xdTLRK7wZD1/ajgHRAXQN8cMwyimdNxOvXauI6ziDFmF3\n8oanC1GBXkQGeuLu4ri2zSEmM4x/HyxlsPQJMDtD/3tk2dq3JBp52XNSP3kiE3bMIeD4Xzw+diB3\nDIli2Z5Umnu7EhXkRWgzd5zMDuorSwrgw+GQsR8AZ/9o6HodtOyOy5rX4X9jZR/9pssHrCADfnkY\nWnbHa+Tfuf/khV5HSFos37sOV0DLbvDnG7B3IVz2vJQSALTqIQ0AX4zD9avxhE77FZyDIGVbxcXk\nwZUQPhhGPV3/1+ocowXZOaRnz5506tSJLl26EBUVxaBBgxp7SBcWlnJY/G/wC5ci4B1zL0xBVpwH\nK1+CIQ9LGqchKMiAVa9A9CUw/HFo1V1+uG2ED4SFD8EHQ2DCZxBxdj7Le47mMm97Ct7bPqCddzHD\nLrsWl8iB4OJR6/OyT5Tww9ZkvtlwmAPpUjPz0m/7mD4siqn9I+p3wrJYMNJiyWl/PQXZhQR5uVaO\nqox+EUv8cvLn3sPszh+w62g+FsMg2NuNYB9Xgr1d6ZI6j0y8+bmwO+sOZHIo88TJp88Y0YaHL2sn\nKbysBGka6DIBfn0EPhjCzoFv8K+NrtyS8SrXmVezxGscJcOfY2tMK1ydTJwoLie/pIyC4jJMSUH4\nL7iWd9tthz5DTu4jOsiLN27owX0j2vDm8jj+748DfLspiefGd2F0lxbyHdn+Nfi0ouSSZ7nva4mM\nPX9NF27sF273Uhik5BSyPzWPnUm57EzOZnV8Bj9uS670kvl5ONPZM5+xxYt4Pnc0Hl4+PHxpO27q\nH16RbrSSX1xGYtYJIgLsBETcUknDunjApk+h1zRMJkW3UD+6hfrxyGXtyZnzNcXxnqwo6URuQT7H\n20+mX9xTfDS0CCIrmp08XJzw2PAyGAZuEz8GvzA4sh7W/x/8+aZcRNhw8xXh3eEKSN1N4Na3eNmw\n8Ly7C7t3hxBjOoRydkX1fwAG/g08/B1/ZkY8Dju/gz9egPH/V+vHy93FzOC2gQxuG3jysZIyCwXF\nZeQXl1GUk4r/xlfxCY/BOTpKygKUkqjVr4/huutrGPIwbUc+QdszrSk0O8G1H0F5Kfz2GJicILCd\n+HJ1Gg8DZsh6bS4Bswvs+xXCBxLk7crkvmF1b/+v2SLGLn9BfoN97RytOo+Hn+6R/R5ZD1e/LWKs\nOBfGv1c96j7mRUj4A36+F0bNguXPyEXRgCoJtpBecNMP8NW18MEwKCuEohxZFtgOet4i0e0mHNVX\nRkN7fZxlevfubWzevLnSY3v27KFjx46NNKLG42I97hrZ+gXMv18EQuJG2PwJPLK/4URLY7HpY/kB\nu+I16HN7w+xj2dNyArtvIwS1c7xO6m74diocPwSXPAED7q/0Y5dfXFY5ZWAph0NrIKRPJYGVkl3I\nz9uTmbcthX2peUx0WsnLTh+cXG6YnFEhfeSKPeZ6CGx7ctm+Y3l8uCqBhTtSKC6z0CPMjxv7hRPm\n78E7K+JZtT+dQC9Xpg+L4qb+4dW65CwWg/1peaw7kEnc3p38J3Eqj5XewZzykQAEeLrQ3MeNQC8X\nko8X0iNrEa+6vM+/Sm/jD++rcHUykZpbhKWkgJedP+Qq83r2WkK53vQq/SL96R8VQP+oAL5af5g5\nmxKZ3DeU58bHYH4lSk5MV76OJWUHuV9MwaswmQRzJO0sBygY+A88L3289mL+L8ZJRO+BHeDs7nCV\nXck5PPr9DmKP5nJF15Y838+C35eXYLj6MD3kJxbvTuWZcZ25eUBEzfuxIzW3iD1Hc0nLLSY1t4gT\nWUncuv8+gkuTWdv1P/S8anqNnYjVKDkBL0dCr2nyGVv4INy+DEIram4pL4X/toW2l8G1H1Y879UO\nUth/3UcV66Zshw+HwaCZcOkzlfd1/DDsXyxRrOAu4BtS+bUtyhFLjYOrKTy4HueIfjgNeehk1LJW\nlvwb1r4D96yF4E51r18T82bAti8r7nsFWyNACnZ9DwPvh0ufPbsNHmUlMPdmaWBx8ZbmgDuXg6td\n8f6X10D2Ebh/S/22abHAu33B1QvuXOF4vBaLROOWPw2ezSH/GFzypFxkOmLfbzB7kkSVA9vBHctl\n+444vBZ+f15qLiOsndLeZ79L9FRQSm0xDKN3Xes1Xamo0ZwKxfnw+3MQ0leunpqFw4b3pFW+1y2N\nPbr6U5+Ouh1z5fbgyoYRZCeyYOOH1tRcDWIMILgz3PUHzJ8hV9Z/zYFRTxPvN5AXFu1j+d40RnVs\nzlNXdSY0ay0sfUpSdRFDYMpcCnHlnRVxfLgqgdJyg55hfrwzwsQVG/8HYUP5pdMr/PDzj4z1imNc\ncQLOq16R7rLbFpPv25Y3lu7ns7WHcHMycX3vEKb0DadTK5+Tw/sisi+bD2Xx+rL9PPfLHl5fur9a\nCrOwtJy8IqnRnOyzG4BRw0fS3TeG1NxiUvOKSMstIi2vmOjmXkR0v52suB08e/w7TPf+XU5gxw9R\nPnsKprRYTvi2oV1+ItsfvwSzU8W+Xrg2hgAvF95dcYCi3ExeL8wC/yiyCkp44LcitmU/xVeBX9C1\nYA1c+TqevW+r+30a+qikfrZ8Dv2nO1ylS2tf5s0YxAcrD/Dm8jgi4xbzCKCKc1mz+xBPXdWr3mIM\nINjHjWAfa11mfhr8bwqoHHD2YKBLPNRXjIGI87IiSQeH9oUlT8hFlL0gO7RazGA7Xl3xmIsHdL0e\ntn4JY1+WCy7DEGHkEeD4pN4sHPrdVfNY3Hyh/RhoPwbH0rYWBj8EW76QyM2UOaf6bOHYLtj2FfS/\nD/reKWm2Q6sl1ZZ/DPrfe/bFGIjH18TP4dub4MgGmPRVZTEG0H6sRHEz4ipdDNXIgd+l1vSaD2se\nr8kEgx+AkN7w3TS5SBs4s+Ztth8NPaZKOnXSVzWLMZDo/bRf6h5nE0QLMk3To7wM3h8sdR/97q7f\nc9a+Bfmp8mVVClr1lG60nd81bUFWVgJH1kHcEvkrzoP7NsgJwhHHD0HiBnBykx9ri+Xse2RteB9K\n8mHoI3Wv6+YD138OexZQvvQpzLMnkWHpSIGayg19hrBv+1qOvPkgoWonhl84atBMWPs2mZ9cx4Ts\nv3Ewx8K1PVozc1Rbwt2LJcLhGQgTPuMKz0A8fe7gnq+28pbZldlTW9Dqx3EUfXYNk8qeITbfkxv6\nhPHo5e2rpcds9I7w5+s7+rMhIZMFO1Iot1TOCDiZTHQN8WVAdAAhO3bDChg1dFjtP/g934X/Gwi/\n/l1Ont/ditmwwI3f45GbDAv+BnlJlToolVL8/fIOBHq58uPCheAKu4oCuPOt1WTml/DUNX3p2uc6\nVFF2zemxqkQMgvBBUlPT69YaG1iczSZmjGzLZZ1bkPXJW2CdPGTW8GZcPyiyfvuqSkEGfH415CRJ\nmmjVK3JCPxXiloCzhxyDsxt0nSSi5PL/VLwGsfPB2VNSZ/b0vEUixTu+E6G1b5EImLH/rfm701B4\n+Iu4WP60RGfCB57a821i0s1XvnMe/uAfKb9bhgFF2Q0b5XdyhSlz5TtfVYwBtBstgmzfrxBYi2iy\nseE9ie51vqbudSMGS4QXVXcq8eq3YfSLtX83z3O0INM0PY6shfQ9UrhZH0GWmwJ/viU/AKF95TGl\nIGai1HbkJEmKoilxdIecxA6sgJI8qdMI6SN1F9u+hgH3On7ezu/kdugjEhFM3SmFrmfAlsNZfLTq\nIEeyThDlXcYrSe+SEjCCLYk+NMtMdTilRlX2HuvIx1nPcXX5Uh51+4k5Zf+ErN4Y5i0UmLx5pngq\nf5aOY0bzzqQFuDLt2Cu85FSEcfvX9GvbStKZX0+FvGMw7TcRZcDw9s355s5+3Pa/TYz7JpnL/J/k\nn6kP87bT8+TdvoBubarUs1gsUiOVuktO7NbuxX5RAfSLCqj9IFJ3Q7PIun/w/aOkFmXZU2KHEdQB\nbvgaAqLh0J+yTma8Q0uLaYMiiTnuBpvhoaW5ODdryY/3DqRLa6uIqK8YszH07/DleNj+FfS5o9ZV\n2wV5Ypj3kecegndhEte3PU0hfyJL0qXHD8KN34kACe0v37XCbHD3q3sbhiFNN5HDKoRk79skQrb9\nGxg4Qz4TexdCu8uqp2RbdoWW3WHr53LhtvQJSWX1uvX0julM6TddospLn4Lbl5xaJCt+GSSskHqr\nqu+/Uuem5EIpx2IMJM3bIkZE76A6BFn6fjmeEf+qv8N+Del2x2O8cMUYaEGmaYrEzpfbpC0SLavr\nyun358Aol4JPe2ImwB//gZ3fyxVsU6EoB2ZPhtIT0OVaqYWJtEZlPrlcIlT97q5uhWAYsOM7soN6\nM2tfZ94ASW2chiCzWAyW703jg5UH2Hz4OH4eznQL8aNP2hzcLfn8LWUUu7/fcUrbvLRTMLeMeQ4v\n72dg7duwcy5q0Ey8Bj/IkCMlLJ+/m/tnb8PDpRdtOj3BsL3PwKYHIfJLqzhdDle+IcW5dvQIa8Z3\n0wdy8ycbWJAaxIherzNq+/2otfdDxHcVP/xpe6QO6cg6uR/cGXreXP8DSN0tz6kPA2ZIobFHAFz1\nRsXJzJbSyYiHNqMcPrW3dzYAI/r35d7LYvB1d3a4Xr2IGi5p+jVvQI+baz8Jpu9FFWbhPfR2eb3z\nTsOHuyhHxFhGnKTnIofK42H9AEM6b9s6Pu5KZMRJXdIgu+9liy4Q2k9c2vvfK+9jQXrldKU9PW+G\nXx6C+X8TATz528qNJ+cSFw8R6QtmSiSpwxX1e155mUTH/KPqFNSNSvux8pkpyDh5seSQDe/LxWWv\nC9JWtMHRgkxzaqx+DWJ/hrtnNDECAAAgAElEQVRWNox7uMUCexaAq4903aTukg6/mjj6l/WK+v7q\nEYmAaGjdW6JKZyrI6iMM68uSf0NeihQwVxEf9L8HvrsF9v9W7Uc9LW4TzTP28XLp7fyqFDNMrSj5\ncwGtut+Nn0fNJ+ITJWVSD5VbRGpuEcnZhfy4NZn4tHxa+7kz66pOTOwTiodRCG/8Au1G8+PEe0jL\nLSb7RGm9DsnLzYlIezfykf+SPysj2sOABwJYuOMoA6MDaOU3Gjb5yQn1szGQvFlsCWqIcLRp7sXi\nB4diMRABE2rAvHuliePK1+RksfZtEUZXvyMNHr8/B52vrd9VdWkhZB0QgVwfzE5w88/VH/cMks9u\nZnzNzz1+ELxb8fi4nvXbV20oBcMeFY+0HXNqF6CHrdG7mOvl9cpNrnndmtjyPzi2A6Z8B9EjKx5v\n3Vtc9BM31E+QxS+V27aXVn689+3w011SH7lvkaTm217meBsxE2Dxv+Cvb0QYnuPplKrR/SYp7v/j\nxfoLsm1fQPpeKbVoiDkbzxbtx0hnd9wS6D7F8TqFx6W7Mub6+jVDaKqhBZnm1Ij9WURQVoIInrNN\n0kYpYh31tKSEEjfULshWWot6a+rO6ToRFj1q9Zc6zQ6oE1nwTm9JgY5+4cyEaPwyEQuDHqguxgA6\nXAm+oWIcav1RLymz8Mmag7j+/iY3KTPRw29k29BuxH02iLZH53PJq8uZdU0PsTVABNiauAyW7Ull\nxb500qvMUQfQsaUPb97QnStiWlb4CK35WH5Uhz6Kq5OZUH8PQk8xg1Ybbs5mJvSySx33uV28kBY9\nKlG+K/5b62vr7WYX/ehxowiKFc9Lh1hRDnSbApc9K1fwQR3gk1Fid2AnDGskfa848zc/gy45kPEH\ntKkw0HVEVoJERM4WbUaJD9PqV+U1qOnC4fCfMs1OYDuZDir3NKYOjl8mr1G7KiLJ1UsiXInr67ed\nuCXyHvlVSTl3Gid2CJs+huQtcmw1CWo3XxHQ278RT6rGnl7K7AQ9p8LSJyX1XldnX1EurPgPhA2U\n731TpmV3MUvet6hmQbb1S4n693PcYKKpGy3IzgKZmZlccokUnR47dgyz2UxQkFwhbNy4sZLzfm18\n+umnjB07lhYtGrdFt0YKs+HYTvn/0JraBVlWgnRNXfN+zbUJjoidJyHv3rfBxo9EkNVUR1ZWIjVY\n3W6ouW6l87Xw2+Owcy4Ez6r/OOxJ2iwGiRveo8yAvzo9ys7kHPYey+O6XiH0iainainKkfRKUAfx\n9nKE2UlSF8uegmO72K/CuffrrSSk5bLFcx3l4aO4/VIRct2HjYNvv2OIx2Gmf2Xhsk7BlFsM1lhN\nPb3dnBjevjmdWvqIT5aP+GUFebng42pG2Z+4Swrk6j56pGOh2FD0u1tsCII61L+WxMbQv4tYPrxG\n6m8iK/y4CO0j7/3atyXqZu+D5IhU65RJwV1ObQyOCGhTkTZ1RFZCzVGf00EpeS3mTBF7hG43VF/H\nMKS+LWq4rO/TWqbBOhWK88U3qm8N3Yqh/aUov65ocnG+jMVRZ6izm4jttW/L/bp8BC99FrrfKDVl\nTYGo4XKbsBK6Tap93T/fkJTslLmNLybrQimJkv31LZQWVW8gKS+T3+vwwU3nvTgP0YLsLBAQEMD2\n7dsBmDVrFl5eXjzySD061Krw6aef0rNnz8YRZIfXWc0Sa4kQHFkvUQSUCLLauhe3fyMFuUfWV09L\n1IRhSP1Y9CXSvRfat/bOrcT1MuFw1Q4se7yCIHqE1JGNfLJyR2JWgoyv2+QafxDLLQZJO9cQimKx\ny6WM2fgeG9cm8VLZDZiU4s8DGSx9cFj9vJcW/1OunCd9WfuUTj1vhpUvcfz3t5gUPwFns4nvR5fT\n7I9M6Gl3sg0fBChe7HGccC7hreXxBPu6MqVfGJd2DKZPpD/Ojly0P7lMog/eLeXPp5Wk7E5kiCP5\nueZ0TWWVEtPImhj1lHwGf38Ornmv9m2l7gYnd+luO1MC28oFQMmJ6oa2xfnSDXw29mNP+7EQ1BHW\nvSPdilU/z5nxUJBW0QHo0+rUU5aH1kB5SY21cYT1g40fSKNJqx41b+fgSrCU1ixKe00TQWZyrjsN\n6RkAnk3IYDs4RqKPCX/ULsiyE2HduxJ1b30WUtfngvZjpb7v0Jrqael9v0DOERj9n8YZ2wXCWe6X\n11Tl888/p2/fvnTv3p17770Xi8VCWVkZU6dOJSYmhi5duvDWW2/x7bffsn37diZNmkT37t0pKSk5\ntwNd+IDU49TGodUSvWo/Rr6UtZkKxy+T22OnUBievBVyk6CTtYg3tJ/cz0lyvP6B38VhOmKI4+U2\nYiZCTmJFOiX7iBzr273h53uqRTMMw2BHUjbPLIil/wvLObB9JQlGa+YEP8L24Gu5x2kBO4dt5svb\n+5GYVcgnaw7WfWxxSyV6MGgmtK4jAuXhT3r0NXjs/5FWzgV8N30APXOWinFj+zGV1qNlN8yHVzNj\nZFt2P3M5q/4+gqeu6szANoGOxVhqrEQd21wqLefOblKnd3CV/OCG9a/7WM4XmkVI+uSv2WIaWhup\nu2TCbgdzSp4yAdaJ17MSqi87bv2snM2UJYgA6z9dItiH11Zfbqsfs00149Py1FOWB5aLTUXYAMfL\nQ62fnbrsL+KWyGc5tIbPWkC0zGDQdeK5t7A4U0wmiBomgqy238etn4u4veSJcza0MyZiiFiQ7Pu1\n8uOWcimx8AuT3xDNaXPhRcgWPVaRVjtbtIip/Uq8Bnbt2sVPP/3E2rVrcXJy4q677mLOnDlER0eT\nkZHBzp0yzuzsbPz8/Hj77bd555136N69lpqphuJElsxRmJ8GXs0dr2NzWW8zSr6UNdWRFWRUnABP\n5b3YM08Elk10hPWT28QNjm0r4peLaHPzqb7Mng5XyIlkwwew6wcx0lRK6j22/E8EmTVysPFgFo//\nuIMD6QW4mE0MbxfIoJQjmNtfzufX9gNLH1jggfeG1xnk4cFlnUby7op4rusZQgvfGqJehdnWVGXH\nek1MvSEhk+die7LA9DWze+7Bx2eMRA47XlU9rRc1DNb9H5QU4Ozi6XiD9uz+Udyur3qz8hyU9TGk\nPR8Z8rAI4SX/hlsW1HyMabFnryjcJsgy46Suyp6sBhJkIBcey2bJVEFVo46H/hRHdNvYfFpLRLSs\nWHyo6kP8sgoR7wjf1lL/mLi+RqNasbtYCtHDay9in/BJ/cbUFIkaDrt/kk7SmoyVY+fJa1m1hq4p\n4+wGbUZKHVnbSyFpk/wlbxUPMzubGc3poSNkDciyZcvYtGkTvXv3pnv37qxcuZIDBw7Qpk0b9u3b\nx8yZM1m8eDG+vo18FWgzH8SQ6UUcUZQj0a6IwRURKdtVd1UOrJBt+YaJA3V9xxA7T+wfbL47wV1E\nSCVurL5+fpqMx77TqyZcveTKLfZnEWA9boK/bRNREtgejqzHYjF4f+UBJn+0nnKLwYvXxrDpX6P4\n8OrmuBZn4WSrqzKZ4Kq3oOsNsOJ5XvH7CaO8jJd+2+t438V58NPdkqYa/3/g5IphGBzOLGDL4eMk\nZp2guKz85Oqr49K55bONFPq1pTh8BD47P5e0W3GuuJNXJXKYpH9qq1myYRiw60d5/6pOCH4hijGQ\n2sLhj0t0d98ix+vkp0ktT/N6Wl7Uhe0iJcNBp6UtatbsLKcsQdKjvW6Vi6XjhyseNwz5roYPrHif\nfVrJbX2tL7IS5K+mdKUNW5lBTdGhtD2SKj2bNXRNjajhcpvwh+PlaXvFb7AmO4+mTPux0iE++wZp\nmCnKlZKP6z6Bfvc09ujOey68CNlpRLIaCsMwuO2223j22WerLduxYweLFi3irbfe4ocffuDDDz9s\nhBFaKS2U8DmI3ULPqdXXsdWPRQyWGhnP5hIxc9RmH79M6ii6T5YuyJICqCt6c2yHuNAPfqjiMbOz\npPeOOOjcOrBCbmurH7Njfdgd5B91xdLzVgb36YmHi/WjH9YfY/dP3P3FRpbuzWBsTAteuq5rRUff\nwa1ya59mNJlFXDm74bvlHX4LWMd12+5gS/9weoXbmTim7YFvp2JkHSC2279YuNODnYs2sCMpm1zr\ndD02mnk4E+zjRkJ6AdHNvfjy9r64Hr1P7AwWPSrO15HDqh9Y2ABJIyesrPtkefQvsXYY9Ld6vWYX\nDL2nWU07n5Ar+6peVakyZVK9PcjqwsVTIlCOrC+yEsQao66o7unS5w4xSd74IVz+vDyWfVhEUMSD\nFevZBFluikMD22rEL5fb6Dq+b6H9JQqdk+g4+hO3RG7r+qyezzSLkL+EPxxP1xQ7D1AS8T7fiLle\nxLZ/lHRGV62R1JwRF54ga0KMGjWKCRMmMHPmTAIDA8nMzKSgoAB3d3fc3Ny4/vrriYyMZPp0Ce97\ne3uTl5d37gdalCO3Lt5Sl+Woi8ZWPxbSR66yIwZV1JHZR1csFtlG9EirYakhdUv289M5Ina+pNKq\n+veE9pNJrquKugPLwSOQucn+pMTuZ/qwaIeF9YZh8Nmfh3j2lyyczVdRsiAd99+WcVnnYMZ3b02E\nZ1ciiz8nJW4bs666nFsGRqDsjyd5ixx31e47k1kibCF9CPvlYRa5/ZPXfsylx8y7MZkU/PUtxsIH\nKDa5M4MnWba+Hc7mBDq08OGKrq3oGuJLsI8rGXkl4g+WV0RqbjEdWngz6+rO4isWfQkEtJXUV/97\nHacDXDzEGPTgytpfX5ATpcnp/LwyPxPMznDp09KFuONbiZDac7YFGdRsfZGV0DDRMRu+IdKZuPVL\niQy6elXMHhBul8b0thNk9SF+OfiF1211YyszOLKhBkG2VArfbYLwQiVquESjHXWc7pkvtZqNPOH1\naWF2li5YTYPQoIJMKTUaeBMwAx8bhvFileXhwKdAEJAF3GQYRg0V3OcfMTExPPXUU4waNQqLxYKz\nszPvv/8+ZrOZ22+/HcMwUErx0ksvATBt2jTuuOMO3N3dT8ku44wpEudwOo2TKVgOra7eGXlojZg/\n2mqYIgZLncTxg5XrYVJ3SjdXm0uk9g4k+lWbILOlKyMGV3eBDusvLvzJWypcwa2iLzVoAP/4cReG\nAfO3p/DyhK70trOgKCu38OzCWD5fd5jRnVvw2qRu7EzKYd5fKfyy4yjztqcQqkysdoX3h5YQ6mhe\nv+Stchw11bv0uAnVsjvuX07m2ezH2Tk3lW6ex2HLZ+x368pN2XcTEhbJ92M7EhPii6vTKdRYmEww\n4D5puOhaS8dW5FCZtuZEVs1T7xiGvF/RI099ep4LgfZj5X1c/aqkm+1PkmmxEoGszYH8VAloIxYU\nVS9Ysg5WFNY3FP3vkVrBv2bLXJuH10oZQFCHinVORsjq0WlZViJNH90cdG9WpXlncPGSOrKqKfZj\nuyS1PvhBx8+9kIgaLuURKdsq//ZlHpAGktFNJ5OjaTo0mCBTSpmBd4FLgSRgk1JqvmEYsXar/Rf4\nwjCMz5VSI4EXAAf5svOHWbNmVbo/ZcoUpkypbqS3bdu2ao9NnDiRiRMnNtTQaqbQKsg6XiknbVvR\npo2iHEl3DbGz8rDVkR36s7IgO5naGCknOTdf+QGqjfS9Ek1w5DcW0ltuEzdUCLLUnVCQztsFYbQP\n9ubR0e15ct5urv9gHbcMiODR0e0xDLh/9jZ+35vGXUOjeGx0B0wmdXJOw1lXdWbl/nT2H8vFsiWY\n0HwH3aCWcmlOqOuKsEUXPO5bzfo3pzBw72sAfMI4XiuYyINXdGLaoEjMptOs0ep1qxx3bZGJqGEy\nRdShNRUdqlVJ2iRppBH1MEm9EFEKhj4Kc6eKWOlq9z1L3XXmhrBVCWwr35uCjArX8tIiEUANUdBv\nT0gfaNVTprHpfbv4tIUPqmz54uYjEfH6eJGdtJepR5rR7CTf2aqdluVlMO8+uRgYcN+pHc/5SMRQ\nQMkclfaCLHae3J6P6UpNg9OQRf19gXjDMBIMwygB5gBVXf46AdYzOCscLNecC2wRMq/m4tm1f3Hl\notwjGyrqx2wEtpNamENrKm8rfrmkJLxbyEkwOKbuTssqNRXHC0r4eHUCa+MzrFf2HSv9wJfuE0uN\ntXTlg6m9GNkhmMUPDOWWARH8b+0hLn9jFRPeX8cf+9J4dnwX/jm2o6QR7XBxMnFpp2DuG9kWU/gA\nx3Vq6fvkRNSqbp8gk4cfnjd+zSOld3NzyT9Y3OIeFs4cwR1Dok5fjIHV+b2ONFHrXhKVqC1tuesH\nMLtCh4u4Lb3DlSK8Vv1XoqwgQiF939lNV4Jdp6VdHVn2YcBoeEGmlKS4M+Nlap7jhyr8x+zxaVm/\nCFn88vrZy9gI7Q9pu6Xg28a6d+Dodhj7ysURofUMEIPUqoX9sfMk0+Coa1xz0dOQgqw1kGh3P8n6\nmD1/AddZ/78G8FZKBVTdkFLqLqXUZqXU5vT09AYZ7EWNrYbMzU8sJ3KTKoso+/oxG0rJVbe9H1lx\nnlxN2xfat4iRGh1LRSdhNWKlpiLHHMCrS/Yx+KXfee6XPUz5eAOP/bCDkla9ZUoliwXDMDi4cQF7\nLGE8MXkk4QFSV+bp6sSsqzsz9+4BmJXiSGYBn9zah6n9w+s+/rABEj3KTqz8eIqDgv5a6BbWjG5X\n3cfocTcx567+led2bEjMznLCTahBkFnKYffPEvU833ydziYmEwx9BDL2icUKSE1XWdHZcei3x976\nwoatw/Jsm8I6otM48Gohcz1C5foxGz6t6ldDFr9cRFZ9GxHC+skFXNImuZ8RLyn1DldCp/H128aF\nQNQI6RAvzpf7xw+LKK0piq256GlIQeYoLFC1F/oRYJhSahswDEgGyqo9yTA+NAyjt2EYvW1TEjlY\n5wyHe35xVo/XlrJ084O2lwNKui1tHFpjjcJU6aiJGCzi7fghuX9wlcxNaJ/aaBEj85vZ/JeqknkA\n0nbzh7k/g1/6nbd/j2d4++YsmDGY6cOimbs5kZd2+YpozNjH16tiiSjYwYmwYYxoX90vrW+kP4sf\nHMqaf4x0uNwhNjPUxCppluQtMlG07eRaD6b2D2dKv7BqEbkGJ3KYnPwdnWAPr5X5Qes7cfaFTKfx\n0ihhi5LZ0umnO89pTfiFyUWMfYTspCBr4AgZSM1jnzvEH8rVp6Ke0x6f1nULsrxjUiJQz25mwNr4\nY5Lvk8UC82eI19kVr1649iqOiBpe2ZJmz3y5vdiaajT1piEFWRIQanc/BKj07TcMI8UwjGsNw+gB\n/Mv6WM6p7sjNzY3MzMyLRpQZhkFmZiZubrVMv3Mq2FKWbr5S7xLSu8KzqShXruocFSKfrCOzpi3j\nl0nqLLRfxTo2Y0w7x/6ycgt/JWbz/soDfPOl2H38e284g9oEsmjmEN69sScxIb48NqYDP907iAPu\nso0v5s5l5ZKfcFHl9Bg+ocbDcXUy08zzFBoigrvIuKumLZO3ysTmpvPAri/KaonxxwtShG3Prh/E\nz63d6HM/rqaGySxRstRdMil5Wiwos/jRne39+EdV9iLLSpDvmHuzmp93Nuk9TdLUYf0dd+j6tBJ/\nvPJq18AVHPhdbk9FkLl6Swr4yHrY/IkIkstfOD+7Cs+EsP7y+tvSlrHzoEXXcxMh1ZyXNGSX5Sag\nrVIqEol83QBUqm5XSgUCWYZhWIDHkY7LUyYkJISkpCQupnSmm5sbISFnqQ6hKEcKfG2dZ+1Gw+/P\nytXxsZ3V68dsBLUHj0AxnexxkwiyyKGVOxKDOkj9ybGdZEddyT9/2snq/RnkFctJ4CfPP0l1i+T9\nO6+lS+vq6bRuoX58MPN6Trz0OJ6pmxnj4Y2BB6aIGqZvOR3MTnJVby/ISovkpD1gxtnbT0MS3EXG\nuu4dMZ68/jOpUykvlSvz9mPq9oK7WOgyAf54EVa+JFGigDa1zy16ugS0Ebd2G1nWjuRzFSXyDIQp\n38oxOsK7pXQwF6TVbEMRv0w8B4MdRNhqI7Q/bP9aoszRI6F79camCx5ndxFlCX9ATrKkcEeeR1Ml\nac45DSbIDMMoU0rNABYjthefGoaxWyn1DLDZMIz5wHDgBaWUAawCTqv9xtnZmchIfdVx2hRmi6O5\njfZjRJDtXyxGoiZn8bqqir0fWeYBmSNy0MzK6zi5iig7tpMXF+1l8e5UJvYOZUB0AANamQl6bw/0\nvp9gB2LMhquzE0QP5OrUPZgUqMDB9Z/upb6EDZDoUlFORWeopaze9WONjlJiBBrSG+bNgA+GwrUf\nAQacyITOOl15ErOTTKk0f4Z45DVUx1tAG/kO2byoshLO/UTS0SNqXmYTarkpjgWZpVwMmNtedupR\n4rD+sOkjmfvwyjcurlSlPVHDYfnTMik3SG2fRlMDDZqLMQzjV8Mw2hmGEW0YxvPWx560ijEMw/je\nMIy21nXuMAyjuCHHo6mBouzKxd7NO8m0R/sWWeev7F2zI3PEECmIt/3gOHLyDu5CScoO5mxK5I7B\nkbxwbQxXd2tF0LHVInrajan+nKqE9sU5OwHz8YT6TZd0qoT1BwxItBYiJ2+R23N9Aj1TOl8Dd/0h\nliNfXQe//l1qiC5kZ/TTodsN8hm3lJ79+jEbgW1l+9mHJVKZfaRhTWFPlbq8yFK2Q2HW6X12IgaD\nkztc/hw0q0djzYVK1HC5Xfu2/K4Gtm3M0WiaOOdBcYymwSnMloJ+G0pB+9HioZOy3XGHlg1bKnPT\nR+Af7bA+ojy4Cy4nUunsW8zMUXY/SPt/A4+ACq+x2rAV3kPd07ecDiG9pZbIVoCbvFVETU3pnqZM\nYFu4Y5mYyWYlSHdbQ6TkzmfMzjD4Afm/RdeG2cfJTktr9NgoPzcF/fXlZISsBi8yW/1YbVG2mvBu\nAY8dht63nd7YLhRadpPf1vJiXcyvqRMtyDSSprNPWYLUkZUVyUmkNmfxoA4iqspLaiz8/TVdHNCf\n6UfFHJLlZTKNStvLHRccV6Vld+la8w1tmKtMF0/58bTVkSVvEf+x8zXV4uIJ17wPN8+rmNNQU5le\nt8INsxsuehhg/ZxmxlV0GTclQebhL0XnNUXIEteLB+DpzmBwtssKzkdM5gpDa52u1NSBFmTnI6VF\nsOO7yuatZ0LVlCWICHPxkvqxUAf1YzZsfmTg8MSWnF3If7aICOvlajcrVuJ62W/7enb+ObtJ40Df\nOxtOJIUNgOTN4q6eGXf+1I/VhFKSMrkYjDhPB5NZjHLrc0FwOnj4S3QkM16mGIOmJciUsprDOrC+\nsFgkfR/Wr/oyzakxYAYMegCad2zskWiaOHpy8fORPQvgxzvEWd9md3AmVE1Zglzddp0EBel1d+d1\nHl+jNcas+bvJxpsyr1Y42ZvN7lskEa9TqQe78vX6r3s6hPWH9e/Cls/kfuseDbs/zYWNUhLNzYgD\nJzcpcPeqpzfeucKnNeQ5SFmm74XinMoWNprTI6yfFraaeqEF2fmIzWDy4MozF2TlpTI9UNWUJcCV\nr9X61OKycrYdyWbd0RiSW39Fz22ZDIiGiAAPlFIs2X2MpbGpPD6mA07JXSu7/+//TQScq/eZjf9s\nYqtT2/ix3NZjyiSNplYC2sgMCi6eUl/Z1FLg3i0lKlyVRGvqXgsyjeacoQVZU2LPQohbAle/Vft6\ntvTHwVVnvk/7aZPqwdGcQr7fnMS6hEy2HD5OcZkFpcDX3Znvt0hKsoWPGwOiA9iQkEn7YG9uGxwJ\nK2OkZqy0CHKSJI3T18Fk4o2JV3NpTMg6IKklnerTnCkBbeCv2eJc3xQjrj6tYE+KlD/Yi8XEjeIx\n2JRSrBrNBY4WZE2JA8th6+cw5iUxFawJ21RFyVvFSb++c8w5otDOpb8O4tPyufHj9aTlFdOxhQ83\n9gtnQHQAfSP98XFz4kB6AesSMlmfkMmq/enkFJby1uQeOJtNYlxqlEP6ngpn//rWj51LwgaIINPR\nMc3ZwNZpmZsEMdfVvm5j4NNaGnJOZFYu3k/cIBHjphbR02guYLQga0qUWW3Ysg7W7o2UdRD8wsXf\n6Mg6aHf56e/TFiFzlLK0Y++xXG76WOZ6/PVvQ+jYsroIbNPcizbNvZjaPxzDMMgtKsPX3VkW2ubS\nO7YT9v0GzTvLfH9NjbD+sP2r87+gX9M0sO8IborRppNeZCkVgiw/Tcoiet3aaMPSaC5GdJdlU6Ks\nSG7tJySuSskJmSi660RpWT/TtGXRcbmtJWW5MymHGz5cj5PJxLd3D3AoxqqilKoQYyCGmC5ecHC1\niMimGB0DaHupTKN0JiJXo7HhHwVYo0xNyRTWhr0gs5G4UW5D+1dfX6PRNBhakDUlSq2CLOtAzetk\nH5bboA5iR3Fw5SnvZvmeVHanWCNjdaQstxw+zpSP1+Pp4sTcuwcQHeR1yvsDZOqV4M4y0bVRXj93\n/sbAu4WYqgZEN/ZINBcCzu7inQdNPEJm50WWuF46oFt2a5wxaTQXKVqQNSVORshqEWQ2g8lmkdJh\neWwnFGTWexexKbnc8cVmrnp7DU/O20VhnvW5VVKWFovBb7uOMvWTDQR4ujB3+gDCAmqYPqm+tIgR\nMeYZpFOCmouHgGiJZjfFWR+8gmWGiqoRslY99OwOGs05RteQNSVO1pAl1LyOraDfPxKMYcBzcGi1\neIHVg1cW78Xb1Ylx3Vvz1frDNHffzgzAcPNFAel5xczdnMicTUdIzCqkXbAXX93ej+Y+Z+HH2VZH\n1u7yU5+sWKM5X+lyHTSLaJqfeZNZRJnNi6ysGFK2Qb8m1gGt0VwEaEHWlCgrlNvaImTHD8pk0e7N\n5CrWxUvqyOohyDYkZLJiXzqPjenA9GHRTOoTyv6vfqD4hDM3f7qdQG9XFu86RpnFYEBUAI9e3oHL\nO7fAxeksnUhC+gIKOl1zdran0ZwP9Jwqf00Vn1YVKcuU7dJ1qevHNJpzjhZkTQlbhCz/GBTng6uD\neq3jh+RqWymZIDl8YL0K+w3D4KXf9hLs48qtAyMA6NLal84dPCmK9WXvsTw4lsetAyOY3C/s9GvF\naiO4Ezyyv+m5lWs0F6Ow2ysAACAASURBVDM+rcSZH8TuAmqfLk2j0TQIWpA1JcqKpNakvFjSli27\nVl8n62DlOdEih4qZbG5KRYGuA5bGprL1SDYvXBuDm3PF3H2qOAd37wA2TZd5KM9aNKwmtBjTaJoW\nPq3hwO/yf+IGaT7Q31ON5pzTBIsaLmLKiiGovfzvqNPSYpEuS3+79vlI69RJB1fXuNlyi8Eri/cR\nFejJ9b1CKi8szAZ3P1ycTA0vxjQaTdPDpyWU5IsnYeIGPV2SRtNINOgZWCk1Wim1TykVr5R6zMHy\nMKXUCqXUNqXUDqXU2IYcT5OntBCaWw1hHdWR5aVIfUeziIrHgrtIPVkt9hc/bk0iLi2fRy5vj5O5\nyltelF0vl36NRnOBYuv+PLwWCtJ1ulKjaSQaTJAppczAu8AYoBMwWSlV1X7+38BcwzB6ADcA/9dQ\n4zkvKCsGjwDwauFYkNk6LO0NJk0miBgidWSGUe0pRaXlvLEsjq4hvozp0qL6Nguz6z2PpUajuQCx\nlTrs/kludUG/RtMoNGSErC8QbxhGgmEYJcAcYFyVdQzAZvvuC6RwMVNWBE6u4lvkKGV50oMsovLj\nkUMhJ7Fi0nE7vlp/mOTsQv4xugPK0bx0RTl1Tpuk0WguYGyCbO+v4OorptMajeac05CCrDWQaHc/\nyfqYPbOAm5RSScCvwP0NOJ6mjaUcLKXi7O0fVUOE7KCYONqcv22crCOr3G15vKCEd1fEM6RtIIPa\nBFINi0UEmU5ZajQXL94t5bYkD0L7NE2/NI3mIqAhv3kOwjFUzalNBv5nGEYIMBb4UilVbUxKqbuU\nUpuVUpvT09MbYKhNAJtLvy1CdiKjYuJvG8cPgV8omKs0xwa2lR/VKoLsiXm7yC8u459jO+KQ4lzA\n0ClLjeZixskVPKwXbLqgX6NpNBpSkCUB9qGcEKqnJG8H5gIYhrEOcAOqhXIMw/jQMIzehmH0DgoK\naqDhNjI2DzInN/C3zqNYNUqWddDxBMVKSdrSro5swV8pLNxxlAdGtat5MnCb4NMpS43m4saWttSC\nTKNpNBpSkG0C2iqlIpVSLkjR/vwq6xwBLgFQSnVEBNkFGgKrg0oRsjbyf9UplI4fqmx5YU/kUOmQ\nOraTtLwinpi3i26hftw9tJYJjYtsE4trQabRXNT4tJJyCD3HrEbTaDSYMaxhGGVKqRnAYsAMfGoY\nxm6l1DPAZsMw5gMPAx8ppR5E0pm3GoaDVsGLgVLrtElO7hWiyz5CVpQDhVnVC/pttLkUXH0w5s/g\nKefnKSwp59Xru1W3ubCn0CbIdA2ZRnNR02k8+IU7nh1Eo9GcExrUqd8wjF+RYn37x560+z8WGNSQ\nYzhvOJmydJXCfp+Qyp2Wjiwv7PEOhms/gtk3cFn5C/S+/B3aNK/jx1WnLDUaDUD3yfKn0WgaDd1O\n01Q4mbJ0k9uAKp2WNVle2JEcPIy3jUlcY/6TaaZf6t6nTllqNBqNRtMk0IKsqWATZM5WQeYfDZnx\nFctPRsgiHD+93MI/vt/B+8Z4TkRfgWnZkxXz09WETllqNBqNRtMk0IKsqVAtQhYtEawTWXL/+EFx\n8Xer3jG5PzWP695by5r4DJ64sjMeEz8Uc8fvplVE1hxRlC2FvK7eZ/lgNBqNRqPRnApakDUV7GvI\noLr1xfFD1erHSsstvPN7HFe+tYbE44W8PbkHk/uGSWHuDV/LSnOmQHG+433aTGEdOfhrNBqNRqM5\nZ2hB1lRwFCGDisL+rIOV0pW7U3IY/+6f/HfJfi7rHMzSB4dyVbdWFdvzj4IJn0JaLGz/2vE+C/XE\n4hqNRqPRNAUatMtScwqUVhFkzSJAmSRCVl4KOUnQdSIAWw5nMemD9fh5uPD+Tb0Y7WjScIDokSK4\n0vc5Xl6UrTssNRqNRqNpAmhB1lSoGiFzcgVfq/VFTiIY5ScjZB+vPoi3mxNLHxxKM0+XmrepVPXm\nAHuKcnSHpUaj0Wg0TQCdsmwqVK0hA3HszzxgZ3kRSVpeEUtjU5nQK6R2MXZyG9HVHf9tFOoImUaj\n0Wg0TQEtyJoKZTanfreKx/ytYup4hQfZd5uTKLMYUrxfH/yjJd1pS4naU6RryDQajUajaQpoQdZU\nsJ9c3EZANBTnQtJmMLti8WrB7I1HGBAVQFRQPac4+f/27j867rrO9/jznUnSJv2RNm1oS5O0pRSx\n/BIMBcXroqJSZWHXX4DuRVGXo0dWr6674r0udy939dxl9+hejxyvqLCyqyLWH7d6uqIXf4IUWgqi\nLVZLKG1o06ZJkyZNJskk7/vH9zvNZDKZmYR8M9N8X49zcma+n/nMdz7pnG/77ufz/r4/y9YDPhbU\npbmHSf2aIRMRESk1BWTlIpWERDVUZHwl6dIX+x6CpWv45b5O2o4P8M7Lipwdg7G7NTOr/kOwd+bo\nsJYsRUREyoACsnKRGhw/OwZjwdTJo7B0Hd947ADLFlTzxvMmuasyl/qs8hlpSVXpFxERKRcKyMrF\n8MDEgGxJc1BJH+hf2MRDvz/K21oaqa6cwtdWsySo8J89QzagfSxFRETKhQKycpFrhixRBUvXALCj\np46RUefGS6ewXJlWn+NOy2RP8KglSxERkZJTQFYuUsnxJS/SwiXHHxyYx6vOXs7a5Qumfu5l6yfO\nkCU1QyYiIlIuFJCVi1Ry4gwZnMoje+rkkqkl82eqXw+9h2Do5FjbgHLIREREykWkAZmZXW1me81s\nn5ndluP1z5nZU+HPH8ysO8rxlLVUEqpyBGRnvYa2qrX0L2jm9RtXTO/cy84KHjOXLU8tWS6d3jlF\nRERkxkS2dZKZJYC7gNcDbcAOM9vq7nvSfdz9oxn9/wq4OKrxlL1cOWTAoRV/wqv7PsMHr1xHVWKa\n8XN9RumLlRcEz9NLlvMWT++cIiIiMmOinCHbBOxz91Z3HwLuB67L0/9G4JsRjqe85cgh23XgODfd\n8zhmxg3TSeZPW5aj9MVAN1QvgoS2MxURESm1KP81Xg0czDhuAy7L1dHM1gDrgJ9GOJ7yNpyERcEM\n2cDQCJ/9yV6++vBzrFw8n3vfcylN9bXTP/e8RbBwBXRmLllqH0sREZFyEWVAZjnafJK+NwBb3H0k\n54nMbgFuAWhufhEzReUsTOp//Lku/nbLb9jf2c+7Lmvmts3nsmh+1Ys/f/368TNkyR7dYSkiIlIm\nolyybAOaMo4bgUOT9L2BPMuV7n63u7e4e0tDQ8MMDrGMpAZ5rjvFO770KCPufOP9l/HpP79gZoIx\nCBL7O7OWLHWHpYiISFmIcoZsB7DBzNYBLxAEXe/M7mRmLwGWAo9GOJay56kBftOe5KKmJXzzLy+j\ntnqGv5r69cEWTMkTMH9xsGRZf9bMfoaIiIhMS8EZMjO71cymXBvB3VPArcCDwDPAA+6+28zuMLNr\nM7reCNzv7pMtZ8bC6FCSjmQF//nyNTMfjEFGYn+YR6YlSxERkbJRzL/8KwlKVuwC7gEeLDZ4cvdt\nwLasttuzjv++uKHOcakko4l5vOmCKWwcPhWZm4yf+bJgyVJJ/SIiImWh4AyZu38K2AB8FXgP8Ecz\n+4yZrY94bLHRn0ySYIS1Z9RHMzsGY8uTnc/CyDAMn1QOmYiISJkoKqk/nBFrD39SBDlfW8zszgjH\nFhs//s3zALy0OcIbFqprYdGZQUA2oH0sRUREykkxOWQfNrMngDuBR4AL3P2DwMuBt0Y8vljYtms/\nAE1n1Ef7QcvC0hentk1SQCYiIlIOilkfWw68xd2fz2x091EzuyaaYcXHwa5+nn7+CMwHy7W5+Exa\nth72bB3bNklLliIiImWhmCXLbUBX+sDMFpnZZQDu/kxUA4uL7+xqo6ZiKDiIOiCrXw8DXXB8f3Cs\nJUsREZGyUExA9kWgL+P4ZNgmL9LoqLPliTYua1oYNFTNwgwZwAu7gkctWYqIiJSFYgIyyyxz4e6j\nRFtQNja2P9dJ2/EBNp8bBkazMUMGcCgMyDRDJiIiUhaKCchaw8T+qvDnI0BrwXdJQVueaGPRvEou\nbw5nyCrnRfuBS9cCBoeeCo6VQyYiIlIWignIPgC8kmD7ozbgMsKNvmX6+gZT/Mdv27nmojOZ54NB\nY9QzZFXzoa4JUgPBZ0W9RCoiIiJFKbj06O5HCfahlBm07enDDAyP8PaWRug/GDRGHZBBsMl4zwEt\nV4qIiJSRggGZmc0H3gecB5yKGNz9vRGOa857YOdBzmpYwMVNS2B3MmicjYCsfj20/lzLlSIiImWk\nmCXLfyPYz/KNwC+ARqA3ykHNdfuO9rHz+eNc39KEmUEqHZBFnEMGY3da6g5LERGRslFMQHa2u/8d\ncNLdvwa8Gbgg2mHNbQ/sPEhlhfGWSxqDhtQsz5CBlixFRETKSDEB2XD42G1m5wN1wNrIRjTHDaVG\n+c4TbVz10hU0LApnxFJhUv9sJNkvOzt41AyZiIhI2SimntjdZrYU+BSwFVgI/F2ko5rDfvr7I3Se\nHOL6S5vGGmdzhmzpGqio1AyZiIhIGckbkJlZBXDC3Y8DvwTOmpVRzWH37zjIysXzefU5DWONw2FA\nlpiFHLJEFbzly7Dywug/S0RERIqSd8kyrMp/6yyNZc471D3AL/7QwTtaGklU2NgLqWQQjFUUs4I8\nA85/Cyw/e3Y+S0RERAoqJgL4iZl93MyazKw+/VPMyc3sajPba2b7zOy2Sfq8w8z2mNluM/vGlEZ/\nmtnyRBvu8PaWpvEvpAZnZ7lSREREylIxOWTpemMfymhzCixfmlkCuAt4PUGF/x1mttXd92T02QB8\nErjC3Y+b2RlTGfzpZHTU+daOg7zq7OU01deOfzE1MDslL0RERKQsFVOpf900z70J2OfurQBmdj9w\nHbAno89fAneFOWrpXQHmpEeePcYL3QN8YvO5E1/UDJmIiEisFVOp/6Zc7e5+X4G3rgYOZhyn98HM\ndE74GY8ACeDv3f1HOcZwC+H+mc3NzYWGXJa+teMgS2qreMPGFRNfTCW1r6SIiEiMFbNkeWnG8/nA\n64BdQKGAzHK0eY7P3wBcSbADwK/M7Hx37x73Jve7gbsBWlpass9R9rpODvHj3Ud41+XNzK9KTOyQ\nGtSSpYiISIwVs2T5V5nHZlZHsJ1SIW1AZvZ6I3AoR5/t7j4MPGdmewkCtB1FnP+08b0nX2BoZHR8\n7bFMwwNashQREYmx6dRZ6CcImgrZAWwws3VmVg3cQFBYNtP3gdcAmNlygiXM1mmMqax978k2Lmqs\n49yVi3N3UA6ZiIhIrBWTQ/YDxpYaK4CNwAOF3ufuKTO7FXiQID/sHnffbWZ3ADvdfWv42hvMbA8w\nAvyNu3dO71cpT939Q+w+dIKPXXXO5J1SSahdNnuDEhERkbJSTA7ZP2c8TwHPu3tbMSd3923Atqy2\n2zOeO/Cx8GdO2t7ahTu8Yn2egCuVVA6ZiIhIjBUTkB0ADrt7EsDMasxsrbvvj3Rkc8T21k5qqhJc\n2Jhn78hUUkuWIiIiMVZMDtm3gdGM45GwTYrw6LOdtKxdSnVlnj/q1KDKXoiIiMRYMQFZpbsPpQ/C\n59XRDWnu6OwbZO+RXi4/q0B+mGbIREREYq2YgKzDzK5NH5jZdcCx6IY0dzz2XBdQIH8MYFgBmYiI\nSJwVk0P2AeDrZvaF8LgNyFm9X8Z79NlOaqsTXLC6Ln9HJfWLiIjEWjGFYZ8FLjezhYC5e2/0w5ob\nHm3t5NK19VQl8kxEjqTAR6CyZvYGJiIiImWl4JKlmX3GzJa4e5+795rZUjP7h9kY3OnsaG+SfUf7\nCi9XpgaCR82QiYiIxFYxOWSbM/eWdPfjwJuiG9LcsL01yB8rnNA/GDwqh0xERCS2ignIEmZ2avrG\nzGoATecUsL21k4XzKjn/zEm2S0pLJYNHlb0QERGJrWKS+v8deMjM7g2Pbwa+Ft2Q5obtz3ayaV09\nlfnyx0AzZCIiIlJUUv+dZvY0cBVgwI+ANVEP7HR25ESS1mMnuXFTc+HOw8ohExERibtiliwB2gmq\n9b8VeB3wTGQjmgMefTbYH71g/hhohkxEREQmnyEzs3OAG4AbgU7gWwRlL14zS2M7bT36bCeL51ey\nsVD+GIzlkCkgExERia18S5a/B34F/Km77wMws4/OyqhOc9uf62TTumUkKqxw51NlLxSQiYiIxFW+\nJcu3EixV/szMvmxmryPIIZM8DnUP8Hxnf+H6Y2mnliyVQyYiIhJXkwZk7v49d78eOBf4OfBRYIWZ\nfdHM3jBL4zvtjOWP1Rf3hlNlL1SpX0REJK4KJvW7+0l3/7q7XwM0Ak8BtxVzcjO72sz2mtk+M5vw\nHjN7j5l1mNlT4c/7p/wblJlHWztZUlvFS1cWkT8GmiETERGRouqQneLuXcCXwp+8zCwB3AW8nmBD\n8h1mttXd92R1/Za73zqVcZSr0VHn1/uOcdm6eiqKyR+DjLIXyiETERGJq2LLXkzHJmCfu7e6+xBw\nP3BdhJ9Xcj/be5RDPUk2n7+q+DdphkxERCT2ogzIVgMHM47bwrZsbzWzp81si5k15TqRmd1iZjvN\nbGdHR0cUY50RX/5VK6vq5vPmC6cSkKXLXiiHTEREJK6iDMhyrdl51vEPgLXufiHw/5hkSyZ3v9vd\nW9y9paGhYYaHOTN+90IP21u7eM8r11JVaLukTKcCMs2QiYiIxFWUAVkbkDnj1Qgcyuzg7p3uHq7Z\n8WXg5RGOJ1Jf+VUrC6oT3JBru6Sf/y/Yee/EdggCssQ8MFUUERERiasoA7IdwAYzW2dm1QRV/7dm\ndjCzzLW9azlNt2Q63DPAD58+zPWXNlNXUzWxw65/gz3fz/3m1KAS+kVERGJuSndZToW7p8zsVuBB\nIAHc4+67zewOYKe7bwU+bGbXAimgC3hPVOOJ0r8+sp9Rd26+Yu3EF92h7wjULs395lQSqhSQiYiI\nxFlkARmAu28DtmW13Z7x/JPAJ6McQ9T6BlN84/EDbL5gFU31tRM79HfB6HDwmMtwUvljIiIiMRfl\nkmUsPLDjIL3JFO9/1brcHfrag8f+ztyvp5JashQREYk5BWQvQmpklHseeY6WNUu5uHmSJcnew2Hn\nJAz15ziJcshERETiTgHZi/Dg7iO0HR/g/f/prMk79R4Ze55rliw1oIBMREQk5hSQvQhfebiVNctq\nef3GFZN3Si9ZwiQB2aByyERERGJOAdk0PfH8cZ480M17r1hHIt++lQVnyJRDJiIiEncKyKbpnkee\nY/H8St728sb8HfvaoSKsTTZwfOLrqUGVvRAREYk5BWTT8EL3AD/6XTs3bmpmwbwClUN622H5OcHz\nXDNkw8ohExERiTsFZNNw36/3A3DTK9cW7tzbDg0vAUw5ZCIiIpKTArIpOjmY4puPH+Dq81ayeklN\n/s7pKv2Lz4SaJXlyyAqcR0REROY0BWRT9N1dbZxIpnjvZIVgMyV7goBr0SqoXZa7Wn9KlfpFRETi\nTgHZFIyOOvc+sp+LmpZwSfOSwm/oDUteLFoZBmRZM2TuustSREREFJBNxc//cJTWYyd57xVrMctT\n6iItXYNs4QqoqZ84QzaaAh9VQCYiIhJzCsim4J6H97Ni8TzedMGq4t6QrkE22QxZKhk8quyFiIhI\nrCkgK9Le9l4e3neMm16xlqpEkX9smTNktfUw0BUsU6YNhwGZZshERERiTQFZke595DnmV1Xwzk3N\nxb+ptx2qFsC8RcEMWSoJwxkbjKdnyJTULyIiEmsKyIrQ3T/Ed598gbdc0sjSBdXFv7G3HRatALMg\nIIPxy5apweBRM2QiIiKxFmlAZmZXm9leM9tnZrfl6fc2M3Mza4lyPNO15/AJGkfa2Hxenk3Ec+k7\nAgtXBs9r64PHcQHZQPCogExERCTWIgvIzCwB3AVsBjYCN5rZxhz9FgEfBh6LaiwvVt/BPfx03sc5\nu/fxqb0xPUMGGTNkGXdaaoZMREREiHaGbBOwz91b3X0IuB+4Lke//wncCSQjHMuLMtTxBwCWDTw/\ntTf2HQmKwsIkAZlyyERERCTagGw1cDDjuC1sO8XMLgaa3P2H+U5kZreY2U4z29nR0THzIy1gpPsQ\nANUnDxX/psFeGOoL7rCESXLI0mUvtHWSiIhInEUZkOWqnHqq5oOZVQCfA/660Inc/W53b3H3loaG\nhhkcYnEqeg8HT3rain9TZg0ygPl1TNhgfFgzZCIiIhJtQNYGNGUcNwKZU0yLgPOBn5vZfuByYGs5\nJvbPS4bB1VQCsswaZAAVCahZGtQiS0upDpmIiIhEG5DtADaY2TozqwZuALamX3T3Hndf7u5r3X0t\nsB241t13RjimaVk4FC6Tnnih+Ddl7mOZll2t/1RSv2bIRERE4iyygMzdU8CtwIPAM8AD7r7bzO4w\ns2uj+tyZ1jeYYvloGET1tkNqqLg3FhWQpcteKIdMREQkziqjPLm7bwO2ZbXdPknfK6Mcy3Qd7h5g\npR0nVVlLZaofeg/D0jWF39jXDol5MH/JWFttPXQfGDvWDJmIiIigSv0FtXd2sdj6Obn8ZUFDsXlk\nvUfGqvSn1dZPUvZCOWQiIiJxpoCsgBPtQe0xawzvNSg2j6yvfaxKf1p6yTK9wbhmyERERAQFZAX1\ndwYzYrXrLw8apjRDliMgGxmEoZPB8fBAMDtmuSqEiIiISFwoICsg1R0EYJUN5wRlK4oOyNonBmQ1\n4X6W6dIXqUHNjomIiIgCskJOFYVdtAoWNxa3ZDk8AIM9YzXI0rKr9aeSyh8TERERBWSFVA8cob9i\nAcxbCHWNxc2Q5Sp5AQrIREREJCcFZHm4OwuHjtJXfUbQULe6uICsL6zsnyupH8butFRAJiIiIigg\ny6tnYJgG72KoNlx6rGuEZDcM9uV/46llzuyALMwh61cOmYiIiIxRQJbHoe4kK+w4vnBV0LC4MXgs\nlEeWvbF42vwlYBVashQREZFxFJDlcfh4Hw10U7l0ddBQFwZkPQfzv7GvHSoqx+6qTKuoCO7UTAdk\nw0moUkAmIiISdwrI8jje8QKVNkrtsqagoS4MzHqKmCFbuCIIwLJl7mepGTIRERFBAVle/ceCmbCF\nDWFAtmgVYIUT+3sPT1yuTKtdpjpkIiIiMo4CsjyGu4OZsETdmUFDoioIygrlkPUdmXiHZVpNxn6W\nqQGorJmh0YqIiMjpSgFZPicOBY+Lzhxrq1tdOIestz3YWDyX2vqMJUvNkImIiIgCsryq+48wQgIW\nNIw11jXmzyFLDQVLkpPNkGVuMK4cMhEREUEB2aRGR51FQ0fpq14+Pjl/8epgydI99xvTRWEnnSFb\nBiNDwQbjmiETERERIg7IzOxqM9trZvvM7LYcr3/AzH5rZk+Z2cNmtjHK8UxF58khGryLwZqswKqu\nKZjZSi87Zju1bdKq3K+fKg57LNjzsko5ZCIiInEXWUBmZgngLmAzsBG4MUfA9Q13v8DdXwbcCXw2\nqvFM1eGeAVZaF6PZgdWp0heT3GnZFwZk2RuLp6W3T+o9ArhmyERERCTSGbJNwD53b3X3IeB+4LrM\nDu5+IuNwATDJOuDsS1fpr1yyevwLp4rDThKQTbaxeFo6IEvfqakcMhERkdirjPDcq4HM2xHbgMuy\nO5nZh4CPAdXAa3OdyMxuAW4BaG5unvGB5nKss4OFlsTqG8e/UGj7pL4jwfZImTcCZDoVkIV3cCog\nExERib0oZ8gsR9uEGTB3v8vd1wOfAD6V60Tufre7t7h7S0PDJIHODDsZFoWtXd40/oUFyyExb/LS\nF72HYcEZUJHI/XrN0uBRAZmIiIiEogzI2oDMaKYROJSn//3An0U4nikZ6gpmwGzxmeNfMAtrkU0y\nQ9Z7ZPI7LGFsg3EtWYqIiEgoyoBsB7DBzNaZWTVwA7A1s4OZbcg4fDPwxwjHMzW96aKwOe6WrGvM\nn9Q/WQ0yCDcYr8+YIVNSv4iISNxFFpC5ewq4FXgQeAZ4wN13m9kdZnZt2O1WM9ttZk8R5JG9O6rx\nTFXVyTA5P3uGDII8slw5ZO5w4nD+GTII8sjSAZnKXoiIiMRelEn9uPs2YFtW2+0Zzz8S5edP18io\ns2Cog4HqxdTkCpjqGoNcsZEUJDL+CA9sD+qLNU24d2G82mXQuS94rhkyERGR2FOl/hyO9iZZQReD\nNWfk7lC3Gnw0CMoy7boPqhfBeX+e/wNq68FHgufKIRMREYk9BWQ5pGuQjSycpNp+XY7SF8ke2P09\nuOBtUL0g/wekq/WDZshEREREAVkuh3sGWGVdJJbkyB+DsVpkmYn9v90CqQG45KbCH5CuRQZQqRwy\nERGRuIs0h+x01d7Vy3J6GMouCpuWa/ukXffBigvgzIsLf8C4gEwzZCIiInGnGbIcejtfoMKcefVN\nuTvMWwTz68YCssO/gcNPBbNjlqsebpaazCVL5ZCJiIjEnQKyHCYtCpsps/TFrvuC6v0Xvr24D8ic\nIatSQCYiIhJ3Cshy8BN5isKm1TUG2ycN9cPT34aN141ti1TIuCVLBWQiIiJxp4Ash8p8RWHT0tsn\nPbMVBnvg5VOoaZt5l2WienqDFBERkTlDAVmWodQoC4c6SFnV+JmsbHWNMNAFj/0fqD8L1lxR/Iek\nA7LK+cXlnImIiMicpoAsy5ETSVZYF8n5Z+QPltKlLw49WXwyf9q8OrCElitFREQEUNmLCQ51D7CS\n44zk2yAcxorDWgIueufUPqSiIpgls8T0BikiIiJzimbIsvQNpjgzcZxEXZ78MRirRfaSzYU3E8+l\ndplqkImIiAigGbIJXnfuGVDVA8ub83esa4aW98LLb57eB9XUA13Te6+IiIjMKQrIsiV7YLgfFucp\neQHBsuM1n5v+56y+ZOLm5CIiIhJLCsiyFVODbCa88dPRnl9EREROG8ohy9YbBmT5apCJiIiIzKBI\nAzIzu9rM9prZPjO7LcfrHzOzPWb2tJk9ZGZrohxPUebVwUv/FJaUfigiIiISD5EFZGaWAO4CNgMb\ngRvNbGNWtyeBpwKGkAAABu5JREFUFne/ENgC3BnVeIrWdClc/+9jd1GKiIiIRCzKGbJNwD53b3X3\nIeB+4LrMDu7+M3fvDw+3A40RjkdERESkLEUZkK0GDmYct4Vtk3kf8B+5XjCzW8xsp5nt7OjomMEh\nioiIiJRelAFZrr2EPGdHs78AWoB/yvW6u9/t7i3u3tLQ0DCDQxQREREpvSjLXrQBTRnHjcCh7E5m\ndhXw34A/cffBCMcjIiIiUpainCHbAWwws3VmVg3cAGzN7GBmFwNfAq5196MRjkVERESkbEUWkLl7\nCrgVeBB4BnjA3Xeb2R1mdm3Y7Z+AhcC3zewpM9s6yelERERE5qxIK/W7+zZgW1bb7RnPr4ry80VE\nREROB6rULyIiIlJi5p7zxseyZWYdwPMRf8xy4FjEnyHTo++mPOl7KV/6bsqTvpfyNdPfzRp3L1gi\n4rQLyGaDme1095ZSj0Mm0ndTnvS9lC99N+VJ30v5KtV3oyVLERERkRJTQCYiIiJSYgrIcru71AOQ\nSem7KU/6XsqXvpvypO+lfJXku1EOmYiIiEiJaYZMREREpMQUkImIiIiUmAKyLGZ2tZntNbN9ZnZb\nqccTV2bWZGY/M7NnzGy3mX0kbK83s5+Y2R/Dx6WlHmtcmVnCzJ40sx+Gx+vM7LHwu/lWuIetzCIz\nW2JmW8zs9+G18wpdM+XBzD4a/l32OzP7ppnN1zVTGmZ2j5kdNbPfZbTlvE4s8PkwJnjazC6JalwK\nyDKYWQK4C9gMbARuNLONpR1VbKWAv3b3lwKXAx8Kv4vbgIfcfQPwUHgspfERgn1q0/4R+Fz43RwH\n3leSUcXb/wZ+5O7nAhcRfD+6ZkrMzFYDHwZa3P18IAHcgK6ZUvlX4Oqstsmuk83AhvDnFuCLUQ1K\nAdl4m4B97t7q7kPA/cB1JR5TLLn7YXffFT7vJfiHZTXB9/G1sNvXgD8rzQjjzcwagTcDXwmPDXgt\nsCXsou9mlpnZYuDVwFcB3H3I3bvRNVMuKoEaM6sEaoHD6JopCXf/JdCV1TzZdXIdcJ8HtgNLzGxV\nFONSQDbeauBgxnFb2CYlZGZrgYuBx4AV7n4YgqANOKN0I4u1fwH+FhgNj5cB3e6eCo917cy+s4AO\n4N5wKfkrZrYAXTMl5+4vAP8MHCAIxHqAJ9A1U04mu05mLS5QQDae5WhTXZASMrOFwHeA/+LuJ0o9\nHgEzuwY46u5PZDbn6KprZ3ZVApcAX3T3i4GTaHmyLIT5SNcB64AzgQUES2HZdM2Un1n7u00B2Xht\nQFPGcSNwqERjiT0zqyIIxr7u7t8Nm4+kp4vDx6OlGl+MXQFca2b7CZb1X0swY7YkXI4BXTul0Aa0\nuftj4fEWggBN10zpXQU85+4d7j4MfBd4Jbpmyslk18msxQUKyMbbAWwI73ypJki63FriMcVSmJP0\nVeAZd/9sxktbgXeHz98N/N/ZHlvcufsn3b3R3dcSXCM/dfd3AT8D3hZ203czy9y9HThoZi8Jm14H\n7EHXTDk4AFxuZrXh323p70bXTPmY7DrZCtwU3m15OdCTXtqcaarUn8XM3kTwv/0EcI+7f7rEQ4ol\nM3sV8Cvgt4zlKf1XgjyyB4Bmgr/k3u7u2cmZMkvM7Erg4+5+jZmdRTBjVg88CfyFuw+WcnxxY2Yv\nI7jRohpoBW4m+I+3rpkSM7P/AVxPcAf5k8D7CXKRdM3MMjP7JnAlsBw4Avx34PvkuE7CAPoLBHdl\n9gM3u/vOSMalgExERESktLRkKSIiIlJiCshERERESkwBmYiIiEiJKSATERERKTEFZCIiIiIlpoBM\nROYUMxsxs6cyfmasWr2ZrTWz383U+URE0ioLdxEROa0MuPvLSj0IEZGp0AyZiMSCme03s380s8fD\nn7PD9jVm9pCZPR0+NoftK8zse2b2m/DnleGpEmb2ZTPbbWY/NrOakv1SIjJnKCATkbmmJmvJ8vqM\n1064+yaCytv/ErZ9AbjP3S8Evg58Pmz/PPALd7+IYE/I3WH7BuAudz8P6AbeGvHvIyIxoEr9IjKn\nmFmfuy/M0b4feK27t4Yb17e7+zIzOwascvfhsP2wuy83sw6gMXMrGzNbC/zE3TeEx58Aqtz9H6L/\nzURkLtMMmYjEiU/yfLI+uWTuNTiCcnFFZAYoIBOROLk+4/HR8PmvgRvC5+8CHg6fPwR8EMDMEma2\neLYGKSLxo//ZichcU2NmT2Uc/8jd06Uv5pnZYwT/Gb0xbPswcI+Z/Q3QAdwctn8EuNvM3kcwE/ZB\n4HDkoxeRWFIOmYjEQphD1uLux0o9FhGRbFqyFBERESkxzZCJiIiIlJhmyERERERKTAGZiIiISIkp\nIBMREREpMQVkIiIiIiWmgExERESkxP4/cAXh1QEE05MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAEWCAYAAADIE4vrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(best_model.history.history['acc'])\n",
    "plt.plot(best_model.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(best_model.history.history['loss'])\n",
    "plt.plot(best_model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets try train already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0339 - acc: 0.9910 - val_loss: 0.1249 - val_acc: 0.9896\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0278 - acc: 0.9919 - val_loss: 0.0614 - val_acc: 0.9896\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0266 - acc: 0.9929 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0294 - acc: 0.9929 - val_loss: 0.1383 - val_acc: 0.9583\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0208 - acc: 0.9970 - val_loss: 0.1555 - val_acc: 0.9531\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0178 - acc: 0.9961 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0332 - acc: 0.9899 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0252 - acc: 0.9960 - val_loss: 0.1048 - val_acc: 0.9896\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0258 - acc: 0.9950 - val_loss: 0.0694 - val_acc: 0.9844\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0206 - acc: 0.9970 - val_loss: 0.2568 - val_acc: 0.9271\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0403 - acc: 0.9880 - val_loss: 0.0641 - val_acc: 0.9881\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0284 - acc: 0.9900 - val_loss: 0.1594 - val_acc: 0.9531\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0230 - acc: 0.9950 - val_loss: 0.0600 - val_acc: 0.9844\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0200 - acc: 0.9960 - val_loss: 0.0354 - val_acc: 0.9896\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0249 - acc: 0.9960 - val_loss: 0.0678 - val_acc: 0.9948\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0362 - acc: 0.9930 - val_loss: 0.0765 - val_acc: 0.9762\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0313 - acc: 0.9909 - val_loss: 0.0492 - val_acc: 0.9844\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0260 - acc: 0.9980 - val_loss: 0.0805 - val_acc: 0.9896\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0219 - acc: 0.9960 - val_loss: 0.0687 - val_acc: 0.9948\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0280 - acc: 0.9950 - val_loss: 0.2527 - val_acc: 0.9531\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0202 - acc: 0.9970 - val_loss: 0.0352 - val_acc: 0.9948\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.0275 - acc: 0.9950 - val_loss: 0.0452 - val_acc: 0.9881\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0305 - acc: 0.9950 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0223 - acc: 0.9950 - val_loss: 0.0888 - val_acc: 0.9896\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0215 - acc: 0.9980 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0204 - acc: 0.9970 - val_loss: 0.0965 - val_acc: 0.9740\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0301 - acc: 0.9909 - val_loss: 0.0633 - val_acc: 0.9821\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0189 - acc: 0.9980 - val_loss: 0.0292 - val_acc: 0.9896\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0276 - acc: 0.9919 - val_loss: 0.0958 - val_acc: 0.9792\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0229 - acc: 0.9960 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0243 - acc: 0.9960 - val_loss: 0.0496 - val_acc: 0.9896\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0168 - acc: 0.9980 - val_loss: 0.0958 - val_acc: 0.9881\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0289 - acc: 0.9939 - val_loss: 0.3301 - val_acc: 0.8958\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0160 - acc: 0.9990 - val_loss: 0.1883 - val_acc: 0.9375\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0222 - acc: 0.9970 - val_loss: 0.1164 - val_acc: 0.9688\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0184 - acc: 0.9970 - val_loss: 0.0317 - val_acc: 0.9896\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0208 - acc: 0.9950 - val_loss: 0.0291 - val_acc: 0.9948\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0187 - acc: 0.9970 - val_loss: 0.0197 - val_acc: 0.9940\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0267 - acc: 0.9939 - val_loss: 0.0994 - val_acc: 0.9792\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0264 - acc: 0.9910 - val_loss: 0.0744 - val_acc: 0.9844\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0182 - acc: 0.9970 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0235 - acc: 0.9920 - val_loss: 0.2240 - val_acc: 0.9323\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0250 - acc: 0.9930 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0250 - acc: 0.9910 - val_loss: 0.0240 - val_acc: 0.9948\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0239 - acc: 0.9939 - val_loss: 0.0430 - val_acc: 0.9844\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0826 - val_acc: 0.9740\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0230 - acc: 0.9970 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0221 - acc: 0.9970 - val_loss: 0.4472 - val_acc: 0.8810\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0229 - acc: 0.9970 - val_loss: 0.0612 - val_acc: 0.9792\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0231 - acc: 0.9940 - val_loss: 0.0363 - val_acc: 0.9896\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0265 - acc: 0.9939 - val_loss: 0.3158 - val_acc: 0.9115\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0319 - acc: 0.9900 - val_loss: 0.3947 - val_acc: 0.8854\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.0226 - acc: 0.9939 - val_loss: 0.2393 - val_acc: 0.9323\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0201 - acc: 0.9970 - val_loss: 0.1527 - val_acc: 0.9702\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.1725 - val_acc: 0.9635\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0220 - acc: 0.9940 - val_loss: 0.0121 - val_acc: 0.9948\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0305 - acc: 0.9920 - val_loss: 0.0575 - val_acc: 0.9844\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0625 - acc: 0.9732 - val_loss: 0.1494 - val_acc: 0.9375\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0207 - acc: 0.9970 - val_loss: 0.0870 - val_acc: 0.9792\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0241 - acc: 0.9940 - val_loss: 0.0892 - val_acc: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0232 - acc: 0.9920 - val_loss: 0.0142 - val_acc: 0.9948\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.0656 - val_acc: 0.9844\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0187 - acc: 0.9980 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0181 - acc: 0.9980 - val_loss: 0.1114 - val_acc: 0.9740\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0194 - acc: 0.9960 - val_loss: 0.0518 - val_acc: 0.9948\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0208 - acc: 0.9970 - val_loss: 0.0598 - val_acc: 0.9792\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0155 - acc: 0.9980 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0213 - acc: 0.9920 - val_loss: 0.0301 - val_acc: 0.9896\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0186 - acc: 0.9980 - val_loss: 0.0756 - val_acc: 0.9821\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0124 - acc: 0.9990 - val_loss: 0.0788 - val_acc: 0.9792\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0307 - acc: 0.9899 - val_loss: 0.1070 - val_acc: 0.9688\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0204 - acc: 0.9970 - val_loss: 0.0715 - val_acc: 0.9948\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0155 - acc: 0.9990 - val_loss: 0.0067 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0166 - acc: 0.9970 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0229 - acc: 0.9940 - val_loss: 0.0151 - val_acc: 0.9948\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0155 - acc: 0.9939 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0196 - acc: 0.9960 - val_loss: 0.0796 - val_acc: 0.9844\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0160 - acc: 0.9970 - val_loss: 0.0296 - val_acc: 0.9948\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.1034 - val_acc: 0.9821\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0125 - acc: 0.9980 - val_loss: 0.0837 - val_acc: 0.9844\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0163 - acc: 0.9970 - val_loss: 0.0295 - val_acc: 0.9948\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0256 - acc: 0.9929 - val_loss: 0.0454 - val_acc: 0.9844\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0171 - acc: 0.9990 - val_loss: 0.3288 - val_acc: 0.8854\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9948\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0857 - val_acc: 0.9881\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0236 - acc: 0.9900 - val_loss: 0.0950 - val_acc: 0.9792\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.0193 - acc: 0.9980 - val_loss: 0.1508 - val_acc: 0.9479\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.0159 - acc: 0.9970 - val_loss: 0.0109 - val_acc: 0.9948\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.0189 - acc: 0.9960 - val_loss: 0.0359 - val_acc: 0.9881\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0169 - acc: 0.9980 - val_loss: 0.0661 - val_acc: 0.9948\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0145 - acc: 0.9970 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.0163 - acc: 0.9970 - val_loss: 0.0493 - val_acc: 0.9948\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0258 - acc: 0.9909 - val_loss: 0.0269 - val_acc: 0.9948\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0191 - acc: 0.9960 - val_loss: 0.0306 - val_acc: 0.9940\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0190 - acc: 0.9970 - val_loss: 0.0614 - val_acc: 0.9948\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0202 - acc: 0.9939 - val_loss: 0.0458 - val_acc: 0.9844\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.0175 - acc: 0.9970 - val_loss: 0.1577 - val_acc: 0.9531\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.0147 - acc: 0.9990 - val_loss: 0.0276 - val_acc: 0.9948\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "('Score is', 0.031197834131426995, 0.9948849104859335)\n"
     ]
    }
   ],
   "source": [
    "history, score = datagen(best_model_sgd,'./Synthetic_dataset/train', './Synthetic_dataset/val',\\\n",
    "                         './Synthetic_dataset/test', verbose=1, img_size=(32,32), batch_size=32,\\\n",
    "                         epochs=100, nb_train_samples=1000, nb_validation_samples=200, nb_test_samples = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate test score of best_model_sgd with one more training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 4s 19ms/step\n",
      "200/200 [==============================] - 4s 19ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 20ms/step\n",
      "200/200 [==============================] - 4s 19ms/step\n",
      "0.9950447570332482\n"
     ]
    }
   ],
   "source": [
    "acc_sgd = []\n",
    "for i in range(5):\n",
    "    acc_sgd.append(best_model_sgd.evaluate_generator(generator=test_generator, steps=200, verbose = 1)[1])\n",
    "print(np.mean(acc_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_sgd.save_weights('best_model_top_sgd_weights_second')\n",
    "best_model_sgd.save('best_model_top_sgd_second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(best_model_sgd.history.history['acc'])\n",
    "plt.plot(best_model_sgd.history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(best_model_sgd.history.history['loss'])\n",
    "plt.plot(best_model_sgd.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclsuion\n",
    "\n",
    "We trained 2 models with identity architecture:\n",
    "\n",
    "    INPUT - [CONV - CONV - CONV - POOL]*2 - [DENSE]*2 - OUTPUT\n",
    "    \n",
    "One has trained with Adam optimizator, another with SGD.\n",
    "\n",
    "### Results:\n",
    "    \n",
    "With Adam optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy is', 0.9930306905370843)\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy is', np.mean(acc_adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With SGD optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy is', 0.9950447570332482)\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy is', np.mean(acc_sgd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
